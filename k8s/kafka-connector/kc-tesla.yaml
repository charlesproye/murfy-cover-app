apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: tesla-kafka-to-s3
  namespace: kafka
  labels:
    strimzi.io/cluster: connect-cluster
spec:
  # https://docs.lenses.io/latest/connectors/kafka-connectors/sinks/aws-s3
  class: io.lenses.streamreactor.connect.aws.s3.sink.S3SinkConnector
  tasksMax: 1
  config:
    topics: tesla_V
    connect.s3.kcql: "INSERT INTO bib-prod-kafka-sink:tesla SELECT * FROM tesla_V PARTITIONBY _header.year, _header.month, _header.day STOREAS `JSON` PROPERTIES ('flush.interval'=3600, 'flush.size'=100000000, 'flush.count'=500000)"
    # SMT to insert timestamp headers for partitioning
    transforms: partition
    transforms.partition.type: io.lenses.connect.smt.header.InsertRecordTimestampHeaders
    transforms.partition.year.format: "yyyy"
    transforms.partition.month.format: "MM"
    transforms.partition.day.format: "dd"

    connect.s3.aws.auth.mode: Credentials
    connect.s3.aws.region: "fr-par"
    connect.s3.aws.access.key: "${secrets:kafka/s3-secret:S3_KEY}"
    connect.s3.aws.secret.key: "${secrets:kafka/s3-secret:S3_SECRET}"
    connect.s3.custom.endpoint: "https://s3.fr-par.scw.cloud"
    connect.s3.vhost.bucket: false
    # Converter configuration for handling message deserialization
    key.converter: org.apache.kafka.connect.storage.StringConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter.schemas.enable: "false"
