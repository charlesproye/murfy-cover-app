{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMW raw time series Exploratory Data Analysis\n",
    "The goal of this notebook is to validate the integrity of the data provided by the BMW API.  \n",
    "We will examine the data on its own and compare it to the one provided by High Mobility.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as DT\n",
    "import pytz\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "import plotly.express as px\n",
    "\n",
    "from core.s3_utils import S3_Bucket\n",
    "from core.constants import *\n",
    "from core.pandas_utils import *\n",
    "from transform.bmw.bmw_raw_tss import get_raw_tss_without_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss = get_raw_tss_without_units(force_update=True)\n",
    "raw_tss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = (\n",
    "    raw_tss.astype({\n",
    "        \"charging_ac_ampere\": \"float\",\n",
    "        \"charging_ac_voltage\": \"float\",\n",
    "        \"charging_method\": \"category\",\n",
    "        \"charging_plug_connected\": \"category\",\n",
    "        \"charging_status\": \"category\",\n",
    "        \"coolant_temperature\": \"float\",\n",
    "        \"kombi_remaining_electric_range\": \"float\",\n",
    "        \"mileage\": \"float\",\n",
    "        \"soc_customer_target\": \"float\",\n",
    "        \"soc_hv_header\": \"float\",\n",
    "        \"soc_target_charging_time_forecast\": \"float\",\n",
    "        \"teleservice_status\": \"category\",\n",
    "        \"vin\": \"category\",\n",
    "    })\n",
    "    .assign(date_of_value=pd.to_datetime(raw_tss[\"date_of_value\"], format='mixed'))\n",
    "    .rename(columns={\n",
    "        \"date_of_value\": \"date\",\n",
    "        \"mileage\": \"odometer\",\n",
    "        \"soc_hv_header\": \"soc\",\n",
    "    })\n",
    "    .sort_values(by=[\"vin\", \"date\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list the variables and the respective count ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss.count() / len(raw_tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss.set_index(\"vin\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data_cache\n",
    "var_counts = raw_tss.groupby('vin').count()\n",
    "var_counts.to_csv(\"data_cache/var_counts_per_vin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    tss,\n",
    "    x=\"date\",\n",
    "    y=\"odometer\",\n",
    "    facet_col=\"vin\",\n",
    "    facet_col_wrap=1,\n",
    "    facet_row_spacing=0.01   # Ensure the spacing is smaller than 0.025641\n",
    ").update_layout(\n",
    "    height=5000,            # Adjust the height to fit the rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    tss,\n",
    "    x=\"date\",\n",
    "    y=\"soc\",\n",
    "    facet_col=\"vin\",\n",
    "    facet_col_wrap=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the plots seem skewed.  \n",
    "let's see why.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tss[\"date\"] < DT(year=2024, month=8, day=1, tzinfo=pytz.UTC)\n",
    "tss[mask].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(tss, x=\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a few points before auggust, pretty suprising given the fact the BMW POC started way later than this (late September)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_vars = (\n",
    "    DF.from_dict(data=VARIABLES_THAT_WE_ASKED_FOR)\n",
    "    .drop(columns=[\"key_type\"])\n",
    ")\n",
    "\n",
    "display(requested_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "received_vars = (\n",
    "    tss\n",
    "    .dtypes\n",
    "    .to_frame(\"unit\")\n",
    "    .reset_index(drop=False)\n",
    "    .rename(columns={\"key\": \"key_name\"})\n",
    ")\n",
    "display(received_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss[raw_tss[\"date_of_value\"].isna()]\n",
    "# raw_tss.query(\"date_of_value == 'None'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data extraction pipelines comparaisons\n",
    "Assuming that the data provided by High Mobility comes from BMW API, we will compare these two pipelines:    \n",
    "As of writing this notebook markdown cell, the two data extraction pipelines are (give or take):  \n",
    "- BMW API - High Mobility - [Tom's ingestion](../../../ingestion/) - My high_mobility_raw_ts\n",
    "- BMW API - Theophile's ingestion - My bmw_raw_tss - The preprocessing code cell above(unlikely to destroy affect any values)\n",
    "\n",
    "Let's call them long and direct pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long pipeline EDA\n",
    "We will extract the raw time series of all the vins, even the ones we didn't pull from the BMW API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = S3_Bucket()\n",
    "\n",
    "def get_bmw_hm_raw_tss() -> DF:\n",
    "    keys = bucket.list_keys(\"raw_ts/bmw/time_series/\")\n",
    "    keys = keys[keys.str.endswith(\".parquet\")]\n",
    "    if len(keys) == 0:\n",
    "        print(\"no keys found!!!!!!!!\")\n",
    "        return DF(None, columns=KEY_LIST_COLUMN_NAMES)\n",
    "    # Only retain .json responses\n",
    "    # Reponses are organized as follow response/brand_name/vin/date-of-response.json\n",
    "    keys = str_split_and_retain_src(\n",
    "        keys,\n",
    "        \"/\",\n",
    "        col_names=[\"key\", \"dtype_folder\", \"brnad\", \"dtype_folder2\", \"file\"]\n",
    "    )\n",
    "    raw_tss_dict = {key[\"file\"].split(\".\")[0]: bucket.read_parquet_df(key[\"key\"]) for _, key in keys.iterrows()}\n",
    "    raw_tss = pd.concat(\n",
    "        raw_tss_dict,\n",
    "        axis=\"index\",\n",
    "        keys=raw_tss_dict.keys(),\n",
    "        names=[\"vin\", \"idx\"]\n",
    "    )\n",
    "    return raw_tss\n",
    "\n",
    "long_raw_tss = get_bmw_hm_raw_tss()\n",
    "\n",
    "long_raw_tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_raw_tss.count() / len(long_raw_tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the variables in the long_raw_tss, or rather the lack there of, it is pretty obvious that the direct pipeline is more appropriate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have a fair bit of missing values compared to the ones that we asked for in the direct data pipeline.  \n",
    "The \"High Mobility pipeline\" is even worse so we are already bettery off with the direct one.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

