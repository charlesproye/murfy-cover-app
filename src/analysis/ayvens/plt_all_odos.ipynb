{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime as DT\n",
    "from datetime import timedelta as TD\n",
    "from dateutil import parser\n",
    "\n",
    "from rich import print\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas import DataFrame as DF\n",
    "import plotly.express as px\n",
    "\n",
    "from core.s3_utils import S3_Bucket\n",
    "from jobs.base_jobs.job_interval import Jobinterval\n",
    "from core.constants import *\n",
    "from core.time_series_processing import preprocess_date, estimate_dummy_soh\n",
    "from jobs.high_mobility.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = S3_Bucket()\n",
    "keys = {}\n",
    "\n",
    "for brand in HM_HANDLED_BRANDS:\n",
    "    brand_keys = Series(bucket.list_keys(f\"processed_ts/{brand}/time_series/\"), dtype=\"string\")\n",
    "    if len(brand_keys) == 0:\n",
    "        print(f\"\"\"\n",
    "            No time series found in the 'processed_ts/{brand}/time_series)' folder.\n",
    "            No processed time series have been generated.\n",
    "        \"\"\")\n",
    "        continue\n",
    "    # Only retain .parquet files\n",
    "    brand_keys = brand_keys[brand_keys.str.endswith(\".parquet\")]\n",
    "    brand_keys = (\n",
    "        pd.concat((brand_keys, brand_keys.str.split(\"/\", expand=True).loc[:, 1:]), axis=\"columns\")\n",
    "        .rename(columns={0:\"key\", 3:\"vin\"})\n",
    "        .loc[:, [\"key\", \"vin\"]]\n",
    "        .assign(vin=lambda df: df[\"vin\"].str.split(\".\", expand=True).iloc[:, 0])\n",
    "    )\n",
    "    keys[brand] = brand_keys\n",
    "\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_odo_dict = {}\n",
    "for brand, brand_keys in keys.items(): \n",
    "    brand_max_odos:Series = brand_keys[\"key\"].apply(lambda key: bucket.read_parquet_df(key)[\"odometer\"].max())\n",
    "    max_odo_dict[brand] = brand_max_odos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_odos = pd.concat(max_odo_dict, keys=max_odo_dict.keys(), names=[\"brand\"]).reset_index(0, drop=False).rename(columns={\"key\": \"odometer\"})\n",
    "max_odos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(max_odos, color=\"brand\", opacity=0.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

