{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoH estimation\n",
    "The goal of this notebook is to estimate show all the SoH estimation steps of the tesla vehicles.  \n",
    "This notebooks should always represent the latest version of the SoH estimation that is in `transform.raw_results.tesla_results`.  \n",
    "If the current method gets deprecated because of a refactor/fundamental change please copy paste this notebook into the legacy folder and explain why it got deprecated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook will get completed in issue DATAEV-279"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import plotly.express as px\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from core.pandas_utils import *\n",
    "from core.caching_utils import cache_result\n",
    "from core.ev_models_info import models_info\n",
    "from core.stats_utils import lr_params_as_series\n",
    "from core.plt_utils import plt_3d_df\n",
    "from transform.fleet_info.main import fleet_info\n",
    "from transform.processed_tss.ProcessedTimeSeries import TeslaProcessedTimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw estimation\n",
    "Tesla provides an charge_ernergy_added varaible that represents the cumulative energy added to the battery during a charge.  \n",
    "We express the SoH as the ratio between the energy added and the capacity relative to the difference in SoC during a charge.   \n",
    "This means that we get an SoH estimation per charge.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify the columns that we will be using to avoid loading unnecessary columns.\n",
    "# Otherwise my computer tends to crash ;-)\n",
    "USE_COLS = [\n",
    "    \"vin\",\n",
    "    \"trimmed_in_charge_idx\",\n",
    "    \"trimmed_in_charge\",\n",
    "    \"charge_energy_added\",\n",
    "    \"soc\",\n",
    "    \"inside_temp\",\n",
    "    \"capacity\",\n",
    "    \"odometer\",\n",
    "    \"model\",\n",
    "    \"date\",\n",
    "    \"tesla_code\",\n",
    "    \"battery_heater\",\n",
    "    \"charging_power\",\n",
    "    \"version\",\n",
    "]\n",
    "\n",
    "@cache_result(\"data_cache/tesla_results.parquet\", \"local_storage\")\n",
    "def get_raw_results() -> DF:\n",
    "    return (\n",
    "        TeslaProcessedTimeSeries(\"tesla\", columns=USE_COLS, filters=[(\"trimmed_in_charge\", \"==\", True)]) \n",
    "        .groupby([\"vin\", \"trimmed_in_charge_idx\"])                      # We group by vin and the index of the charge.\n",
    "        .agg(\n",
    "            # Instead of using the first charge_energy_added we use the minimum charge_energy_added.\n",
    "            # Ideally we would use the first charge_energy_added but the masking of the charges has some noise to it because sometimes there are big data gaps living to charges end to end without a discharge in between to seperate them.\n",
    "            # This means that the first charge_energy_added is not ALWAYS the actual charge_energy_added of the beggining of the charge.\n",
    "            # Sometimes we get some of the previous charge's points so we use the minimum charge_energy_added to counting them in.\n",
    "            # This is because the charge_energy_added is cumulative and the minimum charge_energy_added is the first charge_energy_added of the charge.\n",
    "            energy_added_min=pd.NamedAgg(\"charge_energy_added\", \"min\"), \n",
    "            energy_added_end=pd.NamedAgg(\"charge_energy_added\", \"last\"),\n",
    "            soc_end=pd.NamedAgg(\"soc\", \"last\"),\n",
    "            soc_min=pd.NamedAgg(\"soc\", \"min\"),\n",
    "            #soc_diff=pd.NamedAgg(\"soc\", series_start_end_diff),\n",
    "            inside_temp=pd.NamedAgg(\"inside_temp\", \"mean\"),\n",
    "            capacity=pd.NamedAgg(\"capacity\", \"first\"),\n",
    "            odometer=pd.NamedAgg(\"odometer\", \"first\"),\n",
    "            version=pd.NamedAgg(\"version\", \"first\"),\n",
    "            size=pd.NamedAgg(\"soc\", \"size\"),\n",
    "            model=pd.NamedAgg(\"model\", \"first\"),\n",
    "            date=pd.NamedAgg(\"date\", \"first\"),\n",
    "            charging_power=pd.NamedAgg(\"charging_power\", \"median\"),\n",
    "            tesla_code=pd.NamedAgg(\"tesla_code\", \"first\"),\n",
    "        )\n",
    "        .reset_index(drop=False)\n",
    "        .eval(\"energy_added = energy_added_end - energy_added_min\")\n",
    "        .eval(\"soc_diff = soc_end - soc_min\")\n",
    "        .eval(\"soh = energy_added / (soc_diff / 100.0 * capacity)\")\n",
    "        #.query(\"soc_diff > 40 & soh.between(0.75, 1.05)\")\n",
    "\t    #.eval(\"bottom_soh = soh.between(0.75, 0.9)\")\n",
    "        #.eval(\"fixed_soh_min_end = soh.mask(tesla_code == 'MTY13', soh / 0.96)\")\n",
    "        #.eval(\"fixed_soh_min_end = fixed_soh_min_end.mask(bottom_soh & tesla_code == 'MTY13', fixed_soh_min_end + 0.08)\")\n",
    "        .sort_values([\"tesla_code\", \"vin\", \"date\"])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_raw_results(force_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.scatter(\n",
    "#    results,\n",
    "#    x=\"odometer\",\n",
    "#    y=\"soh\",\n",
    "#    color=\"tesla_code\",\n",
    "#    #color_discrete_sequence=\"Rainbow\",\n",
    "#    opacity=0.25,\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the simplest SoH estimation is very noisy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing SoH variance by filtering results with low soc diff.\n",
    "As for any dataset, the values have some noise to them when we use divisions the noise is amplified the lower the values are.  \n",
    "We can reduce the noise by filtering the results with low soc diff.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soh_std_over_soc_diff:DF = (\n",
    "    results\n",
    "    .assign(soh_mean=results.groupby(\"vin\")[\"soh\"].transform(\"mean\"))\n",
    "    .assign(soh_median=results.groupby(\"vin\")[\"soh\"].transform(\"median\"))\n",
    "    .eval(\"soh_to_mean = soh - soh_mean\")\n",
    "    .eval(\"soh_to_median = soh - soh_median\")\n",
    "    .assign(soh_to_mean_abs=lambda df: df[\"soh_to_mean\"].abs())\n",
    "    .assign(soh_to_median_abs=lambda df: df[\"soh_to_median\"].abs())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    soh_std_over_soc_diff,\n",
    "    x=\"soc_diff\",\n",
    "    y=\"soh_to_mean_abs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, per vehicle, the absolute between an SoH point and the overall vehicle SoH median decreases until ~40% soc_diff, after that it doesn't change much.  \n",
    "So this is the minimum soc_diff that we will use as to filter SoH points.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.query(\"soc_diff > 40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the chemistry of the battery of the vehicles.  \n",
    "This extra imformatoion allows us to perform statistical description (and hopefully inference) on the SoH of the vehicles relative to the chemistry.  \n",
    "Ultimately this information will be pulled from the DB, for now we will do it \"manually\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TESLA_CODES = [\n",
    "    \"MT351\",\n",
    "    \"MT336\",\n",
    "    \"MT322\",\n",
    "]\n",
    "NCA_TESLA_CODES = [\n",
    "    \"MT353\",\n",
    "    \"MT308\", #BAttery: BT35\n",
    "]\n",
    "NMC_TESLA_CODES = [\n",
    "    \"MTY09\",\n",
    "    \"MTY12\", # BAttery: BT43\n",
    "    \"MT353\", # BAttery: BT43\n",
    "]\n",
    "raw_results = (\n",
    "    get_raw_results()\n",
    "    .eval(\"LFP = tesla_code in @LFP_TESLA_CODES\")\n",
    "    .eval(\"NCA = tesla_code in @NCA_TESLA_CODES\")\n",
    "    .eval(\"NMC = tesla_code in @NMC_TESLA_CODES\")\n",
    "    .sort_values([\"tesla_code\", \"vin\"])\n",
    ")\n",
    "raw_results[\"chemistry\"] = raw_results[[\"LFP\",\"NCA\",\"NMC\",]].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing SoH over odometer by vin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_vin = (\n",
    "    raw_results\n",
    "    .groupby(\"vin\")\n",
    "    .agg({\"odometer\": \"last\", \"soh\": \"median\", \"tesla_code\": \"first\", \"chemistry\": \"first\"})\n",
    "    .reset_index()\n",
    "    .sort_values([\"tesla_code\", \"vin\"])\n",
    ")\n",
    "results_by_vin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    (\n",
    "        results_by_vin\n",
    "        .dropna(subset=[\"fixed_soh_min_end\", \"odometer\", \"tesla_code\"])\n",
    "    ),\n",
    "    x=\"odometer\",\n",
    "    y=\"fixed_soh_min_end\",\n",
    "    color=\"tesla_code\",\n",
    "    color_continuous_scale=\"Rainbow\",\n",
    "    #trendline=\"ols\",\n",
    "    opacity=0.25,\n",
    "    title=\"SoH(State of Health) over odometer for 12589 Tesla vehicles\",\n",
    "    labels={\n",
    "        \"odometer\": \"Odometer (km)\",\n",
    "        \"fixed_soh_min_end\": \"SoH (State of Health)\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    (\n",
    "        results_by_vin\n",
    "        .dropna(subset=[\"fixed_soh_min_end\", \"odometer\", \"tesla_code\"])\n",
    "    ),\n",
    "    x=\"odometer\",\n",
    "    y=\"fixed_soh_min_end\",\n",
    "    color=\"chemistry\",\n",
    "    color_continuous_scale=\"Rainbow\",\n",
    "    #trendline=\"ols\",\n",
    "    opacity=0.4,\n",
    "    title=\"SoH(State of Health) over odometer for 12589 Tesla vehicles\",\n",
    "    labels={\n",
    "        \"odometer\": \"Odometer (km)\",\n",
    "        \"fixed_soh_min_end\": \"SoH (State of Health)\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the filtered dataset\n",
    "filtered_data = (\n",
    "    results_by_vin\n",
    "    .dropna(subset=[\"fixed_soh_min_end\", \"odometer\", \"tesla_code\", \"chemistry\"], how=\"any\")\n",
    "    .query(\"(tesla_code in @LFP_TESLA_CODES | tesla_code in @NCA_TESLA_CODES | tesla_code in @NMC_TESLA_CODES)\")\n",
    "    .query(\"fixed_soh_min_end.between(0.9, 1.05)\")\n",
    "    .sort_values(\"odometer\")\n",
    ")\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the SoH over odometer with logarithmic trendlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base scatter plot\n",
    "fig = px.scatter(\n",
    "    filtered_data,\n",
    "    x=\"odometer\",\n",
    "    y=\"fixed_soh_min_end\",\n",
    "    color=\"chemistry\",\n",
    "    color_continuous_scale=\"Rainbow\",\n",
    "    opacity=0.25,\n",
    "    hover_data=[\"tesla_code\"],\n",
    "    title=\"SoH(State of Health) over odometer for 4975 Tesla vehicles\",\n",
    "    labels={\n",
    "        \"odometer\": \"Odometer (km)\",\n",
    "        \"fixed_soh_min_end\": \"SoH (State of Health)\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Define logarithmic function that passes through (0,1)\n",
    "def log_func(x, a):\n",
    "    return 1 + a * np.log1p(x/1000)  # Using log1p for numerical stability\n",
    "\n",
    "# Add trendlines for each chemistry type\n",
    "for chemistry in filtered_data['chemistry'].unique():\n",
    "    chemistry_data = filtered_data[filtered_data['chemistry'] == chemistry].copy()\n",
    "    \n",
    "    # Add the (0,1) point to force trendlines through it\n",
    "    chemistry_data = pd.concat([\n",
    "        pd.DataFrame({'odometer': [0], 'fixed_soh_min_end': [1.0]}),\n",
    "        chemistry_data\n",
    "    ]).sort_values('odometer')\n",
    "    \n",
    "    # Ensure data is clean for trendline calculation\n",
    "    chemistry_data = chemistry_data.dropna(subset=['odometer', 'fixed_soh_min_end'])\n",
    "    \n",
    "    # Fixed maximum x value for all trendlines\n",
    "    MAX_ODOMETER = 250000\n",
    "\n",
    "    if len(chemistry_data) > 0:\n",
    "\n",
    "        try:\n",
    "            x_data = chemistry_data['odometer'].values\n",
    "            y_data = chemistry_data['fixed_soh_min_end'].values\n",
    "            \n",
    "            # Fit logarithmic curve\n",
    "            popt, _ = curve_fit(log_func, x_data, y_data, p0=[-0.01])\n",
    "            \n",
    "            # Generate smooth curve\n",
    "            x_smooth = np.linspace(0, MAX_ODOMETER, 100)\n",
    "            y_smooth = log_func(x_smooth, *popt)\n",
    "            \n",
    "            # Add to plot\n",
    "            fig.add_trace({\n",
    "                'x': x_smooth,\n",
    "                'y': y_smooth,\n",
    "                'name': f\"{chemistry} (Log)\",\n",
    "                'mode': 'lines',\n",
    "                'showlegend': True\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not add logarithmic trendline for {chemistry}: {str(e)}\")\n",
    "\n",
    "# Update layout to ensure y-axis starts at appropriate value\n",
    "fig.update_layout(\n",
    "    yaxis_range=[0.85, 1.05]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    filtered_data,\n",
    "    x=\"odometer\",\n",
    "    y=\"fixed_soh_min_end\",\n",
    "    color=\"chemistry\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Set1,\n",
    "    opacity=0.25,\n",
    "    title=\"SoH(State of Health) over odometer for 4975 Tesla vehicles\",\n",
    "    labels={\n",
    "        \"odometer\": \"Odometer (km)\",\n",
    "        \"fixed_soh_min_end\": \"SoH (State of Health)\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Get color mapping from the created figure\n",
    "color_map = {trace.name: trace.marker.color for trace in fig.data}\n",
    "\n",
    "# Define logarithmic function that passes through (0,1)\n",
    "def log_func(x, a):\n",
    "    return 1 + a * np.log1p(x / 1000)\n",
    "\n",
    "# Constants for the trendlines\n",
    "LOG_THRESHOLD = 50000  # Transition point\n",
    "MAX_ODOMETER = 250000\n",
    "TRANSITION_WINDOW = 20000  # Points for a smooth transition\n",
    "\n",
    "# Iterate for each chemistry type in the data\n",
    "for chemistry in filtered_data[\"chemistry\"].unique():\n",
    "    chemistry_data = filtered_data[filtered_data[\"chemistry\"] == chemistry].copy()\n",
    "    \n",
    "    # Add the (0, 1) point\n",
    "    chemistry_data = pd.concat(\n",
    "        [pd.DataFrame({\"odometer\": [0], \"fixed_soh_min_end\": [1.0]}), chemistry_data]\n",
    "    ).sort_values(\"odometer\")\n",
    "    \n",
    "    chemistry_data = chemistry_data.dropna(subset=[\"odometer\", \"fixed_soh_min_end\"])\n",
    "    \n",
    "    if len(chemistry_data) > 0:\n",
    "        try:\n",
    "            # Fit the logarithmic curve\n",
    "            x_data = chemistry_data[\"odometer\"].values\n",
    "            y_data = chemistry_data[\"fixed_soh_min_end\"].values\n",
    "            popt, _ = curve_fit(log_func, x_data, y_data, p0=[-0.01])\n",
    "            \n",
    "            # Generate logarithmic part\n",
    "            x_log = np.linspace(0, LOG_THRESHOLD, 100)\n",
    "            y_log = log_func(x_log, *popt)\n",
    "            \n",
    "            # Calculate slope at the end of the logarithmic curve\n",
    "            slope_log = popt[0] / (LOG_THRESHOLD + 1000)\n",
    "            \n",
    "            # Fit linear regression to data beyond transition\n",
    "            high_km_data = chemistry_data[\n",
    "                chemistry_data[\"odometer\"] >= LOG_THRESHOLD - TRANSITION_WINDOW / 2\n",
    "            ]\n",
    "            if len(high_km_data) > 0:\n",
    "                lr = LinearRegression()\n",
    "                lr.fit(\n",
    "                    high_km_data[\"odometer\"].values.reshape(-1, 1),\n",
    "                    high_km_data[\"fixed_soh_min_end\"].values,\n",
    "                )\n",
    "                linear_slope = lr.coef_[0]\n",
    "            else:\n",
    "                linear_slope = slope_log  # Use the log slope if no data\n",
    "            \n",
    "            # Adjust linear function to match the end of log curve\n",
    "            x_linear = np.linspace(LOG_THRESHOLD, MAX_ODOMETER, 100)\n",
    "            y_linear = y_log[-1] + slope_log * (x_linear - LOG_THRESHOLD)\n",
    "            \n",
    "            # Smooth transition between log and linear\n",
    "            x_trans = np.linspace(LOG_THRESHOLD - TRANSITION_WINDOW / 2, LOG_THRESHOLD, 50)\n",
    "            weight = np.linspace(0, 1, len(x_trans))\n",
    "            y_trans = (1 - weight) * log_func(x_trans, *popt) + weight * (\n",
    "                y_log[-1] + slope_log * (x_trans - LOG_THRESHOLD)\n",
    "            )\n",
    "            \n",
    "            # Combine all parts\n",
    "            x_combined = np.concatenate([x_log, x_trans, x_linear])\n",
    "            y_combined = np.concatenate([y_log, y_trans, y_linear])\n",
    "            \n",
    "            # Add trendline to the plot\n",
    "            fig.add_trace({\n",
    "                \"x\": x_combined,\n",
    "                \"y\": y_combined,\n",
    "                \"name\": f\"{chemistry} (Trend)\",\n",
    "                \"mode\": \"lines\",\n",
    "                \"line\": {\"color\": color_map[chemistry], \"width\": 2},\n",
    "                \"showlegend\": True\n",
    "            })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Could not add trendline for {chemistry}: {str(e)}\")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    yaxis_range=[0.85, 1.1],\n",
    "    xaxis_range=[0, MAX_ODOMETER]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

