{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {},
      "source": [
        "# Delay to get the first SoH\n",
        "We want to know how much time we have to wait before getting a SoH for a vin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296be494",
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.s3.s3_utils import S3Service\n",
        "from core.s3.settings import S3Settings\n",
        "from core.spark_utils import create_spark_session\n",
        "import plotly.express as px\n",
        "from core.stats_utils import *\n",
        "from core.sql_utils import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "\n",
        "settings = S3Settings()\n",
        "from transform.result_week.result_phase_to_result_week import ResultPhaseToResultWeek\n",
        "spark = create_spark_session(\n",
        "    settings.S3_KEY,\n",
        "    settings.S3_SECRET\n",
        ")\n",
        "\n",
        "s3 = S3Service()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e07271b",
      "metadata": {},
      "outputs": [],
      "source": [
        "oem = \"renault\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3",
      "metadata": {},
      "outputs": [],
      "source": [
        "phases = s3.read_parquet_df_spark(spark, f\"result_phases/result_phases_{oem}.parquet\").toPandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5",
      "metadata": {},
      "outputs": [],
      "source": [
        "with get_connection() as con:\n",
        "    cursor = con.cursor()\n",
        "    cursor.execute(\"\"\"SELECT v.vin as VIN, m.make_name as MAKE, vm.model_name as MODEL, vd.soh as SOH_prod, vd.timestamp, vd.cycles, b.net_capacity  FROM vehicle_data vd \n",
        "                   left JOIN vehicle v on v.id = vd.vehicle_id\n",
        "                    left JOIN vehicle_model vm\n",
        "                    ON v.vehicle_model_id = vm.id\n",
        "                    left JOIN make m on m.id = vm.make_id\n",
        "                    left JOIN battery b on b.id = vm.battery_id\"\"\")\n",
        "    dbeaver_df = cursor.fetchall()\n",
        "dbeaver_df = pd.DataFrame(dbeaver_df, columns=[desc[0] for desc in cursor.description])\n",
        "\n",
        "dbeaver_df['soh_prod'] = dbeaver_df['soh_prod'].astype(float)\n",
        "dbeaver_df['soh_prod'] = np.where(dbeaver_df['soh_prod'] > 1, 1, dbeaver_df['soh_prod'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "415a6e93",
      "metadata": {},
      "outputs": [],
      "source": [
        "phases[\"DATE\"] = (\n",
        "            pd.to_datetime(phases[\"DATETIME_BEGIN\"], format=\"mixed\")\n",
        "            .dt.floor(pd.Timedelta(days=7))\n",
        "            .dt.tz_localize(None)\n",
        "            .dt.date.astype(\"datetime64[ns]\")\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb677604",
      "metadata": {},
      "source": [
        "## 1. Pipeline de production SoH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae6bcf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "a = ResultPhaseToResultWeek(\"renault\", spark= None, has_soh= True, has_soh_oem=False,has_levels = False,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1e19616",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prod_soh(df):\n",
        "    phases_no_inf = a._replace_inf_soh(df)\n",
        "    from transform.result_week.config import SOH_FILTER_EVAL_STRINGS\n",
        "    phases_reame = phases_no_inf.eval(SOH_FILTER_EVAL_STRINGS[\"renault\"])\n",
        "    phases_freq = a._agg_results_by_update_frequency(phases_reame)\n",
        "\n",
        "    prod = phases_freq.groupby(\"VIN\", observed=True).apply(a._make_soh_presentable_per_vehicle, include_groups=False).reset_index()\n",
        "    prod[\"SOH\"] = np.where(prod[\"SOH\"] > 1, 1, prod[\"SOH\"])\n",
        "    return prod\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a48758a8",
      "metadata": {},
      "source": [
        "## 2. Analyse en fonction du temps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe96c247",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "all_results_list = []\n",
        "\n",
        "unique_vins = phases['VIN'].unique()\n",
        "\n",
        "for vin in unique_vins:\n",
        "    print(f\"Traitement du VIN: {vin}\")\n",
        "    \n",
        "    # Filtrer les données pour ce VIN\n",
        "    vin_test = phases[phases['VIN'] == vin].copy()\n",
        "    \n",
        "    if len(vin_test) == 0:\n",
        "        continue\n",
        "    \n",
        "    # Calculer la première date pour ce VIN\n",
        "    first_date = vin_test['DATE'].min()\n",
        "    \n",
        "    # Calculer le nombre de périodes pour ce VIN depuis dbeaver_df\n",
        "    nbr_periods = dbeaver_df[dbeaver_df['vin'] == vin].shape[0]\n",
        "    \n",
        "    if nbr_periods == 0:\n",
        "        continue\n",
        "    \n",
        "    # Créer les périodes\n",
        "    periods = {i: 7*i for i in range(1, nbr_periods+1)}\n",
        "    \n",
        "    # Créer les filtres spécifiques pour ce VIN\n",
        "    filters_specific_list = []\n",
        "    prev_days = 0\n",
        "    \n",
        "    for period_name, days in periods.items():\n",
        "        period_df = vin_test[\n",
        "            (vin_test['DATE'] >= first_date + pd.Timedelta(days=prev_days)) & \n",
        "            (vin_test['DATE'] < first_date + pd.Timedelta(days=days))\n",
        "        ].copy()\n",
        "        period_df['period'] = period_name\n",
        "        filters_specific_list.append(period_df)\n",
        "        prev_days = days\n",
        "    \n",
        "    if len(filters_specific_list) == 0:\n",
        "        continue\n",
        "    \n",
        "    filters_specific = pd.concat(filters_specific_list, ignore_index=True)\n",
        "    \n",
        "    # Créer les groupes de périodes\n",
        "    group = {f'{i}_semaines': list(range(1, i+1)) for i in range(1, nbr_periods+1)}\n",
        "    \n",
        "    # Calculer les rolling mean SOH pour chaque groupe\n",
        "    for group_name, group_values in group.items():\n",
        "        # Filtrer les données pour ce groupe de périodes\n",
        "        filtered_data = filters_specific[filters_specific['period'].isin(group_values)].copy()\n",
        "        \n",
        "        if len(filtered_data) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Calculer prod_soh sur les données filtrées\n",
        "        prod_result = prod_soh(filtered_data)\n",
        "        \n",
        "        # Extraire seulement la colonne SOH et faire un merge sur DATE et VIN\n",
        "        soh_series = prod_result.set_index(['DATE', 'VIN'])['SOH']\n",
        "        \n",
        "        filters_specific = filters_specific.set_index(['DATE', 'VIN'])\n",
        "        filters_specific[f\"{group_name}_rolling_mean_soh\"] = soh_series\n",
        "        filters_specific = filters_specific.reset_index()\n",
        "    \n",
        "    # Ajouter les résultats de ce VIN à la liste\n",
        "    all_results_list.append(filters_specific)\n",
        "\n",
        "# Concaténer tous les résultats\n",
        "filters_specific_all_vins = pd.concat(all_results_list, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d6d58f9",
      "metadata": {},
      "source": [
        "### 2.1. Évaluation des erreurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f42c65ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = filters_specific_all_vins.merge(\n",
        "    dbeaver_df, \n",
        "    left_on=[\"DATE\", \"VIN\"], \n",
        "    right_on=['timestamp', 'vin'], \n",
        "    how=\"left\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15bc7201",
      "metadata": {},
      "outputs": [],
      "source": [
        "result_comparison = result[['VIN', 'DATE', 'period', 'soh_prod'] + [col for col in filters_specific_all_vins.columns if 'rolling_mean_soh' in col]].copy()\n",
        "semaines_cols = [f\"{i}_semaines_rolling_mean_soh\" for i in range(1, result_comparison.shape[1] - 3)]\n",
        "for col in semaines_cols:\n",
        "    result_comparison[f\"{col}_diff_abs\"] = abs(result_comparison[\"soh_prod\"] - result_comparison[col])\n",
        "    result_comparison[f\"{col}_diff_pct\"] = abs((result_comparison[\"soh_prod\"] - result_comparison[col]) / result_comparison[\"soh_prod\"] * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62be1342",
      "metadata": {},
      "outputs": [],
      "source": [
        "result_comparison = result_comparison.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f89a54",
      "metadata": {},
      "outputs": [],
      "source": [
        "diff_abs_cols = [col for col in result_comparison.columns if col.endswith('_semaines_rolling_mean_soh_diff_abs')]\n",
        "error_stats = []\n",
        "for col in diff_abs_cols:\n",
        "    match = re.search(r'(\\d+)_semaines_rolling_mean_soh_diff_abs', col)\n",
        "    if match:\n",
        "        n_semaines = int(match.group(1))\n",
        "        valid_data = result_comparison[col].dropna()\n",
        "        if len(valid_data) > 0:\n",
        "            error_stats.append({\n",
        "                'Nombre_semaines': n_semaines,\n",
        "                'Erreur_moyenne': valid_data.mean(),\n",
        "                'Erreur_mediane': valid_data.median(),\n",
        "                'Erreur_std': valid_data.std(),\n",
        "                'Erreur_q25': valid_data.quantile(0.25),\n",
        "                'Erreur_q75': valid_data.quantile(0.75),\n",
        "                'Erreur_max': valid_data.max(),\n",
        "                'Nombre_observations': len(valid_data),\n",
        "                'Nombre_VINs': result_comparison[result_comparison[col].notna()]['VIN'].nunique()\n",
        "            })\n",
        "\n",
        "error_df = pd.DataFrame(error_stats).sort_values('Nombre_semaines')\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_df['Nombre_semaines'],\n",
        "    y=error_df['Erreur_q75'],\n",
        "    mode='lines',\n",
        "    line=dict(width=0),\n",
        "    showlegend=False,\n",
        "    hovertemplate='Q75: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_df['Nombre_semaines'],\n",
        "    y=error_df['Erreur_q25'],\n",
        "    mode='lines',\n",
        "    line=dict(width=0),\n",
        "    fillcolor='rgba(255, 0, 0, 0.2)',\n",
        "    fill='tonexty',\n",
        "    name='Intervalle interquartile (Q25-Q75)',\n",
        "    hovertemplate='Q25: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "# Moyenne ± 2 écarts-types\n",
        "if 'Erreur_std' in error_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_df['Nombre_semaines'],\n",
        "        y=error_df['Erreur_moyenne'] + 2 * error_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        showlegend=False,\n",
        "        hovertemplate='Moyenne + 2σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_df['Nombre_semaines'],\n",
        "        y=error_df['Erreur_moyenne'] - 2 * error_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        fillcolor='rgba(0, 0, 255, 0.15)',\n",
        "        fill='tonexty',\n",
        "        name='Moyenne ± 2 écarts-types',\n",
        "        hovertemplate='Moyenne - 2σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "# Ligne principale avec l'erreur moyenne\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_df['Nombre_semaines'],\n",
        "    y=error_df['Erreur_moyenne'],\n",
        "    mode='lines+markers',\n",
        "    name='Erreur moyenne',\n",
        "    line=dict(color='blue', width=3),\n",
        "    marker=dict(size=10),\n",
        "    hovertemplate='<b>%{x} semaines</b><br>Erreur moyenne: %{y:.4f}<br>Nombre d\\'observations: %{customdata[0]}<br>Nombre de VINs: %{customdata[1]}<extra></extra>',\n",
        "    customdata=error_df[['Nombre_observations', 'Nombre_VINs']].values\n",
        "))\n",
        "\n",
        "# Ligne avec l'erreur maximale\n",
        "if 'Erreur_max' in error_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_df['Nombre_semaines'],\n",
        "        y=error_df['Erreur_max'],\n",
        "        mode='markers',\n",
        "        name='Erreur maximale',\n",
        "        marker=dict(symbol='triangle-up', size=10, color='orange'),\n",
        "        hovertemplate='<b>%{x} semaines</b><br>Erreur maximale: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Erreur moyenne en fonction du nombre de semaines de suivi (tous les VINs)',\n",
        "    xaxis_title='Nombre de semaines',\n",
        "    yaxis_title='Erreur absolue moyenne',\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Afficher le tableau récapitulatif\n",
        "print(\"\\nTableau récapitulatif de l'erreur moyenne par nombre de semaines (tous les VINs):\")\n",
        "display(error_df.round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595c07a4",
      "metadata": {},
      "source": [
        "### 2.3 Identification des outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6909be",
      "metadata": {},
      "outputs": [],
      "source": [
        "diff_abs_cols = [col for col in result_comparison.columns if col.endswith('_semaines_rolling_mean_soh_diff_abs')]\n",
        "seuil_erreur = 0.1\n",
        "vins_avec_erreur = []\n",
        "\n",
        "for vin in result_comparison['VIN'].unique():\n",
        "    vin_data = result_comparison[result_comparison['VIN'] == vin].copy()\n",
        "    \n",
        "    erreurs_sup_seuil = []\n",
        "    erreur_max = 0\n",
        "    nb_semaines_avec_erreur = 0\n",
        "    \n",
        "    for col in diff_abs_cols:\n",
        "        match = re.search(r'(\\d+)_semaines_rolling_mean_soh_diff_abs', col)\n",
        "        if match:\n",
        "            n_semaines = int(match.group(1))\n",
        "            # Récupérer l'erreur maximale pour ce VIN et ce nombre de semaines\n",
        "            erreur_max_col = vin_data[col].max()\n",
        "            \n",
        "            if pd.notna(erreur_max_col) and erreur_max_col > seuil_erreur:\n",
        "                erreurs_sup_seuil.append({\n",
        "                    'Nombre_semaines': n_semaines,\n",
        "                    'Erreur_max': erreur_max_col,\n",
        "                    'Date': vin_data.loc[vin_data[col].idxmax(), 'DATE'] if vin_data[col].notna().any() else None\n",
        "                })\n",
        "                nb_semaines_avec_erreur += 1\n",
        "                erreur_max = max(erreur_max, erreur_max_col)\n",
        "    \n",
        "    # Si ce VIN a au moins une erreur supérieure au seuil\n",
        "    if erreurs_sup_seuil:\n",
        "        vins_avec_erreur.append({\n",
        "            'VIN': vin,\n",
        "            'Erreur_maximale': erreur_max,\n",
        "            'Nombre_semaines_avec_erreur': nb_semaines_avec_erreur,\n",
        "            'Details': erreurs_sup_seuil\n",
        "        })\n",
        "\n",
        "# Créer un DataFrame avec les VINs problématiques\n",
        "if vins_avec_erreur:\n",
        "    vins_problematiques_df = pd.DataFrame([\n",
        "        {\n",
        "            'VIN': item['VIN'],\n",
        "            'Erreur_maximale': item['Erreur_maximale'],\n",
        "            'Nombre_semaines_avec_erreur': item['Nombre_semaines_avec_erreur']\n",
        "        }\n",
        "        for item in vins_avec_erreur\n",
        "    ]).sort_values('Erreur_maximale', ascending=False)\n",
        "    \n",
        "vins_problematiques_df = vins_problematiques_df.round(4)\n",
        "vins_problematiques_df.sort_values(\"Nombre_semaines_avec_erreur\", ascending = False)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf48388",
      "metadata": {},
      "source": [
        "**Note :** Il y a des SoH calculés qui sont des \"erreurs\".  \n",
        "Exemple : `VF1AG000765232752` à 5_semaines -> soh_min = 20.59 % et uniquement 2 SoH sur cette période."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44ad864a",
      "metadata": {},
      "source": [
        "### 2.4 Analyse sur un VIN spécifique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3555059d",
      "metadata": {},
      "outputs": [],
      "source": [
        "vin = \"VF1AG000064548077\"\n",
        "vin_test = phases[phases[\"VIN\"] == vin].copy()\n",
        "#VF1AG000064548077\n",
        "#VF1AG000966427889"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb9aa20",
      "metadata": {},
      "outputs": [],
      "source": [
        "first_date = vin_test['DATE'].min()\n",
        "\n",
        "nbr_periods = dbeaver_df[dbeaver_df['vin'] == vin].shape[0]\n",
        "periods = {i: 7*i for i in range(1, nbr_periods+1)}\n",
        "\n",
        "filters_specific_list = []\n",
        "prev_days = 0\n",
        "for period_name, days in periods.items():\n",
        "    print(period_name, days)\n",
        "    period_df = vin_test[\n",
        "        (vin_test['DATE'] >= first_date + pd.Timedelta(days=prev_days)) & \n",
        "        (vin_test['DATE'] < first_date + pd.Timedelta(days=days))\n",
        "    ].copy()\n",
        "    period_df['period'] = period_name\n",
        "    filters_specific_list.append(period_df)\n",
        "    prev_days = days\n",
        "filters_specific_vin = pd.concat(filters_specific_list, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f4293c",
      "metadata": {},
      "outputs": [],
      "source": [
        "group = {f'{i}_semaines': list(range(1, i+1)) for i in range(1, nbr_periods+1)}\n",
        "\n",
        "\n",
        "for group_name, group_values in group.items():\n",
        "    # Filtrer les données pour ce groupe de périodes\n",
        "    filtered_data = filters_specific_vin[filters_specific_vin['period'].isin(group_values)].copy()\n",
        "    \n",
        "    # Calculer prod_soh sur les données filtrées\n",
        "    prod_result = prod_soh(filtered_data)\n",
        "    \n",
        "    # Extraire seulement la colonne SOH et faire un merge sur DATE et VIN\n",
        "    # Assurez-vous que les colonnes de jointure existent dans les deux DataFrames\n",
        "    soh_series = prod_result.set_index(['DATE', 'VIN'])['SOH']\n",
        "    # all_data_sorted[\"DATE\"] = (\n",
        "    #         pd.to_datetime(all_data_sorted[\"DATETIME_BEGIN\"], format=\"mixed\")\n",
        "    #         .dt.floor(pd.Timedelta(days=7))\n",
        "    #         .dt.tz_localize(None)\n",
        "    #         .dt.date.astype(\"datetime64[ns]\")\n",
        "    #     )\n",
        "\n",
        "    filters_specific_vin = filters_specific_vin.set_index(['DATE', 'VIN'])\n",
        "    filters_specific_vin[f\"{group_name}_rolling_mean_soh\"] = soh_series.round(3)\n",
        "    filters_specific_vin = filters_specific_vin.reset_index()\n",
        "\n",
        "\n",
        "columns_to_show = ['VIN', 'DATE', 'period'] + [col for col in filters_specific_vin.columns if 'rolling_mean_soh' in col]\n",
        "\n",
        "filters_specific_vin[columns_to_show].drop_duplicates().head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb7394c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "res = filters_specific_vin.merge(dbeaver_df, left_on = [\"DATE\", \"VIN\"], right_on = ['timestamp', 'vin'], how = \"left\")\n",
        "res_comparison = res[['VIN', 'DATE', 'period', 'soh_prod'] + [col for col in filters_specific_vin.columns if 'rolling_mean_soh' in col]]\n",
        "semaines_cols = [f\"{i}_semaines_rolling_mean_soh\" for i in range(1, res_comparison.shape[1] - 3)]\n",
        "res_comparison = res_comparison.drop_duplicates()\n",
        "for col in semaines_cols:\n",
        "    res_comparison[f\"{col}_diff_abs\"] = abs(res_comparison[\"soh_prod\"] - res_comparison[col])\n",
        "    res_comparison[f\"{col}_diff_pct\"] = abs((res_comparison[\"soh_prod\"] - res_comparison[col]) / res_comparison[\"soh_prod\"] * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd404269",
      "metadata": {},
      "outputs": [],
      "source": [
        "diff_abs_cols = [col for col in res_comparison.columns if col.endswith('_semaines_rolling_mean_soh_diff_abs')]\n",
        "\n",
        "error_stats = []\n",
        "for col in diff_abs_cols:\n",
        "    match = re.search(r'(\\d+)_semaines_rolling_mean_soh_diff_abs', col)\n",
        "    if match:\n",
        "        n_semaines = int(match.group(1))\n",
        "        \n",
        "        # Calculer l'erreur moyenne (en excluant les NaN)\n",
        "        valid_data = res_comparison[col].dropna()\n",
        "        if len(valid_data) > 0:\n",
        "            error_stats.append({\n",
        "                'Nombre_semaines': n_semaines,\n",
        "                'Erreur_moyenne': valid_data.mean(),\n",
        "                'Erreur_mediane': valid_data.median(),\n",
        "                'Erreur_std': valid_data.std(),\n",
        "                'Nombre_observations': len(valid_data)\n",
        "            })\n",
        "\n",
        "\n",
        "error_df = pd.DataFrame(error_stats).sort_values('Nombre_semaines')\n",
        "\n",
        "\n",
        "########### raphique\n",
        "fig = go.Figure()\n",
        "\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_df['Nombre_semaines'],\n",
        "    y=error_df['Erreur_moyenne'],\n",
        "    mode='lines+markers',\n",
        "    name='Erreur moyenne',\n",
        "    line=dict(color='blue', width=3),\n",
        "    marker=dict(size=10),\n",
        "    hovertemplate='<b>%{x} semaines</b><br>Erreur moyenne: %{y:.4f}<br>Nombre d\\'observations: %{customdata}<extra></extra>',\n",
        "    customdata=error_df['Nombre_observations']\n",
        "))\n",
        "\n",
        "\n",
        "if 'Erreur_std' in error_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_df['Nombre_semaines'],\n",
        "        y=error_df['Erreur_moyenne'] + error_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        showlegend=False,\n",
        "        hovertemplate='Moyenne + 1σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_df['Nombre_semaines'],\n",
        "        y=error_df['Erreur_moyenne'] - error_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        fillcolor='rgba(0, 0, 255, 0.2)',\n",
        "        fill='tonexty',\n",
        "        name='Moyenne ± 1 écart-type',\n",
        "        hovertemplate='Moyenne - 1σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Erreur moyenne en fonction du nombre de semaines de suivi',\n",
        "    xaxis_title='Nombre de semaines',\n",
        "    yaxis_title='Erreur absolue moyenne',\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Afficher le tableau récapitulatif\n",
        "\n",
        "error_df.round(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0abfd5",
      "metadata": {},
      "source": [
        "## 3. Analyse en fonction du nombre de phases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3caec8",
      "metadata": {},
      "outputs": [],
      "source": [
        "phases_with_cycles = pd.merge_asof(phases.sort_values(\"DATETIME_BEGIN\"), dbeaver_df.sort_values(\"timestamp\")[['vin', 'cycles', 'timestamp']], left_on = \"DATETIME_BEGIN\", right_on = \"timestamp\", left_by = \"VIN\", right_by = \"vin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e13b51",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_results_by_phases_list = []\n",
        "\n",
        "unique_vins = phases['VIN'].unique()\n",
        "\n",
        "# Seuils de phases à tester\n",
        "phase_thresholds = [1, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100]\n",
        "\n",
        "for vin in unique_vins:\n",
        "    print(f\"Traitement du VIN: {vin}\")\n",
        "    \n",
        "    # Filtrer les données pour ce VIN et trier par date\n",
        "    vin_temp = phases[phases['VIN'] == vin].sort_values('DATETIME_BEGIN').copy()\n",
        "    \n",
        "    if len(vin_temp) == 0:\n",
        "        continue\n",
        "    vin_prod_data = dbeaver_df[dbeaver_df['vin'] == vin].copy()\n",
        "    if len(vin_prod_data) == 0:\n",
        "        continue\n",
        "    for threshold in phase_thresholds:\n",
        "        if len(vin_temp) < threshold:\n",
        "            continue\n",
        "        \n",
        "        # Prendre les N premières phases\n",
        "        phases_subset = vin_temp.head(threshold).copy()\n",
        "        try:\n",
        "            prod_result = prod_soh(phases_subset)\n",
        "            \n",
        "            if len(prod_result) == 0:\n",
        "                continue\n",
        "            \n",
        "            # Pour chaque date où on a un SoH calculé, trouver le soh_prod le plus proche\n",
        "            for idx, row in prod_result.iterrows():\n",
        "                soh_calculated = row['SOH']\n",
        "                date_calculated = row['DATE']\n",
        "                \n",
        "                # Trouver le soh_prod le plus proche dans le temps (forward fill)\n",
        "                closest_prod = vin_prod_data[\n",
        "                    vin_prod_data['timestamp'] >= date_calculated\n",
        "                ].sort_values('timestamp') \n",
        "\n",
        "                if len(closest_prod) > 0:\n",
        "                    soh_prod = closest_prod.iloc[0]['soh_prod']\n",
        "                    \n",
        "                    all_results_by_phases_list.append({\n",
        "                        'VIN': vin,\n",
        "                        'Nombre_phases': threshold,\n",
        "                        'DATE': date_calculated,\n",
        "                        'SOH_calculated': soh_calculated,\n",
        "                        'SOH_prod': soh_prod,\n",
        "                        'Erreur_abs': abs(soh_prod - soh_calculated),\n",
        "                        'Erreur_pct': abs((soh_prod - soh_calculated) / soh_prod * 100) if soh_prod > 0 else None\n",
        "                    })\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur pour VIN {vin} avec {threshold} phases: {e}\")\n",
        "            continue\n",
        "\n",
        "# Créer le DataFrame avec tous les résultats\n",
        "results_by_phases_df = pd.DataFrame(all_results_by_phases_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48bc6ceb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer les statistiques d'erreur par nombre de phases\n",
        "error_stats_by_phases = []\n",
        "\n",
        "for threshold in phase_thresholds:\n",
        "    threshold_data = results_by_phases_df[results_by_phases_df['Nombre_phases'] == threshold]\n",
        "    \n",
        "    if len(threshold_data) == 0:\n",
        "        continue\n",
        "    \n",
        "    valid_errors = threshold_data['Erreur_abs'].dropna()\n",
        "    \n",
        "    if len(valid_errors) > 0:\n",
        "        error_stats_by_phases.append({\n",
        "            'Nombre_phases': threshold,\n",
        "            'Erreur_moyenne': valid_errors.mean(),\n",
        "            'Erreur_mediane': valid_errors.median(),\n",
        "            'Erreur_std': valid_errors.std(),\n",
        "            'Erreur_q25': valid_errors.quantile(0.25),\n",
        "            'Erreur_q75': valid_errors.quantile(0.75),\n",
        "            'Erreur_max': valid_errors.max(),\n",
        "            'Nombre_observations': len(valid_errors),\n",
        "            'Nombre_VINs': threshold_data['VIN'].nunique()\n",
        "        })\n",
        "\n",
        "error_by_phases_df = pd.DataFrame(error_stats_by_phases).sort_values('Nombre_phases')\n",
        "\n",
        "display(error_by_phases_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f101575",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique de l'erreur en fonction du nombre de phases\n",
        "fig = go.Figure()\n",
        "\n",
        "# Intervalle interquartile (Q25-Q75)\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_phases_df['Nombre_phases'],\n",
        "    y=error_by_phases_df['Erreur_q75'],\n",
        "    mode='lines',\n",
        "    line=dict(width=0),\n",
        "    showlegend=False,\n",
        "    hovertemplate='Q75: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_phases_df['Nombre_phases'],\n",
        "    y=error_by_phases_df['Erreur_q25'],\n",
        "    mode='lines',\n",
        "    line=dict(width=0),\n",
        "    fillcolor='rgba(255, 0, 0, 0.2)',\n",
        "    fill='tonexty',\n",
        "    name='Intervalle interquartile (Q25-Q75)',\n",
        "    hovertemplate='Q25: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "# Moyenne ± 2 écarts-types\n",
        "if 'Erreur_std' in error_by_phases_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_phases_df['Nombre_phases'],\n",
        "        y=error_by_phases_df['Erreur_moyenne'] + 2 * error_by_phases_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        showlegend=False,\n",
        "        hovertemplate='Moyenne + 2σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_phases_df['Nombre_phases'],\n",
        "        y=error_by_phases_df['Erreur_moyenne'] - 2 * error_by_phases_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        fillcolor='rgba(0, 0, 255, 0.15)',\n",
        "        fill='tonexty',\n",
        "        name='Moyenne ± 2 écarts-types',\n",
        "        hovertemplate='Moyenne - 2σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "# Ligne principale avec l'erreur moyenne\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_phases_df['Nombre_phases'],\n",
        "    y=error_by_phases_df['Erreur_moyenne'],\n",
        "    mode='lines+markers',\n",
        "    name='Erreur moyenne',\n",
        "    line=dict(color='blue', width=3),\n",
        "    marker=dict(size=10),\n",
        "    hovertemplate='<b>%{x} phases</b><br>Erreur moyenne: %{y:.4f}<br>Nombre d\\'observations: %{customdata[0]}<br>Nombre de VINs: %{customdata[1]}<extra></extra>',\n",
        "    customdata=error_by_phases_df[['Nombre_observations', 'Nombre_VINs']].values\n",
        "))\n",
        "\n",
        "# Ligne avec l'erreur maximale\n",
        "if 'Erreur_max' in error_by_phases_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_phases_df['Nombre_phases'],\n",
        "        y=error_by_phases_df['Erreur_max'],\n",
        "        mode='markers',\n",
        "        name='Erreur maximale',\n",
        "        marker=dict(symbol='triangle-up', size=10, color='orange'),\n",
        "        hovertemplate='<b>%{x} phases</b><br>Erreur maximale: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Erreur moyenne en fonction du nombre de phases avec SoH calculé (tous les VINs)',\n",
        "    xaxis_title='Nombre de phases',\n",
        "    yaxis_title='Erreur absolue moyenne',\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Afficher le tableau récapitulatif\n",
        "print(\"\\nTableau récapitulatif de l'erreur moyenne par nombre de phases (tous les VINs):\")\n",
        "display(error_by_phases_df.round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0988fb9b",
      "metadata": {},
      "source": [
        "## 4. Analyse en fonction du nombre de cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f5b31cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "phases['odometer_start_following'] =  phases.groupby('VIN')['ODOMETER_FIRST'].transform('first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea51e9c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_results_by_cycles_list = []\n",
        "\n",
        "unique_vins = phases['VIN'].unique()\n",
        "\n",
        "# Seuils de cycles à tester\n",
        "cycle_thresholds = [5, 10, 15, 20, 25, 30, 40, 50, 75, 100]\n",
        "\n",
        "for vin in unique_vins:\n",
        "    print(f\"Traitement du VIN: {vin}\")\n",
        "    \n",
        "    # Filtrer les données pour ce VIN et trier par date\n",
        "    vin_temp = phases[phases['VIN'] == vin].sort_values('DATETIME_BEGIN').copy()\n",
        "    \n",
        "    if len(vin_temp) == 0:\n",
        "        continue\n",
        "    \n",
        "    vin_prod_data = dbeaver_df[dbeaver_df['vin'] == vin].copy()\n",
        "    if len(vin_prod_data) == 0:\n",
        "        continue\n",
        "    \n",
        "    # Vérifier que les colonnes nécessaires existent\n",
        "    if 'ODOMETER_LAST' not in vin_temp.columns or 'RANGE' not in vin_temp.columns:\n",
        "        continue\n",
        "    \n",
        "    if 'odometer_start_following' not in vin_temp.columns:\n",
        "        continue\n",
        "    \n",
        "    # Calculer les cycles pour chaque phase en utilisant la différence entre ODOMETER_LAST et odometer_start_following\n",
        "    # Calculer la distance parcourue depuis le début du suivi\n",
        "    vin_temp['DISTANCE_FOLLOWING'] = vin_temp['ODOMETER_LAST'] - vin_temp['odometer_start_following']\n",
        "    \n",
        "    # Calculer les cycles estimés pour chaque phase\n",
        "    # Utiliser la même formule que estimate_cycles mais avec la distance parcourue depuis le début du suivi\n",
        "    if 'SOH' in vin_temp.columns:\n",
        "        vin_temp['ESTIMATED_CYCLES'] = vin_temp.apply(\n",
        "            lambda row: round(row['DISTANCE_FOLLOWING'] / (row['RANGE'] * (row['SOH'] + 1) / 2)) if pd.notna(row['DISTANCE_FOLLOWING']) and pd.notna(row['RANGE']) and pd.notna(row['SOH']) and row['RANGE'] > 0 else np.nan,\n",
        "            axis=1\n",
        "        )\n",
        "    else:\n",
        "        vin_temp['ESTIMATED_CYCLES'] = vin_temp.apply(\n",
        "            lambda row: round(row['DISTANCE_FOLLOWING'] / row['RANGE']) if pd.notna(row['DISTANCE_FOLLOWING']) and pd.notna(row['RANGE']) and row['RANGE'] > 0 else np.nan,\n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    for threshold in cycle_thresholds:\n",
        "        # Prendre toutes les phases où les cycles estimés sont <= au seuil\n",
        "        # (les cycles estimés augmentent avec l'odomètre, donc cela prend toutes les phases jusqu'à ce seuil)\n",
        "        phases_subset = vin_temp[vin_temp['ESTIMATED_CYCLES'] <= threshold].copy()\n",
        "        \n",
        "        if len(phases_subset) == 0:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            prod_result = prod_soh(phases_subset)\n",
        "            \n",
        "            if len(prod_result) == 0:\n",
        "                continue\n",
        "            \n",
        "            # Pour chaque date où on a un SoH calculé, trouver le soh_prod le plus proche\n",
        "            for idx, row in prod_result.iterrows():\n",
        "                soh_calculated = row['SOH']\n",
        "                date_calculated = row['DATE']\n",
        "                \n",
        "                # Trouver le soh_prod le plus proche dans le temps (forward fill)\n",
        "                closest_prod = vin_prod_data[\n",
        "                    vin_prod_data['timestamp'] >= date_calculated\n",
        "                ].sort_values('timestamp')\n",
        "                \n",
        "                if len(closest_prod) > 0:\n",
        "                    soh_prod = closest_prod.iloc[0]['soh_prod']\n",
        "                    \n",
        "                    all_results_by_cycles_list.append({\n",
        "                        'VIN': vin,\n",
        "                        'Nombre_cycles': threshold,\n",
        "                        'DATE': date_calculated,\n",
        "                        'SOH_calculated': soh_calculated,\n",
        "                        'SOH_prod': soh_prod,\n",
        "                        'Erreur_abs': abs(soh_prod - soh_calculated),\n",
        "                        'Erreur_pct': abs((soh_prod - soh_calculated) / soh_prod * 100) if soh_prod > 0 else None\n",
        "                    })\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur pour VIN {vin} avec {threshold} cycles: {e}\")\n",
        "            continue\n",
        "\n",
        "results_by_cycles_df = pd.DataFrame(all_results_by_cycles_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e96ae023",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer les statistiques d'erreur par nombre de cycles\n",
        "error_stats_by_cycles = []\n",
        "\n",
        "for threshold in cycle_thresholds:\n",
        "    threshold_data = results_by_cycles_df[results_by_cycles_df['Nombre_cycles'] == threshold]\n",
        "    \n",
        "    if len(threshold_data) == 0:\n",
        "        continue\n",
        "    \n",
        "    valid_errors = threshold_data['Erreur_abs'].dropna()\n",
        "    \n",
        "    if len(valid_errors) > 0:\n",
        "        error_stats_by_cycles.append({\n",
        "            'Nombre_cycles': threshold,\n",
        "            'Erreur_moyenne': valid_errors.mean(),\n",
        "            'Erreur_mediane': valid_errors.median(),\n",
        "            'Erreur_std': valid_errors.std(),\n",
        "            'Erreur_q25': valid_errors.quantile(0.25),\n",
        "            'Erreur_q75': valid_errors.quantile(0.75),\n",
        "            'Erreur_max': valid_errors.max(),\n",
        "            'Nombre_observations': len(valid_errors),\n",
        "            'Nombre_VINs': threshold_data['VIN'].nunique()\n",
        "        })\n",
        "\n",
        "error_by_cycles_df = pd.DataFrame(error_stats_by_cycles).sort_values('Nombre_cycles')\n",
        "\n",
        "display(error_by_cycles_df.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ba2811",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique de l'erreur en fonction du nombre de cycles\n",
        "fig = go.Figure()\n",
        "\n",
        "# Intervalle interquartile (Q25-Q75)\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_cycles_df['Nombre_cycles'],\n",
        "    y=error_by_cycles_df['Erreur_q75'],\n",
        "    mode='lines',\n",
        "    line=dict(width=0),\n",
        "    showlegend=False,\n",
        "    hovertemplate='Q75: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_cycles_df['Nombre_cycles'],\n",
        "    y=error_by_cycles_df['Erreur_q25'],\n",
        "    mode='lines',\n",
        "    line=dict(width=0),\n",
        "    fillcolor='rgba(255, 0, 0, 0.2)',\n",
        "    fill='tonexty',\n",
        "    name='Intervalle interquartile (Q25-Q75)',\n",
        "    hovertemplate='Q25: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "# Moyenne ± 2 écarts-types\n",
        "if 'Erreur_std' in error_by_cycles_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_cycles_df['Nombre_cycles'],\n",
        "        y=error_by_cycles_df['Erreur_moyenne'] + 2 * error_by_cycles_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        showlegend=False,\n",
        "        hovertemplate='Moyenne + 2σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_cycles_df['Nombre_cycles'],\n",
        "        y=error_by_cycles_df['Erreur_moyenne'] - 2 * error_by_cycles_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        fillcolor='rgba(0, 0, 255, 0.15)',\n",
        "        fill='tonexty',\n",
        "        name='Moyenne ± 2 écarts-types',\n",
        "        hovertemplate='Moyenne - 2σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "# Ligne principale avec l'erreur moyenne\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_cycles_df['Nombre_cycles'],\n",
        "    y=error_by_cycles_df['Erreur_moyenne'],\n",
        "    mode='lines+markers',\n",
        "    name='Erreur moyenne',\n",
        "    line=dict(color='blue', width=3),\n",
        "    marker=dict(size=10),\n",
        "    hovertemplate='<b>%{x} cycles</b><br>Erreur moyenne: %{y:.4f}<br>Nombre d\\'observations: %{customdata[0]}<br>Nombre de VINs: %{customdata[1]}<extra></extra>',\n",
        "    customdata=error_by_cycles_df[['Nombre_observations', 'Nombre_VINs']].values\n",
        "))\n",
        "\n",
        "# Ligne avec l'erreur maximale\n",
        "if 'Erreur_max' in error_by_cycles_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_cycles_df['Nombre_cycles'],\n",
        "        y=error_by_cycles_df['Erreur_max'],\n",
        "        mode='markers',\n",
        "        name='Erreur maximale',\n",
        "        marker=dict(symbol='triangle-up', size=10, color='orange'),\n",
        "        hovertemplate='<b>%{x} cycles</b><br>Erreur maximale: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Erreur moyenne en fonction du nombre de cycles avec SoH calculé (tous les VINs)',\n",
        "    xaxis_title='Nombre de cycles',\n",
        "    yaxis_title='Erreur absolue moyenne',\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Afficher le tableau récapitulatif\n",
        "print(\"\\nTableau récapitulatif de l'erreur moyenne par nombre de cycles (tous les VINs):\")\n",
        "display(error_by_cycles_df.round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7439ea6",
      "metadata": {},
      "source": [
        "### Analyse en fonction du nombre de points"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0551a26b",
      "metadata": {},
      "source": [
        "Penser à commenter l'aggregation dans transform.processed_phases.raw_ts_to_processed_phases avant de lancer cette partie partie "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09e9e0d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transform.processed_phases.providers.renault import RenaultRawTsToProcessedPhases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4560e0bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "renault = RenaultRawTsToProcessedPhases(spark=spark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2588c3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_tss_pd = renault.run().toPandas()\n",
        "raw_tss_pd.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a1bdb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_tss_pd.rename(columns={'soh': 'SOH'}, inplace=True)\n",
        "raw_tss_pd['consumption'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9781b76a",
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_tss_pd['charging_rate'] = raw_tss_pd['charging_rate'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8dcea1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def aggregate_stats(phase_df):\n",
        "    \"\"\"\n",
        "    Version pandas de la fonction aggregate_stats.\n",
        "    Agrège les statistiques par phase en utilisant pandas au lieu de PySpark.\n",
        "    \"\"\"\n",
        "    # Définir les colonnes de groupement\n",
        "    groupby_cols = [\n",
        "        \"VIN\",\n",
        "        \"PHASE_INDEX\",\n",
        "        \"DATETIME_BEGIN\",\n",
        "        \"DATETIME_END\",\n",
        "        \"PHASE_STATUS\",\n",
        "        \"SOC_FIRST\",\n",
        "        \"SOC_LAST\",\n",
        "        \"SOC_DIFF\",\n",
        "        \"NO_SOC_DATAPOINT\",\n",
        "        \"IS_USABLE_PHASE\",\n",
        "    ]\n",
        "    \n",
        "    # Construire le dictionnaire d'agrégation avec pd.NamedAgg\n",
        "    agg_dict = {}\n",
        "    \n",
        "    # Colonnes avec first (ignore les nulls par défaut en pandas)\n",
        "    if \"make\" in phase_df.columns:\n",
        "        agg_dict[\"MAKE\"] = pd.NamedAgg(column=\"make\", aggfunc=\"first\")\n",
        "    if \"model\" in phase_df.columns:\n",
        "        agg_dict[\"MODEL\"] = pd.NamedAgg(column=\"model\", aggfunc=\"first\")\n",
        "    if \"version\" in phase_df.columns:\n",
        "        agg_dict[\"VERSION\"] = pd.NamedAgg(column=\"version\", aggfunc=\"first\")\n",
        "    if \"net_capacity\" in phase_df.columns:\n",
        "        agg_dict[\"BATTERY_NET_CAPACITY\"] = pd.NamedAgg(column=\"net_capacity\", aggfunc=\"first\")\n",
        "    if \"range\" in phase_df.columns:\n",
        "        agg_dict[\"RANGE\"] = pd.NamedAgg(column=\"range\", aggfunc=\"first\")\n",
        "    \n",
        "    # Odometer: first et last\n",
        "    if \"odometer\" in phase_df.columns:\n",
        "        agg_dict[\"ODOMETER_FIRST\"] = pd.NamedAgg(column=\"odometer\", aggfunc=\"first\")\n",
        "        agg_dict[\"ODOMETER_LAST\"] = pd.NamedAgg(column=\"odometer\", aggfunc=\"last\")\n",
        "    \n",
        "    # SOH: percentile_approx(soh, 0.5) -> quantile(0.5) ou median\n",
        "    if \"soh\" in phase_df.columns:\n",
        "        agg_dict[\"SOH\"] = pd.NamedAgg(column=\"soh\", aggfunc=lambda x: x.quantile(0.5))\n",
        "    \n",
        "    # Charging rate: mean\n",
        "    if \"charging_rate\" in phase_df.columns:\n",
        "        agg_dict[\"CHARGING_RATE\"] = pd.NamedAgg(column=\"charging_rate\", aggfunc=\"mean\")\n",
        "    \n",
        "    # Consumption: mean (si présent)\n",
        "    if \"consumption\" in phase_df.columns:\n",
        "        agg_dict[\"CONSUMPTION\"] = pd.NamedAgg(column=\"consumption\", aggfunc=\"mean\")\n",
        "    \n",
        "    agg_dict[\"SOH\"] = pd.NamedAgg(column=\"SOH\", aggfunc=\"median\")\n",
        "    \n",
        "    # Grouper et agréger\n",
        "    df_aggregated = phase_df.groupby(groupby_cols, observed=True).agg(**agg_dict).reset_index()\n",
        "    \n",
        "    return df_aggregated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83ac6770",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse en fonction du nombre de points de données raw_tss\n",
        "all_results_by_points_list = []\n",
        "\n",
        "unique_vins = raw_tss_pd['VIN'].unique()\n",
        "\n",
        "# Seuils de points à tester\n",
        "point_thresholds = [1, 10, 25, 50, 100, 200, 500]\n",
        "\n",
        "for vin in unique_vins:\n",
        "    \n",
        "    # Filtrer les données pour ce VIN et trier par date\n",
        "    vin_temp = raw_tss_pd[raw_tss_pd['VIN'] == vin].sort_values('date').copy()\n",
        "\n",
        "    \n",
        "    vin_prod_data = dbeaver_df[dbeaver_df['vin'] == vin].copy()\n",
        "    \n",
        "    \n",
        "    for threshold in point_thresholds:\n",
        "        print(threshold)\n",
        "        \n",
        "        # Prendre les N premiers points\n",
        "        points_subset = vin_temp.head(threshold).copy()\n",
        "        \n",
        "        # Filtrer les points avec un soh valide (non null et entre 0 et 1)\n",
        "        valid_soh_points = points_subset[\n",
        "            (points_subset['SOH'].notna()) & \n",
        "            (points_subset['SOH'] > 0) & \n",
        "            (points_subset['SOH'] <= 1)\n",
        "        ]\n",
        "        \n",
        "        if len(valid_soh_points) == 0:\n",
        "            continue\n",
        "        \n",
        "        phase_soh = aggregate_stats(valid_soh_points)\n",
        "        phase_soh['ODOMETER_DIFF'] = phase_soh['ODOMETER_LAST'] - phase_soh['ODOMETER_FIRST']\n",
        "        phase_prod = prod_soh(phase_soh)\n",
        "        # Utiliser la date du dernier point pour la comparaison\n",
        "        last_date = points_subset['date'].max()\n",
        "        \n",
        "        # Trouver le soh_prod le plus proche dans le temps (forward fill)\n",
        "        closest_prod = vin_prod_data[\n",
        "            vin_prod_data['timestamp'] >= last_date\n",
        "        ].sort_values('timestamp')\n",
        "        \n",
        "        if len(closest_prod) > 0:\n",
        "            soh_prod = closest_prod.iloc[0]['soh_prod']\n",
        "            \n",
        "            # Calculer les erreurs pour la moyenne et la médiane\n",
        "            all_results_by_points_list.append({\n",
        "                'VIN': vin,\n",
        "                'Nombre_points': threshold,\n",
        "                'DATE': last_date,\n",
        "                'SOH_calculated_mean': phase_prod['SOH'].values[-1],\n",
        "                'SOH_prod': soh_prod,\n",
        "                'Erreur_abs_mean': abs(soh_prod - phase_prod['SOH'].values[-1]),\n",
        "                'Erreur_pct_mean': abs((soh_prod - phase_prod['SOH'].values[-1]) / soh_prod * 100) if soh_prod > 0 else None,\n",
        "                'Nombre_points_valides': len(phase_prod['SOH'])\n",
        "            })\n",
        "\n",
        "# Créer le DataFrame avec tous les résultats\n",
        "results_by_points_df = pd.DataFrame(all_results_by_points_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48662078",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer les statistiques d'erreur par nombre de points (en utilisant la moyenne)\n",
        "error_stats_by_points = []\n",
        "\n",
        "for threshold in point_thresholds:\n",
        "    threshold_data = results_by_points_df[results_by_points_df['Nombre_points'] == threshold]\n",
        "    \n",
        "    if len(threshold_data) == 0:\n",
        "        continue\n",
        "    \n",
        "    valid_errors = threshold_data['Erreur_abs_mean'].dropna()\n",
        "    \n",
        "    if len(valid_errors) > 0:\n",
        "        error_stats_by_points.append({\n",
        "            'Nombre_points': threshold,\n",
        "            'Erreur_moyenne': valid_errors.mean(),\n",
        "            'Erreur_mediane': valid_errors.median(),\n",
        "            'Erreur_std': valid_errors.std(),\n",
        "            'Erreur_q25': valid_errors.quantile(0.25),\n",
        "            'Erreur_q75': valid_errors.quantile(0.75),\n",
        "            'Erreur_max': valid_errors.max(),\n",
        "            'Nombre_observations': len(valid_errors),\n",
        "            'Nombre_VINs': threshold_data['VIN'].nunique()\n",
        "        })\n",
        "\n",
        "error_by_points_df = pd.DataFrame(error_stats_by_points).sort_values('Nombre_points')\n",
        "\n",
        "display(error_by_points_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f65ced",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique de l'erreur en fonction du nombre de points\n",
        "fig = go.Figure()\n",
        "\n",
        "# Intervalle interquartile (Q25-Q75)\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_points_df['Nombre_points'],\n",
        "    y=error_by_points_df['Erreur_q75'],\n",
        "    mode='lines',\n",
        "    line=dict(width=0),\n",
        "    showlegend=False,\n",
        "    hovertemplate='Q75: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_points_df['Nombre_points'],\n",
        "    y=error_by_points_df['Erreur_q25'],\n",
        "    mode='lines',\n",
        "    line=dict(width=0),\n",
        "    fillcolor='rgba(255, 0, 0, 0.2)',\n",
        "    fill='tonexty',\n",
        "    name='Intervalle interquartile (Q25-Q75)',\n",
        "    hovertemplate='Q25: %{y:.4f}<extra></extra>'\n",
        "))\n",
        "\n",
        "# Moyenne ± 2 écarts-types\n",
        "if 'Erreur_std' in error_by_points_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_points_df['Nombre_points'],\n",
        "        y=error_by_points_df['Erreur_moyenne'] + 2 * error_by_points_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        showlegend=False,\n",
        "        hovertemplate='Moyenne + 2σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_points_df['Nombre_points'],\n",
        "        y=error_by_points_df['Erreur_moyenne'] - 2 * error_by_points_df['Erreur_std'],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        fillcolor='rgba(0, 0, 255, 0.15)',\n",
        "        fill='tonexty',\n",
        "        name='Moyenne ± 2 écarts-types',\n",
        "        hovertemplate='Moyenne - 2σ: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "# Ligne principale avec l'erreur moyenne\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=error_by_points_df['Nombre_points'],\n",
        "    y=error_by_points_df['Erreur_moyenne'],\n",
        "    mode='lines+markers',\n",
        "    name='Erreur moyenne',\n",
        "    line=dict(color='blue', width=3),\n",
        "    marker=dict(size=10),\n",
        "    hovertemplate='<b>%{x} points</b><br>Erreur moyenne: %{y:.4f}<br>Nombre d\\'observations: %{customdata[0]}<br>Nombre de VINs: %{customdata[1]}<extra></extra>',\n",
        "    customdata=error_by_points_df[['Nombre_observations', 'Nombre_VINs']].values\n",
        "))\n",
        "\n",
        "# Ligne avec l'erreur maximale\n",
        "if 'Erreur_max' in error_by_points_df.columns:\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=error_by_points_df['Nombre_points'],\n",
        "        y=error_by_points_df['Erreur_max'],\n",
        "        mode='markers',\n",
        "        name='Erreur maximale',\n",
        "        marker=dict(symbol='triangle-up', size=10, color='orange'),\n",
        "        hovertemplate='<b>%{x} points</b><br>Erreur maximale: %{y:.4f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Erreur moyenne en fonction du nombre de points de données raw_tss (tous les VINs)',\n",
        "    xaxis_title='Nombre de points',\n",
        "    yaxis_title='Erreur absolue moyenne',\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Afficher le tableau récapitulatif\n",
        "print(\"\\nTableau récapitulatif de l'erreur moyenne par nombre de points (tous les VINs):\")\n",
        "display(error_by_points_df.round(4))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
