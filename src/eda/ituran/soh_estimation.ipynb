{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ituran Second Response charging points SoH esitmation\n",
    "\n",
    "In this notebook we will handle the processed time series data to compute the SoH from the charging points (like we did with Watea).  \n",
    "This would corresponds to the result/soh_estimation step in our pipeline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Please run the `ituran_second_response_tss_EDA.ipynb` notebook before running this one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import qualitative\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer, StandardScaler\n",
    "\n",
    "from core.pandas_utils import *\n",
    "from core.plt_utils import plt_3d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simply load the processed time series data computed in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = pd.read_parquet(\"./data_cache/ituran_tss.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoH estimation  \n",
    "To estimate the SoH, we will use the charging points' energy_added.  \n",
    "In this context a charging point is an statistical description of a period of charging from one soc to the next.  \n",
    "We consider the energy added to be the energy that the battery required to gain that soc.  \n",
    "We will estimate/express the SoH of the battery as the energy required by the battery to gain a certain soc divided by the energy required by a 100%SoH battery to gain the same soc.  \n",
    "Since the added energy that a battery requires to gain a certain soc depends on multiple factors, we will try to capture as many factors as possible.  \n",
    "To estimate the SoH all we really need to estimate is the energy required by a 100%SoH battery to gain a certain soc based on the charging point's factors.  \n",
    "Then we just need to divide the energy required by the battery to gain a certain soc by the estimated energy required by a 100%SoH battery to gain the same soc in the same conditions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charging points SoH estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_first_charge_soc(tss:DF) -> DF:\n",
    "    tss[\"first_charge_soc\"] = (\n",
    "        tss\n",
    "        .groupby([\"vehicle_id\", \"trimmed_in_charge_idx\"])\n",
    "        [\"soc\"]\n",
    "        .transform(\"first\")\n",
    "    )\n",
    "    tss[\"first_charge_soc\"] = tss[\"first_charge_soc\"].where(tss[\"trimmed_in_charge\"], pd.NA)\n",
    "    return tss\n",
    "\n",
    "CHARGING_POINT_QUANTIZATION = 3\n",
    "\n",
    "def floor_soc(tss:DF) -> DF:\n",
    "    return (\n",
    "        tss\n",
    "        .assign(floored_soc=floor_to(tss[\"soc\"], CHARGING_POINT_QUANTIZATION))\n",
    "    )\n",
    "\n",
    "charging_points:DF = (\n",
    "    tss\n",
    "    .pipe(compute_first_charge_soc)\n",
    "    .pipe(floor_soc)\n",
    "    .query(\"vehicle_model == 'geometry c' & trimmed_in_charge\")\n",
    "    .groupby([\"vehicle_id\", \"trimmed_in_charge_idx\", \"floored_soc\"], as_index=False, observed=True)\n",
    "    .agg(\n",
    "        energy_added_at_start=pd.NamedAgg(column=\"cum_energy_added\", aggfunc=\"first\"),\n",
    "        energy_added_at_end=pd.NamedAgg(column=\"cum_energy_added\", aggfunc=\"last\"),\n",
    "        energy_added=pd.NamedAgg(column=\"cum_energy_added\", aggfunc=series_start_end_diff),\n",
    "        ac_mode_mean=pd.NamedAgg(column=\"charging_ac_mode\", aggfunc=\"mean\"),\n",
    "        dc_mode_mean=pd.NamedAgg(column=\"charging_dc_mode\", aggfunc=\"mean\"),\n",
    "        current=pd.NamedAgg(column=\"ffilled_charging_current\", aggfunc=\"median\"),\n",
    "        voltage=pd.NamedAgg(column=\"ffilled_charging_voltage\", aggfunc=\"median\"),\n",
    "        estimated_range=pd.NamedAgg(column=\"ffilled_estimated_range\", aggfunc=\"median\"),\n",
    "        time_remaining_for_charge=pd.NamedAgg(column=\"ffilled_time_remaining_for_charge\", aggfunc=\"median\"),\n",
    "        model=pd.NamedAgg(column=\"vehicle_model\", aggfunc=\"first\"),\n",
    "        first_charge_soc=pd.NamedAgg(column=\"first_charge_soc\", aggfunc=\"first\"),\n",
    "        duration=pd.NamedAgg(column=\"date\", aggfunc=series_start_end_diff),\n",
    "        date=pd.NamedAgg(column=\"date\", aggfunc=\"first\"),\n",
    "        nb_points=pd.NamedAgg(column=\"soc\", aggfunc=\"size\"),\n",
    "        odometer=pd.NamedAgg(column=\"odometer\", aggfunc=\"first\"),\n",
    "    )\n",
    "    .rename(columns={\"floored_soc\": \"soc\"})\n",
    "    .eval(\"energy_added=energy_added_at_end - energy_added_at_start\")\n",
    "    .eval(\"soc_added = soc - first_charge_soc\")\n",
    "    .eval(\"power = current * voltage\")\n",
    "    .eval(\"in_ac = ac_mode_mean > 0.3\")\n",
    "    .eval(\"in_dc = dc_mode_mean > 0.3\")\n",
    "    .eval(\"power = current * voltage\")\n",
    "    .eval(\"sec_duration = duration.dt.total_seconds()\")\n",
    "    .eval(\"energy_added_per_point = energy_added / nb_points\")\n",
    ")\n",
    "\n",
    "sanity_check(charging_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charging points EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    charging_points.query(\"energy_added.between(26e3, 245e3)\"),\n",
    "    x=\"nb_points\",\n",
    "    y=\"energy_added\",\n",
    "    color=\"vehicle_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charging_points[\"vehicle_id\"].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_3d_df(\n",
    "    charging_points.query(\"vehicle_id == 27 & energy_added > 13e3\"),\n",
    "    x=\"date\",\n",
    "    y=\"duration\",\n",
    "    z=\"energy_added\",\n",
    "    color=\"nb_points\",\n",
    "    log_z=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_3d_df(\n",
    "    (\n",
    "        charging_points\n",
    "        .query(\"energy_added.between(26e3, 245e3)\")\n",
    "        .query(\"in_dc\")\n",
    "        #.query(\"nb_points == 4\")\n",
    "        #.query(\"nb_points.between(3, 6)\")\n",
    "        .astype({\"vehicle_id\": \"category\"})\n",
    "    ),\n",
    "    x='power',\n",
    "    y=\"soc\",\n",
    "    z=\"energy_added\",\n",
    "    color=\"vehicle_id\",\n",
    "    opacity=0.25,\n",
    "    size=3,\n",
    "    width=1500,\n",
    "    height=1000,\n",
    "    log_z=True,\n",
    "    #log_y=True,\n",
    "    #symbol=\"in_dc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charging_points_to_plot = (\n",
    "    charging_points\n",
    "    # .query(\"energy_added.between(26e3, 100e3)\")\n",
    "    .query(\"in_dc\")\n",
    "    # .query(\"vehicle_id == 27\")\n",
    ")\n",
    "\n",
    "# Initialize 3D plot\n",
    "fig = go.Figure()\n",
    "\n",
    "x='power'\n",
    "Y='soc'\n",
    "Z='energy_added'\n",
    "\n",
    "# Add a trace for each `trimmed_in_charge_idx` group\n",
    "for (vehicle_id, trimmed_in_charge_idx), group_data in charging_points_to_plot.groupby([\"vehicle_id\", \"trimmed_in_charge_idx\"]):\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=group_data[x],\n",
    "        y=group_data[Y],\n",
    "        z=group_data[Z],\n",
    "        mode='lines',\n",
    "        name=f'Group {trimmed_in_charge_idx} (vehicle_id: {vehicle_id})'\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Charges time series\",\n",
    "    scene=dict(\n",
    "        xaxis_title=x,\n",
    "        yaxis_title=Y,\n",
    "        zaxis_title=Z,\n",
    "        zaxis=dict(\n",
    "            type='log'\n",
    "        ),\n",
    "        camera=dict(\n",
    "            projection=dict(\n",
    "                type='orthographic'\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    width=1500,\n",
    "    height=1000,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 3D plot\n",
    "fig = go.Figure()\n",
    "\n",
    "x='soc'\n",
    "Y='nb_points'\n",
    "Z='energy_added'\n",
    "\n",
    "charging_points_to_plot = (\n",
    "    charging_points\n",
    "    # .query(\"energy_added.between(26e3, 100e3)\")\n",
    "    .query(\"in_dc\")\n",
    "    .dropna(subset=[x, Y, Z], how=\"any\")\n",
    "    .query(\"energy_added > 1e5\")\n",
    "    .query(\"nb_points < 30\")\n",
    ")\n",
    "\n",
    "# Add a trace for each `trimmed_in_charge_idx` group\n",
    "for (vehicle_id, trimmed_in_charge_idx), group_data in charging_points_to_plot.groupby([\"vehicle_id\", \"trimmed_in_charge_idx\"]):\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=group_data[x],\n",
    "        y=group_data[Y],\n",
    "        z=group_data[Z],\n",
    "        mode='lines',\n",
    "        name=f'Group {trimmed_in_charge_idx} (vehicle_id: {vehicle_id})'\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Charges time series\",\n",
    "    scene=dict(\n",
    "        xaxis_title=x,\n",
    "        yaxis_title=Y,\n",
    "        zaxis_title=Z,\n",
    "        zaxis=dict(\n",
    "            type='log'\n",
    "        ),\n",
    "        camera=dict(\n",
    "            projection=dict(\n",
    "                type='orthographic'\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    width=1500,\n",
    "    height=1000,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Energy added fitting\n",
    "We will try to fit a model to estimate the default(brand new vehicle) energy added required for a charging point to complete based on its power, soc and nb_points.  \n",
    "And them, express the SoH as the ratio between the energy that charging point actually required and this estimated default required energy added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the vehicles with the least amount distance traveled to use as a reference point for the default energy added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: There is only one odo value per vehicle (>_<)\n",
    "vehicle_od = (\n",
    "    charging_points\n",
    "    .groupby(\"vehicle_id\", observed=True, as_index=False)[\"odometer\"]\n",
    "    .agg(\"min\")\n",
    "    .sort_values(\"odometer\")\n",
    ")\n",
    "display(vehicle_od)\n",
    "px.bar(vehicle_od.astype({\"vehicle_id\": \"string\"}), x=\"vehicle_id\", y=\"odometer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually seems like a pretty good distribution of odometers for that small of a sample size. :thumbsup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We express the SoH of the charging points as their energy added divided by an estimation of the default energy added.  \n",
    "The default energy added is estimated as the polyfit of the charging points + the residual from that fit to the points of the vehicles with the lowest odometer.  \n",
    "Then we perform aggregations to get the SoH per vehicle.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_soh(charging_points:DF, model_degrees:int, soh_col_name:str=\"soh\") -> DF:\n",
    "    # Define the features and target\n",
    "    FEATURES = [\"power\", \"soc\", \"nb_points\", \"voltage\", \"current\", \"soc_added\"]\n",
    "    TARGETS = [\"energy_added\"]\n",
    "\n",
    "    if charging_points[FEATURES + TARGETS].isna().any().any():\n",
    "        charging_points = charging_points.dropna(subset=FEATURES + TARGETS, how=\"any\").copy()\n",
    "\n",
    "    # Extract the feature matrix (X) and target vector (y)\n",
    "    x = charging_points[FEATURES].values\n",
    "    y = charging_points[TARGETS].values\n",
    "\n",
    "    # Create a pipeline with an exponential transformation step\n",
    "    model = Pipeline([\n",
    "        ('standard_scaler', StandardScaler()),  # Standardization\n",
    "        ('polynomial_features', PolynomialFeatures(model_degrees)),  # Polynomial expansion\n",
    "        ('linear_regression', LinearRegression())  # Linear regression\n",
    "    ])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x, y)\n",
    "\n",
    "    charging_points[\"fit_energy_added\"] = model.predict(x)\n",
    "    charging_points[\"residual\"] = charging_points.eval(\"fit_energy_added - energy_added\")\n",
    "    charging_points[\"is_default_soh\"] = charging_points[\"odometer\"] < 5000\n",
    "    default_soh_residual = charging_points.query(\"is_default_soh\")[\"residual\"].mean()\n",
    "    charging_points[\"default_energy_added\"] = charging_points[\"fit_energy_added\"] + default_soh_residual\n",
    "    charging_points[soh_col_name] = charging_points.eval(\"energy_added / default_energy_added\")\n",
    "\n",
    "    return charging_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charging_points = (\n",
    "    charging_points\n",
    "    .pipe(estimate_soh, 10, \"soh_10\")\n",
    "    .pipe(estimate_soh, 6, \"soh_6\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soh_per_vin = (\n",
    "    charging_points\n",
    "    .groupby(\"vehicle_id\", observed=True, as_index=False)\n",
    "    .agg({\n",
    "            \"soh_10\": \"median\",\n",
    "            \"soh_6\": \"median\",\n",
    "            \"odometer\": \"last\",\n",
    "    })\n",
    "    .melt(\n",
    "        [\"odometer\", \"vehicle_id\"],\n",
    "        [\"soh_10\", \"soh_6\"],\n",
    "    )\n",
    ")\n",
    "px.scatter(\n",
    "    soh_per_vin,\n",
    "    x=\"odometer\",\n",
    "    y=\"value\",\n",
    "    facet_row=\"variable\",\n",
    "    color=\"vehicle_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that going from 10 to 6 parameters we end up with completly different results so we need to search for a method to get the best number of degrees.  \n",
    "I believe that we could get away with a simple hyper parameter tunning based on cross validation to find the right number of params.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The small amount of data makes it easy for LR model to overfit the dataset.  \n",
    "The vins are not too far away from each other but I am afraid we still don't have enough vehicles and odometer depth to properly evaluate our estimation.   \n",
    "Nevertheless, it seems possible to compute the SoH.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

