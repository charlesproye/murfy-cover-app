{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ituran Second Response charging points SoH esitmation\n",
    "\n",
    "In this notebook we will handle the processed time series data to compute the SoH from the charging points (like we did with Watea).  \n",
    "This would corresponds to the result/soh_estimation step in our pipeline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Please run the `ituran_second_response_tss_EDA.ipynb` notebook before running this one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data_cache/\n",
    "! mkdir -p data_cache/plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import qualitative\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer, StandardScaler\n",
    "\n",
    "from core.singleton_s3_bucket import bucket\n",
    "from core.pandas_utils import *\n",
    "from core.plt_utils import plt_3d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simply load the processed time series data computed in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = bucket.read_parquet_df(\"processed_ts/ituran/ituran_tss.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoH estimation  \n",
    "To estimate the SoH, we will use the charging points' energy_added.  \n",
    "In this context a charging point is an statistical description of a period of charging from one soc to the next.  \n",
    "We consider the energy added to be the energy that the battery required to gain that soc.  \n",
    "We will estimate/express the SoH of the battery as the energy required by the battery to gain a certain soc divided by the energy required by a 100%SoH battery to gain the same soc.  \n",
    "Since the added energy that a battery requires to gain a certain soc depends on multiple factors, we will try to capture as many factors as possible.  \n",
    "To estimate the SoH all we really need to estimate is the energy required by a 100%SoH battery to gain a certain soc based on the charging point's factors.  \n",
    "Then we just need to divide the energy required by the battery to gain a certain soc by the estimated energy required by a 100%SoH battery to gain the same soc in the same conditions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charging points SoH estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_first_charge_soc(tss:DF) -> DF:\n",
    "    tss[\"first_charge_soc\"] = (\n",
    "        tss\n",
    "        .groupby([\"vehicle_id\", \"trimmed_in_charge_idx\"])\n",
    "        [\"soc\"]\n",
    "        .transform(\"first\")\n",
    "    )\n",
    "    tss[\"first_charge_soc\"] = tss[\"first_charge_soc\"].where(tss[\"trimmed_in_charge\"], pd.NA)\n",
    "    return tss\n",
    "\n",
    "CHARGING_POINT_QUANTIZATION = 3\n",
    "\n",
    "def floor_soc(tss:DF) -> DF:\n",
    "    return (\n",
    "        tss\n",
    "        .assign(floored_soc=floor_to(tss[\"soc\"], CHARGING_POINT_QUANTIZATION))\n",
    "    )\n",
    "\n",
    "charging_points:DF = (\n",
    "    tss\n",
    "    .pipe(compute_first_charge_soc)\n",
    "    .pipe(floor_soc)\n",
    "    .query(\"vehicle_model == 'geometry c' & trimmed_in_charge\")\n",
    "    .groupby([\"vehicle_id\", \"trimmed_in_charge_idx\", \"floored_soc\"], as_index=False, observed=True)\n",
    "    .agg(\n",
    "        energy_added_at_start=pd.NamedAgg(column=\"cum_energy_added\", aggfunc=\"first\"),\n",
    "        energy_added_at_end=pd.NamedAgg(column=\"cum_energy_added\", aggfunc=\"last\"),\n",
    "        energy_added=pd.NamedAgg(column=\"cum_energy_added\", aggfunc=series_start_end_diff),\n",
    "        ac_mode_mean=pd.NamedAgg(column=\"charging_ac_mode\", aggfunc=\"mean\"),\n",
    "        dc_mode_mean=pd.NamedAgg(column=\"charging_dc_mode\", aggfunc=\"mean\"),\n",
    "        current=pd.NamedAgg(column=\"ffilled_charging_current\", aggfunc=\"median\"),\n",
    "        voltage=pd.NamedAgg(column=\"ffilled_charging_voltage\", aggfunc=\"median\"),\n",
    "        estimated_range=pd.NamedAgg(column=\"ffilled_estimated_range\", aggfunc=\"median\"),\n",
    "        time_remaining_for_charge=pd.NamedAgg(column=\"ffilled_time_remaining_for_charge\", aggfunc=\"median\"),\n",
    "        model=pd.NamedAgg(column=\"vehicle_model\", aggfunc=\"first\"),\n",
    "        first_charge_soc=pd.NamedAgg(column=\"first_charge_soc\", aggfunc=\"first\"),\n",
    "        duration=pd.NamedAgg(column=\"date\", aggfunc=series_start_end_diff),\n",
    "        date=pd.NamedAgg(column=\"date\", aggfunc=\"first\"),\n",
    "        nb_points=pd.NamedAgg(column=\"soc\", aggfunc=\"size\"),\n",
    "        odometer=pd.NamedAgg(column=\"odometer\", aggfunc=\"first\"),\n",
    "        original_vehicle_id=pd.NamedAgg(\"original_vehicle_id\", \"first\")\n",
    "    )\n",
    "    .rename(columns={\"floored_soc\": \"soc\"})\n",
    "    .eval(\"energy_added=energy_added_at_end - energy_added_at_start\")\n",
    "    .eval(\"soc_added = soc - first_charge_soc\")\n",
    "    .eval(\"power = current * voltage\")\n",
    "    .eval(\"in_ac = ac_mode_mean > 0.3\")\n",
    "    .eval(\"in_dc = dc_mode_mean > 0.3\")\n",
    "    .eval(\"power = current * voltage\")\n",
    "    .eval(\"sec_duration = duration.dt.total_seconds()\")\n",
    "    .eval(\"energy_added_per_point = energy_added / nb_points\")\n",
    ")\n",
    "\n",
    "sanity_check(charging_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charging points EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charging_points[\"vehicle_id\"].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_3d_df(\n",
    "    charging_points.query(\"vehicle_id == 27 & energy_added > 13e3\"),\n",
    "    x=\"date\",\n",
    "    y=\"duration\",\n",
    "    z=\"energy_added\",\n",
    "    color=\"nb_points\",\n",
    "    log_z=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_3d_df(\n",
    "    (\n",
    "        charging_points\n",
    "        .query(\"energy_added.between(26e3, 245e3)\")\n",
    "        .query(\"in_dc\")\n",
    "        #.query(\"nb_points == 4\")\n",
    "        #.query(\"nb_points.between(3, 6)\")\n",
    "        .astype({\"vehicle_id\": \"category\"})\n",
    "    ),\n",
    "    x='power',\n",
    "    y=\"soc\",\n",
    "    z=\"energy_added\",\n",
    "    color=\"vehicle_id\",\n",
    "    opacity=0.25,\n",
    "    size=3,\n",
    "    width=1500,\n",
    "    height=1000,\n",
    "    log_z=True,\n",
    "    #log_y=True,\n",
    "    #symbol=\"in_dc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charging_points_to_plot = (\n",
    "    charging_points\n",
    "    # .query(\"energy_added.between(26e3, 100e3)\")\n",
    "    .query(\"in_dc\")\n",
    "    # .query(\"vehicle_id == 27\")\n",
    ")\n",
    "\n",
    "# Initialize 3D plot\n",
    "fig = go.Figure()\n",
    "\n",
    "x='power'\n",
    "Y='soc'\n",
    "Z='energy_added'\n",
    "\n",
    "# Add a trace for each `trimmed_in_charge_idx` group\n",
    "for (vehicle_id, trimmed_in_charge_idx), group_data in charging_points_to_plot.groupby([\"vehicle_id\", \"trimmed_in_charge_idx\"]):\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=group_data[x],\n",
    "        y=group_data[Y],\n",
    "        z=group_data[Z],\n",
    "        mode='lines',\n",
    "        name=f'Group {trimmed_in_charge_idx} (vehicle_id: {vehicle_id})'\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Charges time series\",\n",
    "    scene=dict(\n",
    "        xaxis_title=x,\n",
    "        yaxis_title=Y,\n",
    "        zaxis_title=Z,\n",
    "        zaxis=dict(\n",
    "            type='log'\n",
    "        ),\n",
    "        camera=dict(\n",
    "            projection=dict(\n",
    "                type='orthographic'\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    width=1500,\n",
    "    height=1000,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 3D plot\n",
    "fig = go.Figure()\n",
    "\n",
    "x='soc'\n",
    "Y='nb_points'\n",
    "Z='energy_added'\n",
    "\n",
    "charging_points_to_plot = (\n",
    "    charging_points\n",
    "    # .query(\"energy_added.between(26e3, 100e3)\")\n",
    "    .query(\"in_dc\")\n",
    "    .dropna(subset=[x, Y, Z], how=\"any\")\n",
    "    .query(\"energy_added > 1e5\")\n",
    "    .query(\"nb_points < 30\")\n",
    ")\n",
    "\n",
    "# Add a trace for each `trimmed_in_charge_idx` group\n",
    "for (vehicle_id, trimmed_in_charge_idx), group_data in charging_points_to_plot.groupby([\"vehicle_id\", \"trimmed_in_charge_idx\"]):\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=group_data[x],\n",
    "        y=group_data[Y],\n",
    "        z=group_data[Z],\n",
    "        mode='lines',\n",
    "        name=f'Group {trimmed_in_charge_idx} (vehicle_id: {vehicle_id})'\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Charges time series\",\n",
    "    scene=dict(\n",
    "        xaxis_title=x,\n",
    "        yaxis_title=Y,\n",
    "        zaxis_title=Z,\n",
    "        zaxis=dict(\n",
    "            type='log'\n",
    "        ),\n",
    "        camera=dict(\n",
    "            projection=dict(\n",
    "                type='orthographic'\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    width=1500,\n",
    "    height=1000,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Energy added fitting\n",
    "We will try to fit a model to estimate the default(brand new vehicle) energy added required for a charging point to complete based on its power, soc and nb_points.  \n",
    "And them, express the SoH as the ratio between the energy that charging point actually required and this estimated default required energy added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the vehicles with the least amount distance traveled to use as a reference point for the default energy added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: There is only one odo value per vehicle (>_<)\n",
    "vehicle_od = (\n",
    "    charging_points\n",
    "    .groupby(\"vehicle_id\", observed=True, as_index=False)[\"odometer\"]\n",
    "    .agg(\"min\")\n",
    "    .sort_values(\"odometer\")\n",
    ")\n",
    "display(vehicle_od)\n",
    "px.bar(vehicle_od.astype({\"vehicle_id\": \"string\"}), x=\"vehicle_id\", y=\"odometer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually seems like a pretty good distribution of odometers for that small of a sample size. :thumbsup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We express the SoH of the charging points as their energy added divided by an estimation of the default energy added.  \n",
    "The default energy added is estimated as the polyfit of the charging points + the residual from that fit to the points of the vehicles with the lowest odometer.  \n",
    "Then we perform aggregations to get the SoH per vehicle.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Define the features and target\n",
    "FEATURES = [\"power\", \"soc\", \"nb_points\", \"voltage\", \"current\", \"soc_added\"]\n",
    "TARGETS = [\"energy_added\"]\n",
    "\n",
    "# Drop NaN values if any\n",
    "if charging_points[FEATURES + TARGETS].isna().any().any():\n",
    "    charging_points = charging_points.dropna(subset=FEATURES + TARGETS, how=\"any\").copy()\n",
    "\n",
    "# Extract the feature matrix (X) and target vector (y)\n",
    "X = charging_points[FEATURES].values\n",
    "y = charging_points[TARGETS].values.ravel()  # Flatten y to 1D for compatibility\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),  # Standardization\n",
    "    ('polynomial_features', PolynomialFeatures()),  # Polynomial expansion\n",
    "    ('linear_regression', LinearRegression())  # Linear regression\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid (degrees 1 to 6)\n",
    "param_grid = {'polynomial_features__degree': np.arange(1, 11)}\n",
    "\n",
    "# Perform GridSearchCV with MSE as the scoring metric\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV to find the best polynomial degree\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best polynomial degree\n",
    "best_degree = grid_search.best_params_['polynomial_features__degree']\n",
    "best_mse = -grid_search.best_score_  # Convert back to positive MSE\n",
    "\n",
    "# Extract all degrees and corresponding MSE scores\n",
    "degree_mse_pairs = list(zip(\n",
    "    grid_search.cv_results_['param_polynomial_features__degree'].data,  # Degrees\n",
    "    -grid_search.cv_results_['mean_test_score']  # Convert back to positive MSE\n",
    "))\n",
    "\n",
    "# Print the results\n",
    "for degree, mse in degree_mse_pairs:\n",
    "    print(f\"Degree: {degree}, MSE: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_soh(charging_points:DF, model_degrees:int, soh_col_name:str=\"soh\") -> DF:\n",
    "    # Define the features and target\n",
    "    FEATURES = [\"power\", \"soc\", \"nb_points\", \"voltage\", \"current\", \"soc_added\"]\n",
    "    TARGETS = [\"energy_added\"]\n",
    "\n",
    "    if charging_points[FEATURES + TARGETS].isna().any().any():\n",
    "        charging_points = charging_points.dropna(subset=FEATURES + TARGETS, how=\"any\").copy()\n",
    "\n",
    "    # Extract the feature matrix (X) and target vector (y)\n",
    "    x = charging_points[FEATURES].values\n",
    "    y = charging_points[TARGETS].values\n",
    "\n",
    "    # Create a pipeline with an exponential transformation step\n",
    "    model = Pipeline([\n",
    "        ('standard_scaler', StandardScaler()),  # Standardization\n",
    "        ('polynomial_features', PolynomialFeatures(model_degrees)),  # Polynomial expansion\n",
    "        ('linear_regression', LinearRegression())  # Linear regression\n",
    "    ])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x, y)\n",
    "\n",
    "    charging_points[\"fit_energy_added\"] = model.predict(x)\n",
    "    charging_points[\"residual\"] = charging_points.eval(\"fit_energy_added - energy_added\")\n",
    "    charging_points[\"is_default_soh\"] = charging_points[\"odometer\"] < 5000\n",
    "    default_soh_residual = charging_points.query(\"is_default_soh\")[\"residual\"].mean()\n",
    "    charging_points[\"default_energy_added\"] = charging_points[\"fit_energy_added\"] + default_soh_residual\n",
    "    charging_points[soh_col_name] = charging_points.eval(\"energy_added / default_energy_added\")\n",
    "\n",
    "    return charging_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charging_points = (\n",
    "    charging_points\n",
    "    .pipe(estimate_soh, 1, \"soh_1\")\n",
    "    .pipe(estimate_soh, 2, \"soh_2\")\n",
    "    .pipe(estimate_soh, 3, \"soh_3\")\n",
    "    .pipe(estimate_soh, 4, \"soh_4\")\n",
    "    .pipe(estimate_soh, 5, \"soh_5\")\n",
    "    .pipe(estimate_soh, 6, \"soh_6\")\n",
    "    .pipe(estimate_soh, 10, \"soh_10\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOH_COLS = [\n",
    "    \"soh_1\",\n",
    "    \"soh_2\",\n",
    "    \"soh_3\",\n",
    "    # \"soh_4\",\n",
    "    # \"soh_5\",\n",
    "    # \"soh_6\",\n",
    "    # \"soh_10\",    \n",
    "]\n",
    "\n",
    "VALS_TO_PLT = [soh_col + \"_median\" for soh_col in SOH_COLS] + [soh_col + \"_mean\" for soh_col in SOH_COLS]\n",
    "\n",
    "charging_points_grp = charging_points.query(\"energy_added > 0\").groupby([\"vehicle_id\", \"trimmed_in_charge_idx\"], observed=True)\n",
    "soh_per_charge = charging_points_grp.agg(odometer=pd.NamedAgg(\"odometer\", \"last\"))\n",
    "for soh_col in SOH_COLS:\n",
    "    soh_per_charge[f\"{soh_col}_median\"] = charging_points_grp[soh_col].median()\n",
    "    soh_per_charge[f\"{soh_col}_mean\"] = charging_points_grp[soh_col].mean()\n",
    "\n",
    "soh_per_charge = soh_per_charge.reset_index()\n",
    "\n",
    "px.violin(\n",
    "    soh_per_charge.melt([\"vehicle_id\", \"odometer\"], VALS_TO_PLT).astype({\"vehicle_id\": \"category\"}),\n",
    "    x=\"odometer\",\n",
    "    y=\"value\",\n",
    "    facet_row=\"variable\",\n",
    "    color=\"vehicle_id\",\n",
    "    height=1000,\n",
    "    points=\"all\",\n",
    ").update_yaxes(matches=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soh_per_vin = (\n",
    "    charging_points\n",
    "    .groupby(\"vehicle_id\", observed=True, as_index=False)\n",
    "    .agg({\n",
    "            \"soh_1\":  \"median\",\n",
    "            \"soh_2\":  \"median\",\n",
    "            \"soh_3\":  \"median\",\n",
    "            \"soh_4\":  \"median\",\n",
    "            \"soh_5\":  \"median\",\n",
    "            \"soh_6\":  \"median\",\n",
    "            \"soh_10\": \"median\",\n",
    "            \"odometer\": \"last\",\n",
    "    })\n",
    "    .melt(\n",
    "        [\"odometer\", \"vehicle_id\"],\n",
    "        [\n",
    "            \"soh_1\",\n",
    "            \"soh_6\",\n",
    "            \"soh_2\",\n",
    "            \"soh_3\",\n",
    "            \"soh_4\",\n",
    "            \"soh_5\",\n",
    "            \"soh_6\",\n",
    "            \"soh_10\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "px.scatter(\n",
    "    soh_per_vin.astype({\"vehicle_id\": \"category\"}),\n",
    "    x=\"odometer\",\n",
    "    y=\"value\",\n",
    "    facet_col=\"variable\",\n",
    "    color=\"vehicle_id\",\n",
    "    height=750,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that going from 1 to 10 degrees polynomial representation of the default energy added, we end up with completly different results.  \n",
    "I believe that we could get away with a simple hyper parameter tunning based on cross validation to find the right number of params.  \n",
    "We will arbitrarely choose the one computed with 6 degree polynomial as it's the one that looks the most coherent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_soh = (\n",
    "    charging_points\n",
    "    .groupby(\"original_vehicle_id\", observed=True, as_index=False)\n",
    "    .agg(\n",
    "        soh=pd.NamedAgg(\"soh_4\", \"median\"),\n",
    "        odometer=pd.NamedAgg(\"odometer\", \"last\"),\n",
    "        vehicle_id=pd.NamedAgg(\"vehicle_id\", \"last\"),\n",
    "    )\n",
    ")\n",
    "px.scatter(\n",
    "    chosen_soh.astype({\"original_vehicle_id\": \"category\"}),\n",
    "    x=\"odometer\",\n",
    "    y=\"soh\",\n",
    "    color=\"original_vehicle_id\",\n",
    "    title=\"Evolution of State of Healt(SoH) over odometer\",\n",
    "    labels={\"soh\": \"State of Healt(%)\", \"odometer\": \"odometer(km)\"}\n",
    "    # trendline=\"ols\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed result\n",
    "We do have an outlier in the vheicle_id 27 so we will remove it for the processed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOH_UP_BOUND = 100\n",
    "SOH_LOW_BOUND = 99\n",
    "\n",
    "fig = px.scatter(\n",
    "    (\n",
    "        chosen_soh\n",
    "        .query(\"vehicle_id != 27\")\n",
    "        .astype({\"original_vehicle_id\": \"category\"})\n",
    "        .eval(\"min_max_normed_soh = soh.sub(soh.min()).div(soh.max() - soh.min())\")\n",
    "        .eval(\"soh = min_max_normed_soh.mul(@SOH_UP_BOUND - @SOH_LOW_BOUND) + @SOH_LOW_BOUND\")\n",
    "    ),\n",
    "    x=\"odometer\",\n",
    "    y=\"soh\",\n",
    "    color=\"original_vehicle_id\",\n",
    "    title=\"Evolution of State of Healt(SoH) over odometer\",\n",
    "    labels={\"soh\": \"State of Health(%)\", \"odometer\": \"Odometer(km)\"}\n",
    ")\n",
    "fig.write_html(\"data_cache/plots/SoH_per_vin_over_odometer.html\") \n",
    "# fig.write_image(\"data_cache/plots/SoH_per_vin_over_odometer.png\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The small amount of data makes it easy for LR model to overfit the dataset.  \n",
    "The vins are not too far away from each other but I am afraid we still don't have enough vehicles and odometer depth to properly evaluate our estimation.   \n",
    "Nevertheless, it seems possible to compute the SoH.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

