{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.spark_utils import create_spark_session\n",
    "from core.s3.s3_utils import S3Service\n",
    "from core.s3.settings import S3Settings\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, lead, sum, when, col, signum, dense_rank\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import DataFrame as DF\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "settings = S3Settings()\n",
    "\n",
    "spark = create_spark_session(\n",
    "    settings.S3_KEY,\n",
    "    settings.S3_SECRET\n",
    ")\n",
    "\n",
    "s3 = S3Service()\n",
    "\n",
    "SCALE_SOC = {\n",
    "    'tesla-fleet-telemetry': 1,\n",
    "    'mercedes-benz': 100,\n",
    "    'volvo-cars': 100,\n",
    "    'kia': 100,\n",
    "    'renault': 100,\n",
    "    'ford': 100,\n",
    "    'stellantis': 100,\n",
    "    'bmw': 1,\n",
    "    'volkswagen': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reassign_short_phases(df, min_duration_minutes=3):\n",
    "    \"\"\"\n",
    "    Recalculates phase_id by merging phases shorter than `min_duration_minutes`\n",
    "    with the previous valid phase.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Spark DataFrame with columns `phase_id`, `date`, `total_phase_time`\n",
    "        min_duration_minutes (float): Minimum duration to keep a phase (in minutes)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with updated `phase_id` column\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"is_valid_phase\",\n",
    "        F.when(F.col(\"total_phase_time\") >= min_duration_minutes, 1).otherwise(0),\n",
    "    )\n",
    "\n",
    "    w_time = (\n",
    "        Window.partitionBy(\"vin\")\n",
    "        .orderBy(\"date\")\n",
    "        .rowsBetween(Window.unboundedPreceding, 0)\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"last_valid_phase_id\",\n",
    "        F.last(\n",
    "            F.when(F.col(\"is_valid_phase\") == 1, F.col(\"phase_id\")),\n",
    "            ignorenulls=True,\n",
    "        ).over(w_time),\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"phase_id_updated\",\n",
    "        F.when(F.col(\"is_valid_phase\") == 1, F.col(\"phase_id\")).otherwise(\n",
    "            F.col(\"last_valid_phase_id\")\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"phase_id_final\",\n",
    "        F.dense_rank().over(Window.partitionBy(\"vin\").orderBy(\"phase_id_updated\"))\n",
    "        - 1,\n",
    "    )\n",
    "\n",
    "    df = df.drop(\n",
    "        \"phase_id\", \"last_valid_phase_id\", \"is_valid_phase\", \"phase_id_updated\"\n",
    "    )\n",
    "    df = df.withColumnRenamed(\"phase_id_final\", \"phase_id\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_charge_idx(\n",
    "    tss: DF, make, total_soc_diff_threshold: float = 0.5, phase_delimiter_mn: int = 45\n",
    ") -> DF:\n",
    "\n",
    "    w = Window.partitionBy(\"vin\").orderBy(\"date\") # Fenetre partitionnée par vin et triée par date\n",
    "\n",
    "    # Mettre tous les SOCs de 0 à 100 %\n",
    "    tss = tss.withColumn(\"soc\", F.col(\"soc\") * SCALE_SOC[make])\n",
    "    \n",
    "    # Supprimer les lignes avec des valeurs nulles pour la colonne \"soc\", ne pas faire de forward fill pour pouvoir distinguer de vrais idles\n",
    "    tss = tss.na.drop(subset=[\"soc\"]) \n",
    "\n",
    "    # Calculer la soc_diff en chaque point\n",
    "    tss = tss.withColumn(\n",
    "        \"soc_diff\",\n",
    "        F.col(\"soc\")- F.lag(\"soc\").over(w),\n",
    "    )\n",
    "\n",
    "    # Calculer le temps entre deux points\n",
    "    df = tss.withColumn(\"prev_date\", lag(\"date\").over(w)) \\\n",
    "        .withColumn(\n",
    "        \"time_gap_minutes\",\n",
    "        (F.unix_timestamp(\"date\") - F.unix_timestamp(\"prev_date\")) / 60,\n",
    "    )\n",
    "    \n",
    "    # Calculer naïvement la direction de la charge\n",
    "    df = df.withColumn(\n",
    "        \"direction_raw\",\n",
    "        F.when(col(\"soc_diff\").isNull(), None).otherwise(F.signum(\"soc_diff\")),\n",
    "    )\n",
    "\n",
    "    # Forward fill la direction\n",
    "    df = df.withColumn(\n",
    "        \"direction\",\n",
    "        F.last(\"direction_raw\", ignorenulls=True).over(\n",
    "            w.partitionBy(\"vin\")\n",
    "            .orderBy(\"date\")\n",
    "            .rowsBetween(Window.unboundedPreceding, 0)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Calculer les moments où la direction change\n",
    "    df = df.withColumn(\n",
    "        \"direction_change\",\n",
    "        F.when(F.col(\"direction\") != F.lag(\"direction\").over(w), 1).otherwise(0),\n",
    "    )\n",
    "\n",
    "    # A cette étape on a bêtement sans intelligence toutes les phases où on passe d'un statut idle, charging, discharging\n",
    "    # Quelque soit les points de soc gagnés ou perdus et le temps passé dans la phse\n",
    "    df = df.withColumn(\n",
    "        \"phase_id\",\n",
    "        F.sum(\"direction_change\").over(w.rowsBetween(Window.unboundedPreceding, 0)),\n",
    "    )\n",
    "\n",
    "    w_phase = Window.partitionBy(\"vin\", \"phase_id\")\n",
    "\n",
    "\n",
    "    # Pour Tesla \n",
    "    # Temps total de la  phase utile, pour Tesla\n",
    "    # df = df.withColumn(\"total_phase_time\", F.sum(\"time_gap_minutes\").over(w_phase))\n",
    "\n",
    "    #  df = _reassign_short_phases(\n",
    "    #     df\n",
    "    # )  # Reassign short phases to previous valid phase (especiallyuseful for tesla-fleet-telemetry noise)\n",
    "\n",
    "\n",
    "    # Total de soc gagné ou perdu dans la phase bête et méchante\n",
    "    df = df.withColumn(\"total_soc_diff_phase\", F.sum(\"soc_diff\").over(w_phase))\n",
    "\n",
    "    # Direction de la phase précédente et suivante\n",
    "    df = df.withColumn(\"prev_phase\", F.lag(\"direction\").over(w)).withColumn(\n",
    "        \"next_phase\", F.lead(\"direction\").over(w)\n",
    "    )\n",
    "\n",
    "    # Coeur du réacteur : permettant de bien juger du statut, une phase pour être considérée comme charging ou discharging, doit amener un gain ou perte de soc minimum\n",
    "    # Si la phase dure un point et que la précédente et la suivante sont de même nature, on les réassigne sinon c'est un idle\n",
    "    df = df.withColumn(\n",
    "        \"charging_status\",\n",
    "        F.when((F.col(\"total_soc_diff_phase\") > total_soc_diff_threshold), \"charging\")\n",
    "        .when((F.col(\"total_soc_diff_phase\") < -total_soc_diff_threshold), \"discharging\")\n",
    "        .when(\n",
    "            (F.col(\"prev_phase\") == F.col(\"next_phase\"))\n",
    "            & (F.col(\"prev_phase\") > 0),\n",
    "            \"charging\",\n",
    "        )\n",
    "        .when(\n",
    "            (F.col(\"prev_phase\") == F.col(\"next_phase\"))\n",
    "            & (F.col(\"prev_phase\") < 0),\n",
    "            \"discharging\",\n",
    "        )\n",
    "        .otherwise(\"idle\"),\n",
    "    )\n",
    "\n",
    "    # Là on vient faire en sorte que la phase précédente commence au bon endroit\n",
    "    df = df.withColumn(\n",
    "        \"next_status\",\n",
    "        F.lead(\"charging_status\").over(w)\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Set the phase before a charging/discharging phase as the phase to get the correct SOC diff\n",
    "    df = df.withColumn(\n",
    "        \"charging_status\",\n",
    "        F.when(F.col(\"next_status\") == 'charging', \"charging\")\n",
    "        .when(F.col(\"next_status\")== \"discharging\", \"discharging\")\n",
    "        .otherwise(col('charging_status'))\n",
    "    )\n",
    "\n",
    "    # Drop les idles car on a pas d'intérêt à les identifier et ça va permettre de bien découper les numéros de phases\n",
    "    # Mais important de les avoir identifier pour ne pas prolonger des phases de charge ou décharge inutilement comme le temps est important\n",
    "    df = df.withColumn(\n",
    "        \"charging_status\",\n",
    "        F.when(F.col(\"charging_status\") == \"idle\", None).otherwise(F.col(\"charging_status\"))\n",
    "    )\n",
    "\n",
    "    df = df.na.drop(subset=[\"charging_status\"])\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"charging_status_change\",\n",
    "        F.when(\n",
    "            F.col(\"charging_status\") != F.lag(\"charging_status\").over(w), 1\n",
    "        ).otherwise(0),\n",
    "    )\n",
    "    \n",
    "    # Séparer les phases successives qui sont identiques\n",
    "    if make in ('bmw', 'tesla-fleet-telemetry', 'renault'):\n",
    "        df = df.withColumn(\"prev_date\", lag(\"date\").over(w))\n",
    "        df = df.withColumn(\n",
    "            \"time_gap_minutes\",\n",
    "            (F.unix_timestamp(\"date\") - F.unix_timestamp(\"prev_date\")) / 60,\n",
    "        )\n",
    "\n",
    "    # Ajouter la colonne corrigée : pertinent quand la fréquence est suffisante\n",
    "        df = df.withColumn(\n",
    "            \"charging_status_change\",\n",
    "            F.when(\n",
    "                (F.col(\"charging_status_change\") == 0) &\n",
    "                (F.col(\"charging_status\") == 'discharging') & # on peut le retirer si les fréquences de données en charges sont suffisamment élevées\n",
    "                (F.col(\"time_gap_minutes\") > phase_delimiter_mn),\n",
    "                F.lit(1)\n",
    "            ).otherwise(F.col(\"charging_status_change\"))\n",
    "        )\n",
    "\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"charging_status_idx\",\n",
    "        F.sum(\"charging_status_change\").over(\n",
    "            w.rowsBetween(Window.unboundedPreceding, 0)\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_phase(df: DF) -> DF:\n",
    "    w_phase_static = Window.partitionBy(\"vin\").orderBy(\"first_date\")\n",
    "\n",
    "    # 1. Agrégation par phase\n",
    "    phase_stats = (\n",
    "        df\n",
    "        .orderBy(\"date\")\n",
    "        .groupBy(\"vin\", \"charging_status_idx\")\n",
    "        .agg(\n",
    "            F.first(\"soc\", ignorenulls=True).alias(\"first_soc\"),\n",
    "            F.last(\"soc\", ignorenulls=True).alias(\"last_soc\"),\n",
    "            F.min(\"date\").alias(\"first_date\"),\n",
    "            F.max(\"date\").alias(\"last_date\"),\n",
    "            F.count(\"date\").alias(\"count_points\"),\n",
    "            F.first(\"charging_status\").alias(\"charging_status\")\n",
    "        )\n",
    "        .withColumn(\"next_dt_begin\", F.lead(\"first_date\").over(w_phase_static))\n",
    "        .withColumn(\"next_first_soc\", F.lead(\"first_soc\").over(w_phase_static))\n",
    "    )\n",
    "\n",
    "    # 2. Appliquer la logique d'ajustement\n",
    "    condition = (\n",
    "        ((F.col(\"last_soc\") < F.col(\"next_first_soc\")) & (F.col(\"charging_status\") == \"charging\")) |\n",
    "        ((F.col(\"last_soc\") > F.col(\"next_first_soc\")) & (F.col(\"charging_status\") == \"discharging\"))\n",
    "    )\n",
    "\n",
    "    phase_stats = phase_stats.withColumn(\n",
    "        \"adjusted_last_date\",\n",
    "        F.when(condition, F.col(\"next_dt_begin\")).otherwise(F.col(\"last_date\"))\n",
    "    ).withColumn(\n",
    "        \"adjusted_last_soc\",\n",
    "        F.when(condition, F.col(\"next_first_soc\")).otherwise(F.col(\"last_soc\"))\n",
    "    ).withColumn(\n",
    "        \"is_usable_phase\",\n",
    "        F.when(F.col(\"count_points\") > 1, F.lit(1)).otherwise(F.lit(0))\n",
    "    )\n",
    "\n",
    "    phase_stats = phase_stats.drop('last_soc', 'last_date')\n",
    "\n",
    "    # # 4. Renommer pour clarté\n",
    "    phase_stats = phase_stats.withColumnRenamed(\"adjusted_last_soc\", \"last_soc\")\n",
    "    phase_stats = phase_stats.withColumnRenamed(\"adjusted_last_date\", \"last_date\")\n",
    "\n",
    "    phase_stats = phase_stats.withColumn('total_soc_diff', col('last_soc') - col('first_soc'))\n",
    "    phase_stats = phase_stats.withColumn('total_phase_time_minutes', \n",
    "    (F.unix_timestamp(col('last_date')) - F.unix_timestamp(col('first_date'))) / 60\n",
    "    )\n",
    "\n",
    "    # 3. Joindre les stats sur le DataFrame de base\n",
    "    df = df.join(\n",
    "        phase_stats.select(\n",
    "            \"vin\", \"charging_status_idx\",\n",
    "            \"first_soc\", \"last_soc\",\n",
    "            \"first_date\", \"last_date\",\n",
    "            \"count_points\", \"total_soc_diff\", 'total_phase_time_minutes',\n",
    "            \"is_usable_phase\"\n",
    "        ),\n",
    "        on=[\"vin\", \"charging_status_idx\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return df, phase_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_df(make: str, vin: str, col_soc: str) -> None:\n",
    "    rss = s3.read_parquet_df_spark(spark, f'raw_ts/{make}/time_series/raw_ts_spark.parquet')\n",
    "    rss_by_vin = rss.filter(rss['vin'] == vin)\n",
    "    rss_by_vin = rss_by_vin.withColumnRenamed(col_soc, \"soc\")\n",
    "    rss_by_vin_with_idx = compute_charge_idx(rss_by_vin, make)\n",
    "    rss_with_phase, phase_stats = add_phase(rss_by_vin_with_idx)\n",
    "\n",
    "    return rss_with_phase, phase_stats\n",
    "\n",
    "\n",
    "def plot_df(df: DF) -> None:\n",
    "    pdf = df.select(\"date\", \"soc\", \"charging_status\", 'charging_status_idx', 'soc_diff', 'first_date', 'last_date', 'first_soc', 'last_soc', 'total_soc_diff', 'is_usable_phase').toPandas()\n",
    "\n",
    "\n",
    "    # Mapping de couleurs\n",
    "    status_color_map = {\n",
    "        \"charging\": \"green\",\n",
    "        \"discharging\": \"red\",\n",
    "        \"idle\": \"gray\"\n",
    "    }\n",
    "    pdf[\"color\"] = pdf[\"charging_status\"].map(status_color_map)\n",
    "\n",
    "    # Tracé\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # 1. Ligne continue noire\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pdf[\"date\"],\n",
    "        y=pdf[\"soc\"],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\"),\n",
    "        name=\"SoC (ligne)\",\n",
    "        hovertemplate=\"<b>Date:</b> %{x}<br><b>SoC:</b> %{y:.1f}%<extra></extra>\"\n",
    "    ))\n",
    "\n",
    "    # 2. Points colorés avec toutes les informations\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pdf[\"date\"],\n",
    "        y=pdf[\"soc\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=pdf[\"color\"], size=6),\n",
    "        name=\"Status (points)\",\n",
    "        showlegend=False,\n",
    "        hovertemplate=\"<b>Date:</b> %{x}<br><b>SoC:</b> %{y:.1f}%<br><b>Status:</b> %{customdata[0]}<br><b>Index:</b> %{customdata[1]}<br><b>Soc Diff:</b> %{customdata[2]:.2f}<br><b>First Date:</b> %{customdata[3]}<br><b>Last Date:</b> %{customdata[4]}<br><b>First Soc:</b> %{customdata[5]:.2f}<br><b>Last Soc:</b> %{customdata[6]:.2f}<br><b>Total Soc Diff:</b> %{customdata[7]:.2f}<br><b>Is Usable Phase:</b> %{customdata[8]}<extra></extra>\",\n",
    "        customdata=list(zip(pdf[\"charging_status\"], pdf[\"charging_status_idx\"], pdf[\"soc_diff\"], pdf['first_date'], pdf['last_date'], pdf['first_soc'], pdf['last_soc'], pdf['total_soc_diff'], pdf['is_usable_phase']))\n",
    "    ))\n",
    "\n",
    "    # Mise en forme\n",
    "    fig.update_layout(\n",
    "        title=\"Évolution du SoC avec statut de charge\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"SoC (%)\",\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make = 'mercedes-benz'\n",
    "vin = 'W1N2437011J000869'\n",
    "col_soc = 'battery_level'\n",
    "\n",
    "df, phase_df = generate_df(make, vin, col_soc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transform.processed_tss.config import ODOMETER_MILES_TO_KM\n",
    "from transform.fleet_info.main import fleet_info\n",
    "\n",
    "phase_df_processed = phase_df.select(\n",
    "    F.col(\"vin\").alias(\"VIN_ph\"),\n",
    "    F.col(\"first_date\").alias(\"DATETIME_BEGIN\"),\n",
    "    F.col(\"last_date\").alias(\"DATETIME_END\"),\n",
    "    F.col(\"total_phase_time_minutes\").alias(\"PHASE_TIME_MINUTES\"),\n",
    "    F.col(\"charging_status_idx\").alias(\"PHASE_INDEX\"),\n",
    "    F.col(\"charging_status\").alias(\"PHASE_STATUS\"),\n",
    "    F.col(\"first_soc\").alias(\"SOC_FIRST\"),\n",
    "    F.col(\"last_soc\").alias(\"SOC_LAST\"),\n",
    "    F.col(\"total_soc_diff\").alias(\"SOC_DIFF\"),\n",
    "    F.col(\"count_points\").alias(\"NO_SOC_DATAPOINT\"),\n",
    "    F.col(\"is_usable_phase\").alias(\"IS_USABLE_PHASE\")\n",
    ")\n",
    "\n",
    "dynamic_config = s3.read_yaml_file(f\"config/{make}.yaml\")\n",
    "\n",
    "if dynamic_config is None:\n",
    "    raise ValueError(f\"Config file config/{make}.yaml not found\")\n",
    "\n",
    "    \n",
    "rss = s3.read_parquet_df_spark(spark, f'raw_ts/{make}/time_series/raw_ts_spark.parquet')\n",
    "rss_by_vin = rss.filter(rss['vin'] == vin)\n",
    "tss = rss.withColumnsRenamed(dynamic_config['raw_tss_to_processed_tss']['rename'])\n",
    "tss = tss.select(*dynamic_config['raw_tss_to_processed_tss']['keep'])  # Reduce column volumetry\n",
    "\n",
    "\n",
    "def _normalize_units_to_metric(tss, make):\n",
    "    tss = tss.withColumn(\"odometer\", col(\"odometer\") * ODOMETER_MILES_TO_KM.get(make, 1))\n",
    "    tss = tss.withColumn(\"soc\", F.col(\"soc\") * SCALE_SOC[make])\n",
    "    return tss\n",
    "\n",
    "\n",
    "tss = _normalize_units_to_metric(tss, make)\n",
    "\n",
    "# Alias pour plus de clarté\n",
    "ph = phase_df_processed.alias(\"ph\")\n",
    "ts = tss.alias(\"ts\")\n",
    "\n",
    "# Join condition\n",
    "join_condition = (\n",
    "    (ph[\"VIN_ph\"] == ts[\"vin\"]) &\n",
    "    (ts[\"date\"] >= ph[\"datetime_begin\"]) &\n",
    "    (ts[\"date\"] <= ph[\"datetime_end\"])\n",
    ")\n",
    "\n",
    "# Join explicite\n",
    "tss_phased = ph.join(ts, on=join_condition, how=\"left\")\n",
    "\n",
    "\n",
    "tss_phased = tss_phased.join(spark.createDataFrame(fleet_info), \"vin\", \"left\").drop(\"vin\").withColumnRenamed(\"VIN_ph\", \"VIN\")\n",
    "\n",
    "\n",
    "tss_phased.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "agg_columns = [\n",
    "    F.first(\"make\", ignorenulls=True).alias(\"MAKE\"),\n",
    "    F.first(\"model\", ignorenulls=True).alias(\"MODEL\"),\n",
    "    F.first(\"version\", ignorenulls=True).alias(\"VERSION\"),\n",
    "    F.first(\"net_capacity\", ignorenulls=True).alias(\"BATTERY_NET_CAPACITY\"),\n",
    "    F.first(\"odometer\", ignorenulls=True).alias(\"ODOMETER_FIRST\"),\n",
    "    F.last(\"odometer\", ignorenulls=True).alias(\"ODOMETER_LAST\")\n",
    "]\n",
    "\n",
    "if \"consumption\" in tss_phased.columns:\n",
    "    agg_columns.append(F.mean(\"consumption\").alias(\"CONSUMPTION\"))\n",
    "\n",
    "df_final = (\n",
    "    tss_phased.groupBy(\"VIN\", \"PHASE_INDEX\", \"DATETIME_BEGIN\", \"DATETIME_END\", \"PHASE_STATUS\", \"SOC_FIRST\", \"SOC_LAST\", \"SOC_DIFF\", \"NO_SOC_DATAPOINT\", \"IS_USABLE_PHASE\")\n",
    "    .agg(*agg_columns)\n",
    ")\n",
    "\n",
    "df_final.sort(\"DATETIME_BEGIN\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.spark_utils import create_spark_session\n",
    "from core.s3.s3_utils import S3Service\n",
    "from core.s3.settings import S3Settings\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, lead, sum, when, col, signum, dense_rank\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import DataFrame as DF\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "settings = S3Settings()\n",
    "\n",
    "spark = create_spark_session(\n",
    "    settings.S3_KEY,\n",
    "    settings.S3_SECRET\n",
    ")\n",
    "\n",
    "s3 = S3Service()\n",
    "\n",
    "tss = s3.read_parquet_df_spark(spark, 'raw_ts/volkswagen/time_series/raw_ts_spark.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tss.filter(col('SOH_OEM').isNotNull()).show()\n",
    "print(tss.printSchema())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

