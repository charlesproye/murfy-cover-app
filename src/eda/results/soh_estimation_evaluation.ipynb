{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "from core.pandas_utils import *\n",
    "from core.stats_utils import *\n",
    "from transform.raw_results.tesla_results import get_results\n",
    "from transform.raw_results.get_tesla_soh_readouts import get_aviloo_soh_readouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_parquet(\"data_cache/tesla_results.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in subtract\")\n",
    "\n",
    "BASE_SLOPE = 0.8 / 1e4 # base soh loss per kilometer\n",
    "\n",
    "def evaluate_esimtations(results:DF, soh_cols:list[str]) -> DF:\n",
    "    # This is an ugly pd.concat call but it's the first working I found :-)\n",
    "    return pd.concat(\n",
    "        {soh_col: evaluate_single_estimation(results, soh_col, get_aviloo_soh_readouts()) for soh_col in soh_cols},\n",
    "        axis=\"columns\"\n",
    "    ).T\n",
    "\n",
    "def evaluate_single_estimation(results:DF, soh_col:DF, aviloo_soh_readouts:DF) -> DF:\n",
    "    results_grp = results.groupby(\"vin\")\n",
    "    lr_params:DF = results_grp.apply(lr_params_as_series, \"odometer\", soh_col, include_groups=False).reset_index(drop=False)\n",
    "    results:DF = (\n",
    "        results\n",
    "        .merge(lr_params, on=\"vin\", how=\"left\")\n",
    "        .eval(\"lr_soh = odometer * slope + intercept\")\n",
    "        .eval(f\"soh_lr_diff = {soh_col} - lr_soh\")\n",
    "        .groupby(\"vin\")\n",
    "        .agg(**{\n",
    "            \"std_soh_lr_diff\":pd.NamedAgg(\"soh_lr_diff\", \"std\"),\n",
    "            \"nb_soh_counts\":pd.NamedAgg(soh_col, \"count\"),\n",
    "            soh_col:pd.NamedAgg(soh_col, \"median\"),\n",
    "        })\n",
    "        .eval(\"std_soh_lr_diff = std_soh_lr_diff.where(nb_soh_counts > 2)\") # Set to NaN std_soh_lr_diffs of vehicles because their std will always be ~0.\n",
    "    )\n",
    "    # Compute the mean of std from the soh points per charge rather than per vehicle so that the vehicles with more charges count more.\n",
    "    evaluation = (\n",
    "        results\n",
    "        .merge(lr_params, on=\"vin\", how=\"left\")# yes I know I already merged into it..,\n",
    "        .merge(aviloo_soh_readouts[[\"vin\", \"soh_readout\"]], on=\"vin\", how=\"left\")\n",
    "        .assign(abs_soh_residual=lambda df: (df[soh_col] - df[\"soh_readout\"]).abs()) # Have to use assign because .abs() does not work in eval call, idk why...\n",
    "        .assign(abs_diff_to_base_trendline=lambda df: (df[\"slope\"] - BASE_SLOPE).abs())\n",
    "        .agg({\n",
    "            \"abs_diff_to_base_trendline\": \"mean\",\n",
    "            \"abs_soh_residual\": \"mean\",\n",
    "        })\n",
    "    )\n",
    "    evaluation[\"soh_std_mean\"] = results[\"std_soh_lr_diff\"].mean() \n",
    "    return evaluation\n",
    "\n",
    "evaluations = evaluate_esimtations(results, [\"soh\"])\n",
    "evaluations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

