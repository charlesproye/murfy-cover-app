{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.gsheet_utils import *\n",
    "from rapidfuzz import process, fuzz\n",
    "from core.sql_utils import *\n",
    "from load.trendline.trendline_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_sqlalchemy_engine()\n",
    "con = engine.connect()\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    dbeaver_df = pd.read_sql(text(\"\"\"SELECT vm.model_name, vm.id, vm.type, o.oem_name, b.capacity FROM vehicle_model vm\n",
    "                                  join OEM o on vm.oem_id=o.id\n",
    "                                  join battery b on b.id=vm.battery_id;\"\"\"), con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_excel_data(get_gspread_client(), \"202505 - Courbes SoH\", \"Courbes OS\")\n",
    "df_sheet = pd.DataFrame(columns=df[0,:8], data=df[1:,:8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_db_type(row, db_df):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): \n",
    "        db_df (pd.DataFrame): dataframe avec les colonnes model_name, id, type, oem_name, capacity\n",
    "\n",
    "    Returns:\n",
    "        uuid.UUID: id du modèle\n",
    "    \"\"\"\n",
    "\n",
    "    #On récupère les infos \n",
    "    oem = row['OEM'].lower()\n",
    "    model_target = row['Modèle'].lower()\n",
    "    version_target = row['Type'].lower()\n",
    "    # filtre sur l'oem \n",
    "    subset = db_df[db_df['oem_name'] == oem].copy()\n",
    "    \n",
    "    # Trouver la meilleure correspondance\n",
    "    match_model = process.extractOne(model_target, subset['model_name'], scorer=fuzz.token_sort_ratio)\n",
    "    if match_model :\n",
    "        match_model_name, score, index = match_model\n",
    "        # filtre sur le nom du modèle\n",
    "        subset = subset[subset['model_name']==match_model_name]\n",
    "        # on cherche la batetrie qui avec la capacité la + proche\n",
    "        if row['battery_capacity'] != 'unknown':\n",
    "            battery_target = float(row['battery_capacity'].replace('kWh', '').replace('kwh', '').strip())\n",
    "            subset[\"distance\"] = (subset[\"capacity\"] - battery_target).abs()\n",
    "            min_distance = subset[\"distance\"].min()\n",
    "            closest_rows = subset[subset[\"distance\"] == min_distance]\n",
    "            # Si +sieurs batterie -> type le plus ressemblant\n",
    "            match_type = process.extractOne(version_target, closest_rows['type'], scorer=fuzz.token_sort_ratio)\n",
    "            match_model_type, score, index = match_type\n",
    "            return closest_rows.loc[index, \"id\"]\n",
    "\n",
    "        else:  \n",
    "            if subset['type'] is None:\n",
    "                 return None\n",
    "            \n",
    "            # type le plus ressemblant\n",
    "            match_type = process.extractOne(version_target, subset['type'], scorer=fuzz.token_sort_ratio)\n",
    "            match_model_type, score, index = match_type\n",
    "            return subset.loc[index, \"id\"]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sheet['model_id'] = df_sheet.apply(lambda row: find_db_type(row, dbeaver_df), axis=1)\n",
    "df_sheet['model_id'] = df_sheet['model_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sheet['SoH'] = df_sheet['SoH'].apply(lambda x:  x.replace('%', '').strip()).astype(float) / 100\n",
    "df_sheet['Odomètre (km)'] = df_sheet['Odomètre (km)'].apply(lambda x:  str(x).replace(' ', '').strip()).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "def trendline_apply(x, f):\n",
    "    return eval(f)\n",
    "\n",
    "def graph(df, trendline, trendline_max, trendline_min, model):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['Odomètre (km)'],\n",
    "        y=df['SoH'],\n",
    "        mode='markers',\n",
    "        marker_color='rgba(50, 182, 193, .9)',\n",
    "        name='SoH compute'\n",
    "    ))\n",
    "\n",
    "    x_sorted = df['Odomètre (km)'].sort_values()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_sorted,\n",
    "        y=trendline_apply(x_sorted, trendline['trendline']),\n",
    "        mode='lines',\n",
    "        line=dict(color='red'),\n",
    "        name='Fit'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_sorted,\n",
    "        y=trendline_apply(x_sorted, trendline_max['trendline']),\n",
    "        mode='lines',\n",
    "        line=dict(color='green'),\n",
    "        name='Upper'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_sorted,\n",
    "        y=trendline_apply(x_sorted, trendline_min['trendline']),\n",
    "        mode='lines',\n",
    "        line=dict(color='green'),\n",
    "        name='Lower'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        xaxis_title='Odometer',\n",
    "        yaxis_title='State of Health (SoH)',\n",
    "        legend_title='Légende',\n",
    "        title=f\"version: {model}\",\n",
    "        template='plotly_white',\n",
    "        xaxis=dict(range=[0, 150000]),  # Change selon l'échelle souhaitée pour l'odomètre\n",
    "        yaxis=dict(range=[.75, 1.1])     # Change selon l'échelle souhaitée pour le SoH\n",
    "    )\n",
    "    \n",
    "\n",
    "    return fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r110 = df_sheet[df_sheet['model_id']=='6fd1ed33-128b-4b99-a2bf-e01f992e6cf9']\n",
    "df_q210 = df_sheet[df_sheet['model_id']=='6fbdaf91-ff62-4617-b4bb-ca37bfa406ab']\n",
    "df_spring65 = df_sheet[df_sheet['model_id'].isin([\"057e888d-4160-413d-98b2-0a3b75ab9b82\", '9f4fca9a-0e8b-4570-8271-1b8be68e6607'])]\n",
    "df_spring45 = df_sheet[df_sheet['model_id'].isin(([\"9f4fca9a-0e8b-4570-8271-1b8be68e6607\", \"c45d46f3-9327-4308-86d9-ae554979d6ab\"]))]\n",
    "df_208 = df_sheet[df_sheet['model_id']=='94d3310b-b9ac-463f-8a0a-303f492abee3']\n",
    "df_2008 = df_sheet[df_sheet['model_id']=='cc16301c-84a4-43cf-8842-44e4e71df338']\n",
    "df_niro = df_sheet[df_sheet['model_id']=='b84f6c00-a53b-4406-bfef-4a758a2d00e4']\n",
    "df_mini = df_sheet[df_sheet['model_id']=='18e1c778-9260-4d5d-8fcd-61b2d009923f']\n",
    "df_leaf = df_sheet[df_sheet['model_id']=='20b3a708-b621-408d-96b5-3f7bf7222986']\n",
    "df_r90 = df_sheet[df_sheet['model_id'].isin(['f7ecad76-de51-4e72-92ba-4f0c6817cc1e', 'f8ec7f9c-1f50-490d-b243-96c689806edb'])]\n",
    "\n",
    "df_kona = df_sheet[df_sheet['model_id']=='00291455-6521-4256-978b-6aa692837573']\n",
    "\n",
    "df_twingo = df_sheet[df_sheet['model_id']=='41a4dc56-3b62-43e8-bb0a-eec6b7c42510']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = [df_r110, df_q210, df_spring65, df_spring45, df_208, df_2008, df_niro, df_mini, df_leaf, df_r90, df_kona, df_twingo, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# --- 1. Charger les données ---\n",
    "df = list_df[0]  # Remplace par ton chemin si nécessaire\n",
    "df = df[df['SoH'] > .8]\n",
    "x_data, y_data = df[\"Odomètre (km)\"].values, df[\"SoH\"].values\n",
    "x_data = np.hstack((x_data, np.array([0])))\n",
    "y_data = np.hstack((y_data, np.array([1])))\n",
    "sort_idx = np.argsort(x_data)\n",
    "x_sorted, y_sorted = x_data[sort_idx], y_data[sort_idx]\n",
    "coef_mean, _ = curve_fit(log_function, x_sorted, y_sorted, maxfev=10000, bounds=([.97, -np.inf, -np.inf], [1.03, np.inf, np.inf]))\n",
    "print(coef_mean)\n",
    "x = df[\"Odomètre (km)\"].values\n",
    "y = df[\"SoH\"].values\n",
    "\n",
    "# --- 2. Paramètre fixe ---\n",
    "a =coef_mean[2]  # Peut être ajusté plus tard\n",
    "\n",
    "# --- 3. Transformation de x ---\n",
    "X_trans = np.log1p(x / a)\n",
    "X_design = sm.add_constant(X_trans)  # Ajoute l’intercept\n",
    "\n",
    "# --- 4. Régression linéaire ---\n",
    "model = sm.OLS(y, X_design).fit()\n",
    "\n",
    "# --- 5. Prédictions et IC 95% ---\n",
    "x_pred = np.linspace(x.min(), x.max(), 300)\n",
    "x_pred_trans = np.log1p(x_pred / a)\n",
    "X_pred_design = sm.add_constant(x_pred_trans)\n",
    "pred = model.get_prediction(X_pred_design)\n",
    "pred_summary = pred.summary_frame(alpha=0.05)\n",
    "\n",
    "# --- 6. Tracé ---\n",
    "mean = pred_summary[\"mean\"].astype(float).values\n",
    "ci_lower = pred_summary[\"mean_ci_lower\"].astype(float).values\n",
    "ci_upper = pred_summary[\"mean_ci_upper\"].astype(float).values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, label=\"Données réelles\", alpha=0.7)\n",
    "plt.plot(x_pred, mean, color=\"red\", label=\"Trendline\")\n",
    "plt.fill_between(x_pred, ci_lower, ci_upper, color=\"red\", alpha=0.3, label=\"IC 95%\")\n",
    "plt.xlabel(\"Odomètre (km)\")\n",
    "plt.ylabel(\"SoH\")\n",
    "plt.title(\"Trendline avec intervalle de confiance à 95%\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 7. Affichage des résultats ---\n",
    "print(\"Coefficients estimés :\")\n",
    "print(model.params)\n",
    "\n",
    "print(\"\\nIntervalles de confiance (95%) :\")\n",
    "print(model.conf_int())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_battery_data(df, soh_colum, odometer_column):\n",
    "    \"\"\"\n",
    "    Nettoie les données de batterie en supprimant les valeurs aberrantes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame contenant les données de batterie avec des colonnes pour l'odomètre et le SoH\n",
    "    soh_column: str\n",
    "        Nom de la colonne qui contient les SoH\n",
    "    odometer_column: str\n",
    "        Nom de la colonne qui contient l'info sur l'odomètre\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame nettoyé\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    df_clean = df_clean.rename(columns={odometer_column: 'odometer', soh_colum: 'soh'})\n",
    "    df_clean = df_clean.drop(df_clean[(df_clean['odometer'] < 20000) & (df_clean['soh'] < .95)].index)\n",
    "    df_clean = df_clean.drop(df_clean[(df_clean['soh'] < .8)].index)\n",
    "    df_clean = df_clean.dropna(subset=[\"soh\", \"odometer\"])\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def get_model_name(df, dbeaver_df):\n",
    "    \"\"\"\n",
    "    Récupère le nom du modèle à partir de l'ID du modèle.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame contenant la colonne 'model_id'\n",
    "    dbeaver_df : pandas.DataFrame\n",
    "        DataFrame de référence avec colonnes 'id', 'model_name', 'type'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Nom complet du modèle\n",
    "    \"\"\"\n",
    "    id = df['model_id'].unique()\n",
    "    model = f\"{dbeaver_df[dbeaver_df['id'].astype(str) == str(id[0])]['model_name'].values[0]} {dbeaver_df[dbeaver_df['id'].astype(str) == str(id[0])]['type'].values[0]}\"\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_data_for_fitting(df):\n",
    "    \"\"\"\n",
    "    Prépare les données pour le fitting en ajoutant le point d'origine et en triant.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame avec colonnes 'odometer' et 'SoH'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (x_sorted, y_sorted) - données triées prêtes pour le fitting\n",
    "    \"\"\"\n",
    "    x_data, y_data = df[\"odometer\"].values, df[\"soh\"].values\n",
    "    x_data = np.hstack((x_data, np.array([0])))\n",
    "    y_data = np.hstack((y_data, np.array([1])))\n",
    "    sort_idx = np.argsort(x_data)\n",
    "    x_sorted, y_sorted = x_data[sort_idx], y_data[sort_idx]\n",
    "    return x_sorted, y_sorted\n",
    "\n",
    "\n",
    "def compute_main_trendline(x_sorted, y_sorted):\n",
    "    \"\"\"\n",
    "    Calcule la ligne de tendance principale et les bornes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x_sorted : numpy.array\n",
    "        Données x triées\n",
    "    y_sorted : numpy.array\n",
    "        Données y triées\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (coef_mean, coef_lower, coef_upper, mean, upper, lower)\n",
    "    \"\"\"\n",
    "    coef_mean, _ = curve_fit(log_function, x_sorted, y_sorted, maxfev=10000, \n",
    "                           bounds=([.97, -np.inf, -np.inf], [1.03, np.inf, np.inf]))\n",
    "    y_fit = log_function(x_sorted, *coef_mean)\n",
    "    y_lower, y_upper = compute_trendline_bounds(y_sorted, y_fit)\n",
    "    print(y_lower, y_upper)\n",
    "    coef_lower, coef_upper = get_bound_coef(x_sorted, y_lower, y_upper)\n",
    "    mean, upper, lower = build_trendline_expressions(coef_mean, coef_lower, coef_upper, y_lower, y_upper)\n",
    "    return coef_mean, coef_lower, coef_upper,  mean, upper, lower\n",
    "\n",
    "\n",
    "def compute_upper_bound(df, trendline, coef_mean):\n",
    "    \"\"\"\n",
    "    Calcule la borne supérieure si nécessaire.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame des données\n",
    "    trendline : str\n",
    "        Equation de la trendline moyenne\n",
    "    coef_mean : numpy.array\n",
    "        Coefficients moyens\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict or None\n",
    "        Borne supérieure calculée ou None\n",
    "    \"\"\"\n",
    "    mask = eval(trendline['trendline'], {\"np\": np, \"x\": df[\"odometer\"]})\n",
    "    test = df[df['soh'] > mask]\n",
    "    x_sorted, y_sorted = prepare_data_for_fitting(test)\n",
    "    \n",
    "    coef_mean_upper, _ = curve_fit(log_function, x_sorted, y_sorted, maxfev=10000, \n",
    "                                bounds=([.97, -np.inf, -np.inf], [1.03, np.inf, np.inf]))\n",
    "    y_fit = log_function(x_sorted, *coef_mean_upper)\n",
    "    y_lower, y_upper = compute_trendline_bounds(y_sorted, y_fit)\n",
    "    coef_lower_borne_sup, coef_upper_borne_sup = get_bound_coef(x_sorted, y_lower, y_upper, coef_mean[0])\n",
    "    new_upper = build_trendline_expressions(coef_mean, coef_lower_borne_sup, coef_upper_borne_sup, y_lower, y_upper)\n",
    "    upper_bound = new_upper[1]\n",
    "    return upper_bound\n",
    "\n",
    "\n",
    "\n",
    "def compute_lower_bound(df, trendlines):\n",
    "    \"\"\"\n",
    "    Calcule la borne inférieure si nécessaire.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame des données nettoyées\n",
    "    coef_lower : numpy.array\n",
    "        Coefficients de la borne inférieure\n",
    "    trendlines : list\n",
    "        Liste des lignes de tendance\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict or None\n",
    "        Borne inférieure calculée ou None\n",
    "    \"\"\"\n",
    "\n",
    "    mask = eval(trendlines['trendline'], {\"np\": np, \"x\": df[\"odometer\"]})\n",
    "    test = df[df['soh'] < mask]\n",
    "    x_sorted, y_sorted = prepare_data_for_fitting(test)\n",
    "    \n",
    "    coef_mean_upper, _ = curve_fit(log_function, x_sorted, y_sorted, maxfev=10000, \n",
    "                                bounds=([.97, -np.inf, -np.inf], [1.03, np.inf, np.inf]))\n",
    "    y_fit = log_function(x_sorted, *coef_mean_upper)\n",
    "    y_lower, y_upper = compute_trendline_bounds(y_sorted, y_fit)\n",
    "    coef_lower_borne_sup, coef_upper_borne_sup = get_bound_coef( x_sorted, y_lower, y_upper, coef_mean[0],)\n",
    "    new_upper = build_trendline_expressions(coef_mean, coef_lower_borne_sup, coef_upper_borne_sup, y_lower, y_upper)\n",
    "    upper_bound = new_upper[1]\n",
    "    return upper_bound\n",
    "\n",
    "\n",
    "\n",
    "def process_battery_data(df, dbeaver_df):\n",
    "    \"\"\"\n",
    "    Traite les données de batterie pour un DataFrame donné.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame contenant les données de batterie avec colonnes 'odometer', 'SoH', 'model_id'\n",
    "    dbeaver_df : pandas.DataFrame\n",
    "        DataFrame de référence contenant les informations des modèles avec colonnes 'id', 'model_name', 'type'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionnaire contenant les résultats du traitement:\n",
    "        - 'model': nom du modèle\n",
    "        - 'trendlines': lignes de tendance principales\n",
    "        - 'upper_bound': borne supérieure (si calculée)\n",
    "        - 'lower_bound': borne inférieure (si calculée)\n",
    "        - 'processed_df': DataFrame après nettoyage\n",
    "    \"\"\"\n",
    "    \n",
    "    # Étape 1: Nettoyage des données\n",
    "    df_clean = clean_battery_data(df)\n",
    "    \n",
    "    # Étape 2: Récupération du nom du modèle\n",
    "    model = get_model_name(df_clean, dbeaver_df)\n",
    "    \n",
    "    # Étape 3: Préparation des données pour le fitting\n",
    "    x_sorted, y_sorted = prepare_data_for_fitting(df_clean)\n",
    "    \n",
    "    # Étape 4: Calcul de la ligne de tendance principale\n",
    "    coef_mean, coef_lower, coef_upper, mean, upper, lower = compute_main_trendline(x_sorted, y_sorted)\n",
    "    \n",
    "    # Étape 5: Calcul des bornes si nécessaire\n",
    "    upper_bound = compute_upper_bound(df_clean, trendlines, coef_mean)\n",
    "    lower_bound = compute_lower_bound(df_clean, trendlines)\n",
    "    \n",
    "    # Étape 6: Génération du graphique\n",
    "    graph(df_clean, mean, upper, lower, model)\n",
    "    \n",
    "    # Retour des résultats\n",
    "    return {\n",
    "        'model': model,\n",
    "        'trendlines': trendlines,\n",
    "        'upper_bound': upper_bound,\n",
    "        'lower_bound': lower_bound,\n",
    "        'processed_df': df_clean\n",
    "    }\n",
    "\n",
    "\n",
    "def process_all_battery_data(list_df, dbeaver_df):\n",
    "    \"\"\"\n",
    "    Traite tous les DataFrames de la liste.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    list_df : list\n",
    "        Liste des DataFrames à traiter\n",
    "    dbeaver_df : pandas.DataFrame\n",
    "        DataFrame de référence pour les informations des modèles\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Liste des résultats pour chaque DataFrame traité\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for df in list_df:\n",
    "        result = process_battery_data(df, dbeaver_df)\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trendline_functions(df, odometer_column, soh_column):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Liste des résultats pour chaque DataFrame traité\n",
    "    \"\"\"\n",
    "    df_clean = clean_battery_data(df, odometer_column, soh_column)\n",
    "    if df_clean.shape[0] < 20:\n",
    "        return \"Can't compute trendline\"\n",
    "    x_data, y_data = prepare_data_for_fitting(df_clean)\n",
    "    coef_mean, coef_lower, coef_upper, mean, upper_bound, lower_bound = compute_main_trendline(x_data, y_data)\n",
    "    if coef_upper[0] >= 0:\n",
    "        upper_bound = compute_upper_bound(df_clean, mean, coef_mean)\n",
    "    if  coef_lower[0] >= 0:\n",
    "        lower_bound = compute_lower_bound(df_clean, mean)\n",
    "    return mean, upper_bound, lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_car in df_merge['Modèle'].unique():\n",
    "    print(model_car)\n",
    "    for type_car in df_merge[df_merge['Modèle']==model_car].type.unique():\n",
    "        mean, upper_bound, lower_bound = generate_trendline_functions(df_merge[(df_merge['Modèle']==model_car) & (df_merge['type']==type_car)], 'Odomètre (km)', \"SoH\")\n",
    "        print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_vehicules_type(type_car, oem_name, model_name, db_df, battery_capacity=None):\n",
    "    \"\"\"Permet d'uniformiser les types de véhicules avec ceux présent dans la db \n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): avec les infos du vin min required column: oem, Modèle, Type \n",
    "        db_df (pd.DataFrame): dataframe avec les colonnes model_name, id, type, oem_name, capacity\n",
    "\n",
    "    Returns:\n",
    "        str: type du modèle présent sur dbeaver\n",
    "    \"\"\"\n",
    "\n",
    "#__________ Faire tourner cette requête en dehors pour récupérer les infos nécessaires sur la db_________\n",
    "# from core.sql_utils import *\n",
    "# engine = get_sqlalchemy_engine()\n",
    "# con = engine.connect()\n",
    "\n",
    "# with engine.connect() as connection:\n",
    "#     dbeaver_df = pd.read_sql(text(\"\"\"SELECT vm.model_name, vm.id, vm.type, o.oem_name, b.capacity FROM vehicle_model vm\n",
    "#                                   join OEM o on vm.oem_id=o.id\n",
    "#                                   join battery b on b.id=vm.battery_id;\"\"\"), con)\n",
    "#___________________________________________________________________________________________________________\n",
    "\n",
    "    \n",
    "    #On récupère les infos\n",
    "    oem_name = oem_name.lower()\n",
    "    model_name = model_name.lower()\n",
    "    type_car = type_car.lower()\n",
    "    # filtre sur l'oem \n",
    "    subset = db_df[db_df['oem_name'] == oem_name].copy()\n",
    "    # Trouver la meilleure correspondance\n",
    "    # Retourne le modèle le plus proche score_cutoff fixé a 0 pour le moment pour être sur d'avoir un retour\n",
    "    match_model = process.extractOne(model_name, subset['model_name'], scorer=fuzz.token_sort_ratio)\n",
    "    if match_model :\n",
    "        match_model_name, score, index = match_model\n",
    "        # filtre sur le nom du modèle\n",
    "        subset = subset[subset['model_name']==match_model_name]\n",
    "        # on cherche la batetrie avec la capacité la + proche\n",
    "        try:\n",
    "            battery_target = float(battery_capacity.replace('kWh', '').replace('kwh', '').strip())\n",
    "            subset[\"distance\"] = (subset[\"capacity\"] - battery_target).abs()\n",
    "            min_distance = subset[\"distance\"].min()\n",
    "            closest_rows = subset[subset[\"distance\"] == min_distance]\n",
    "            # Si +sieurs batterie -> type le plus ressemblant\n",
    "            match_type = process.extractOne(type_car, closest_rows['type'], scorer=fuzz.token_sort_ratio)\n",
    "            match_model_type, score, index = match_type\n",
    "            return closest_rows.loc[index, \"type\"]\n",
    "        \n",
    "        # type le plus ressemblant sans batterie \n",
    "        except:\n",
    "            match_type = process.extractOne(type_car, subset['type'], scorer=fuzz.token_sort_ratio)\n",
    "            match_model_type, score, index = match_type\n",
    "            return subset.loc[index, \"type\"]\n",
    "        \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeaver_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sheet['OEM'] = df_sheet['OEM'].apply(str.lower)\n",
    "df_sheet['Modèle'] = df_sheet['Modèle'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_sqlalchemy_engine()\n",
    "con = engine.connect()\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    dbeaver_df = pd.read_sql(text(\"\"\"SELECT vm.model_name, vm.id, vm.type, o.oem_name, b.capacity, vm.battery_id FROM vehicle_model vm\n",
    "                                  join OEM o on vm.oem_id=o.id\n",
    "                                  join battery b on b.id=vm.battery_id;\"\"\"), con)\n",
    "\n",
    "df = load_excel_data(get_gspread_client(), \"202505 - Courbes SoH\", \"Courbes OS\")\n",
    "df_sheet = pd.DataFrame(columns=df[0,:8], data=df[1:,:8])\n",
    "df_sheet['SoH'] = df_sheet['SoH'].apply(lambda x:  x.replace('%', '').strip()).astype(float) / 100\n",
    "df_sheet['Odomètre (km)'] = df_sheet['Odomètre (km)'].apply(lambda x:  str(x).replace(' ', '').strip()).astype(float)\n",
    "df_sheet['type'] = df_sheet.apply(lambda row: uniform_vehicules_type(row['Type'], row['OEM'], str(row['Modèle']),dbeaver_df,  row['battery_capacity']), axis=1)\n",
    "df_sheet['Modèle'] = df_sheet['Modèle'].apply(lambda x: x.lower())\n",
    "df_merge = df_sheet.merge(dbeaver_df[['model_name', \"type\", 'battery_id']], left_on=['Modèle', \"type\"], right_on=['model_name', 'type'])\n",
    "df_merge['type'] = df_merge.groupby(['model_name', 'battery_id'])['type'].transform('first')\n",
    "\n",
    "for model_car in df_merge['Modèle'].unique()[:1]:\n",
    "    print(model_car)\n",
    "    for type_car in df_merge[df_merge['Modèle']==model_car].type.unique():\n",
    "        print(type_car)\n",
    "        df_clean = clean_battery_data(df_merge[(df_merge['Modèle']==model_car) & (df_merge['type']==type_car)], \"SoH\", 'Odomètre (km)')\n",
    "        x_data, y_data = prepare_data_for_fitting(df_clean)\n",
    "        print(x_data)\n",
    "        print(y_data)\n",
    "        coef_mean, coef_lower, coef_upper, mean, upper_bound, lower_bound = compute_main_trendline(x_data, y_data)\n",
    "        if coef_upper[0] >= 0:\n",
    "            print('ici')\n",
    "            upper_bound = compute_upper_bound(df_clean, mean, coef_mean)\n",
    "        if  coef_lower[0] >= 0:\n",
    "            print('la')\n",
    "            lower_bound = compute_lower_bound(df_clean, mean)\n",
    "        # graph(df, mean, upper_bound, lower_bound, model)\n",
    "        print(mean, upper_bound, lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"edrive35\", \"73 kwh\", \"73 kwh dual motor\", \"sr awd\", \"performance awd\", \"wd\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"73 kwh dual motor\": \"73 kwh\",\n",
    "    \"120ah\": \"120 ah\",\n",
    "    \"94ah\": \"94 ah\",\n",
    "    \"64kwh\": \"64 kwh\",\n",
    "    \"electric 45\": \"electric\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_vehicules_type(type_car, oem_name, model_name, db_df, battery_capacity=None):\n",
    "    \"\"\"Permet d'uniformiser les types de véhicules avec ceux présent dans la db \n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): avec les infos du vin min required column: oem, Modèle, Type \n",
    "        db_df (pd.DataFrame): dataframe avec les colonnes model_name, id, type, oem_name, capacity\n",
    "\n",
    "    Returns:\n",
    "        str: type du modèle présent sur dbeaver\n",
    "    \"\"\"\n",
    "\n",
    "#__________ Faire tourner cette requête en dehors pour récupérer les infos nécessaires sur la db_________\n",
    "# from core.sql_utils import *\n",
    "# engine = get_sqlalchemy_engine()\n",
    "# con = engine.connect()\n",
    "\n",
    "# with engine.connect() as connection:\n",
    "#     dbeaver_df = pd.read_sql(text(\"\"\"SELECT vm.model_name, vm.id, vm.type, o.oem_name, b.capacity FROM vehicle_model vm\n",
    "#                                   join OEM o on vm.oem_id=o.id\n",
    "#                                   join battery b on b.id=vm.battery_id;\"\"\"), con)\n",
    "#___________________________________________________________________________________________________________\n",
    "\n",
    "    \n",
    "    #On récupère les infos\n",
    "    oem_name = oem_name.lower()\n",
    "    model_name = model_name.lower()\n",
    "    type_car = type_car.lower()\n",
    "    # filtre sur l'oem \n",
    "    subset = db_df[db_df['oem_name'] == oem_name].copy()\n",
    "    # Trouver la meilleure correspondance\n",
    "    # Retourne le modèle le plus proche score_cutoff fixé a 0 pour le moment pour être sur d'avoir un retour\n",
    "    match_model = process.extractOne(model_name, subset['model_name'], scorer=fuzz.token_sort_ratio)\n",
    "    if match_model :\n",
    "        match_model_name, score, index = match_model\n",
    "        # filtre sur le nom du modèle\n",
    "        subset = subset[subset['model_name']==match_model_name]\n",
    "        # on cherche la batetrie avec la capacité la + proche\n",
    "        try:\n",
    "            battery_target = float(battery_capacity.replace('kWh', '').replace('kwh', '').strip())\n",
    "            subset[\"distance\"] = (subset[\"capacity\"] - battery_target).abs()\n",
    "            min_distance = subset[\"distance\"].min()\n",
    "            closest_rows = subset[subset[\"distance\"] == min_distance]\n",
    "            # Si +sieurs batterie -> type le plus ressemblant\n",
    "            match_type = process.extractOne(type_car, closest_rows['type'], scorer=fuzz.token_sort_ratio)\n",
    "            match_model_type, score, index = match_type\n",
    "            return closest_rows.loc[index, \"type\"]\n",
    "        \n",
    "        # type le plus ressemblant sans batterie \n",
    "        except:\n",
    "            match_type = process.extractOne(type_car, subset['type'], scorer=fuzz.token_sort_ratio)\n",
    "            match_model_type, score, index = match_type\n",
    "            return subset.loc[index, \"type\"]\n",
    "        \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#### Matching types ########\n",
    "engine = get_sqlalchemy_engine()\n",
    "con = engine.connect()\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    dbeaver_df = pd.read_sql(text(\"\"\"SELECT vm.model_name, vm.id, vm.type, vm.battery_id, o.oem_name, b.capacity  FROM vehicle_model vm\n",
    "                                  join OEM o on vm.oem_id=o.id\n",
    "                                  join battery b on b.id=vm.battery_id;\"\"\"), con)\n",
    "\n",
    "df_sheet['type'] = df_sheet.apply(lambda row: uniform_vehicules_type(row['Type'], row['OEM'], str(row['Modèle']),dbeaver_df,  row['battery_capacity']), axis=1)\n",
    "df_sheet['Modèle'] = df_sheet['Modèle'].apply(lambda x: x.lower())\n",
    "df_merge = df_sheet.merge(dbeaver_df[['model_name', \"type\", 'battery_id']], left_on=['Modèle', \"type\"], right_on=['model_name', 'type'])\n",
    "df_merge['type'] = df_merge.groupby(['model_name', 'battery_id'])['type'].transform('first')\n",
    "for model_car in df_merge['Modèle'].unique():\n",
    "    for type_car in df_merge[df_merge['Modèle']==model_car].type.unique():\n",
    "        print(generate_trendline_functions(df_merge[(df_merge['Modèle']==model_car) & (df_merge['type']==type_car)], \"Odomètre (km)\", \"SoH\"))\n",
    "            \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.gsheet_utils import *\n",
    "from rapidfuzz import process, fuzz\n",
    "from core.sql_utils import *\n",
    "from load.trendline.trendline_utils import *\n",
    "def generate_trendline_functions(df, odometer_column, soh_column):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe with SoH and Odometer column\n",
    "    soh_column: str\n",
    "        Nom de la colonne qui contient les SoH\n",
    "    odometer_column: str\n",
    "        Nom de la colonne qui contient l'info sur l'odomètre\n",
    "    Returns:\n",
    "    --------\n",
    "    tupple\n",
    "        trendlines moyenne, borne supérieure et inférieure\n",
    "    \"\"\"\n",
    "    df_clean = clean_battery_data(df, odometer_column, soh_column)\n",
    "    if df_clean.shape[0] < 20:\n",
    "        raise Exception(\"Not enough data to compute trendline\")\n",
    "    x_data, y_data = prepare_data_for_fitting(df_clean)\n",
    "    coef_mean, coef_lower, coef_upper, mean, upper_bound, lower_bound = compute_main_trendline(x_data, y_data)\n",
    "    if coef_upper[0] >= 0:\n",
    "        upper_bound = compute_upper_bound(df_clean, mean, coef_mean)\n",
    "    if  coef_lower[0] >= 0:\n",
    "        lower_bound = compute_lower_bound(df_clean, mean, coef_mean)\n",
    "    return mean, upper_bound, lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_excel_data(get_gspread_client(), \"202505 - Courbes SoH\", \"Courbes OS\")\n",
    "df_sheet = pd.DataFrame(columns=df[0,:8], data=df[1:,:8])\n",
    "df_sheet[\"SoH\"] = df_sheet[\"SoH\"].apply(lambda x:  x.replace('%', '').strip()).astype(float) / 100\n",
    "df_sheet[\"Odomètre (km)\"] = df_sheet[\"Odomètre (km)\"].apply(lambda x:  str(x).replace(' ', '').strip()).astype(float)\n",
    "engine = get_sqlalchemy_engine()\n",
    "con = engine.connect()\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    dbeaver_df = pd.read_sql(text(\"\"\"SELECT vm.model_name, vm.id, vm.type, vm.battery_id, o.oem_name, b.capacity  FROM vehicle_model vm\n",
    "                                join OEM o on vm.oem_id=o.id\n",
    "                                join battery b on b.id=vm.battery_id;\"\"\"), con)\n",
    "\n",
    "### Matching type \n",
    "df_sheet['type'] = df_sheet.apply(lambda row: uniform_vehicules_type(row['Type'], row['OEM'], str(row['Modèle']), dbeaver_df,  row['battery_capacity']), axis=1)\n",
    "\n",
    "df_sheet['Modèle'] = df_sheet['Modèle'].apply(lambda x: x.lower())\n",
    "df_merge = df_sheet.merge(dbeaver_df[['model_name', \"type\", 'battery_id']], left_on=['Modèle', \"type\"], right_on=['model_name', 'type'])\n",
    "df_merge['type'] = df_merge.groupby(['model_name', 'battery_id'])['type'].transform('first')\n",
    "for model_car in df_merge['Modèle'].unique():\n",
    "    for type_car in df_merge[df_merge['Modèle']==model_car].type.unique():\n",
    "        if type_car:\n",
    "            print(type_car)\n",
    "            mean_trend, upper_boun, lower_bound = generate_trendline_functions(df_merge[(df_merge['Modèle']==model_car) & (df_merge['type']==type_car)], \"SoH\", \"Odomètre (km)\")\n",
    "            #update_database_trendlines(\"vehicle_model\", \"type\", type_car, mean_trend, upper_boun, lower_bound, False)\n",
    "            print('oueeee')\n",
    "            logging.info(f\"Trendline mise à jour pour {type_car}\")\n",
    "        else: \n",
    "            logging.error(f\"Erreur mise à jour trendline {type_car}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

