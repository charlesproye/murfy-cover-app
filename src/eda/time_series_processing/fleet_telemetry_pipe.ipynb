{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Notebook pour tester le pipe de fleet-telemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Raw tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.s3_utils import *\n",
    "from transform.raw_tss.fleet_telemetry_raw_tss import *\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from transform.processed_tss.config import *\n",
    "from core.constants import *\n",
    "from transform.raw_tss.config import *\n",
    "from transform.processed_tss.ProcessedTimeSeries import ProcessedTimeSeries\n",
    "from transform.raw_results.tesla_fleet_telemetry import get_results as get_results_origin\n",
    "from transform.processed_results.main import get_processed_results\n",
    "from datetime import timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_RAW_TSS_KEY_FORMAT = \"raw_ts/{brand}/time_series/raw_tss.parquet\"\n",
    "FLEET_TELEMETRY_RAW_TSS_KEY = S3_RAW_TSS_KEY_FORMAT.format(brand=\"tesla-fleet-telemetry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3_Bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_keys_to_parse(bucket:S3_Bucket) -> DF:\n",
    "    if bucket.check_file_exists(FLEET_TELEMETRY_RAW_TSS_KEY):\n",
    "        raw_tss_subset = bucket.read_parquet_df(FLEET_TELEMETRY_RAW_TSS_KEY, columns=[\"vin\", \"readable_date\"])\n",
    "    else:\n",
    "        raw_tss_subset = DEFAULT_TESLA_RAW_TSS_DF\n",
    "    last_parsed_date = (\n",
    "        raw_tss_subset\n",
    "        .groupby(\"vin\", observed=True, as_index=False)\n",
    "        # Use \"max\" instead of \"last\" as the keys are not sorted\n",
    "        .agg(last_parsed_date=pd.NamedAgg(\"readable_date\", \"max\"))\n",
    "    )\n",
    "    return (\n",
    "        bucket.list_responses_keys_of_brand(\"tesla-fleet-telemetry\")\n",
    "        .assign(date=lambda df: df[\"file\"].str[:-5].astype(\"datetime64[ns]\"))\n",
    "        .merge(last_parsed_date, \"outer\", \"vin\")\n",
    "        .query(\"last_parsed_date.isna() | date > last_parsed_date\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_tss(bucket: S3_Bucket = S3_Bucket()) -> DF:\n",
    "    logger.debug(\"Getting raw tss from responses provided by tesla fleet telemetry.\")\n",
    "    keys = get_response_keys_to_parse(bucket)\n",
    "    if bucket.check_file_exists(FLEET_TELEMETRY_RAW_TSS_KEY):\n",
    "        raw_tss = bucket.read_parquet_df(FLEET_TELEMETRY_RAW_TSS_KEY)\n",
    "        keys_to_parse = keys[keys['date'] >= pd.to_datetime((pd.to_datetime(raw_tss.readable_date.max()).date() - timedelta(days=1)))].copy()\n",
    "        new_raw_tss = get_raw_tss_from_keys(keys_to_parse, bucket)\n",
    "        return concat([new_raw_tss, new_raw_tss])\n",
    "    else:\n",
    "        new_raw_tss = get_raw_tss_from_keys(keys, bucket)\n",
    "        return new_raw_tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss = get_raw_tss(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss.sort_values('date').head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Processed tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_tss.ProcessedTimeSeries import ProcessedTimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TeslaProcessedTimeSeries(ProcessedTimeSeries):\n",
    "\n",
    "    def __init__(self, make:str=\"tesla\", id_col:str=\"vin\", log_level:str=\"INFO\", max_td:TD=MAX_TD, force_update:bool=False, **kwargs):\n",
    "        self.logger = getLogger(make)\n",
    "        set_level_of_loggers_with_prefix(log_level, make)\n",
    "        super().__init__(make, id_col, log_level, max_td, force_update, **kwargs)\n",
    "\n",
    "    def compute_charge_n_discharge_vars(self, tss:DF) -> DF:\n",
    "        return (\n",
    "            tss\n",
    "            .pipe(self.compute_charge_n_discharge_masks)\n",
    "            .pipe(self.compute_charge_idx_bis)\n",
    "            # .pipe(self.compute_idx_from_masks, [\"in_charge\"])\n",
    "            # .pipe(self.trim_leading_n_trailing_soc_off_masks, [\"in_charge\", \"in_discharge\"])\n",
    "            # # .pipe(self.compute_idx_from_masks, [\"trimmed_in_charge\", \"trimmed_in_discharge\"])\n",
    "        )\n",
    "\n",
    "    def compute_charge_n_discharge_masks(self, tss:DF) -> DF:\n",
    "        self.logger.debug(\"Computing tesla specific charge and discharge masks\")\n",
    "        # We use a nullable boolean Series to represnet the rows where:\n",
    "        tss[\"nan_charging\"] = (\n",
    "            Series(pd.NA, index=tss.index, dtype=\"boolean\")# We are not sure of anything.\n",
    "            .mask(tss[\"charging_status\"].isin(IN_CHARGE_CHARGING_STATUS_VALS), True)# We are sure that the vehicle is in charge.\n",
    "            .mask(tss[\"charging_status\"].isin(IN_DISCHARGE_CHARGING_STATUS_VALS), False)# We are sure that the vehicle is not in charge.\n",
    "        )\n",
    "        # If a period of uncertainty (NaN) is surrounded by equal periods of certainties (True-NaN-True or False-NaN-False),\n",
    "        # We will fill them to the value of these certainties.\n",
    "        # However there are edge cases that have multiple days of uncertainties periods (I can't find the VIN but I'm sure you can ;-) )\n",
    "        # Interestingly enough the charge_energy_added variable does not get forwared that far and gets reset to zero. \n",
    "        # This would create outliers in our charge SoH estimation as we estimate the energy_gained as the diff between the last(0) and first value of charge_energy_added.\n",
    "        # So we set a maximal uncertainty period duration over which we don't fill it.\n",
    "        tss[\"nan_date\"] = tss[\"date\"].mask(tss[\"nan_charging\"].isna())\n",
    "        tss[[\"ffill_charging\", \"ffill_date\"]] = tss.groupby(\"vin\", observed=True)[[\"nan_charging\", \"nan_date\"]].ffill()\n",
    "        tss[[\"bfill_charging\", \"bfill_date\"]] = tss.groupby(\"vin\", observed=True)[[\"nan_charging\", \"nan_date\"]].bfill()\n",
    "        nan_period_duration:Series = tss.eval(\"bfill_date - ffill_date\")\n",
    "        fill_unknown_period = tss.eval(\"ffill_charging.eq(bfill_charging) & @nan_period_duration.le(@MAX_CHARGE_TD)\")\n",
    "        tss[\"nan_charging\"] = tss[\"nan_charging\"].mask(fill_unknown_period, tss[\"ffill_charging\"])\n",
    "        # As mentioned before, the SoC oscillates at [charge_limit_soc - ~3%, charge_limit_soc] so we set these periods to NaN as well.\n",
    "        tss[\"nan_charging\"] = tss[\"nan_charging\"].mask(tss[\"soc\"] >= (tss[\"charge_limit_soc\"] - 3))\n",
    "        # Then we seperate the Series into two, more explicit, columns.\n",
    "        tss[\"in_charge\"] = tss.eval(\"nan_charging.notna() & nan_charging\")\n",
    "        tss[\"in_discharge\"] = tss.eval(\"nan_charging.notna() & ~nan_charging\")\n",
    "        return tss.drop(columns=[\"nan_charging\", \"ffill_charging\", \"bfill_charging\", \"ffill_date\", \"bfill_date\"])\n",
    "    \n",
    "    def compute_charge_n_discharge_masks_bis(self, tss:DF) -> DF:\n",
    "        self.logger.debug(\"Computing tesla specific charge and discharge masks\")\n",
    "\n",
    "        tss_na = tss.dropna(subset=['soc']).copy()\n",
    "\n",
    "        tss_na['soc_diff'] = tss_na.groupby('vin', observed=True)['soc'].diff()\n",
    "\n",
    "        tss_na['trend'] = tss_na['soc_diff'].apply(lambda x: 1 if x > 0 else -1 if x < 0 else 0)\n",
    "\n",
    "        #tss_na['trend_change'] = tss_na.groupby('vin', observed=True)['trend'].transform(lambda x: x != x.shift())\n",
    "        tss = tss.merge(tss_na[[\"soc\", \"date\", \"vin\", 'soc_diff', 'trend']], \n",
    "                        on=[\"soc\", \"date\", \"vin\"], how=\"left\")\n",
    "        tss[[\"trend\", \"soc\", \"odometer\",]].bfill(inplace=True)\n",
    "        tss[\"in_charge\"] = tss.eval('trend==1')\n",
    "        tss[\"in_discharge\"] = tss.eval('trend==-1')\n",
    "        return tss\n",
    "    \n",
    "    \n",
    "    def compute_enenergy_added(self, tss:DF) -> DF:\n",
    "        tss['charge_energy_added'] = tss['dc_charge_energy_added'].where(\n",
    "            tss['dc_charge_energy_added'].notnull() & \n",
    "            (tss['dc_charge_energy_added'] > 0), \n",
    "            tss['ac_charge_energy_added'])\n",
    "        return tss\n",
    "    \n",
    "    # def compute_charge_idx(self, tss:DF) -> DF:\n",
    "    #     self.logger.debug(\"Computing tesla specific charge index.\")\n",
    "    #     if self.make == 'tesla-fleet-telemetry':\n",
    "    #         tss = tss.pipe(self.compute_enenergy_added)\n",
    "    #     tss_grp = tss.groupby(\"vin\", observed=False)\n",
    "    #     tss[\"charge_energy_added\"] = tss_grp[\"charge_energy_added\"].ffill()\n",
    "    #     energy_added_over_time = tss_grp['charge_energy_added'].diff().div(tss[\"sec_time_diff\"].values)\n",
    "    #     # charge_energy_added is cummulative and forward filled, \n",
    "    #     # We check that the charge_energy_added decreases too fast to make sure that  correctly indentify two charging periods before and after a gap as two separate charging periods.\n",
    "    #     new_charge_mask = energy_added_over_time.lt(MIN_POWER_LOSS, fill_value=0) \n",
    "    #     # For the same reason, we ensure that there are no gaps bigger than MAX_CHARGE_TD in between to rows of the same charging period.\n",
    "    #     new_charge_mask |= tss[\"time_diff\"].gt(MAX_CHARGE_TD) \n",
    "    #     # And of course we also check that there is no change of status. \n",
    "    #     new_charge_mask |= (~tss_grp[\"in_charge\"].shift().bfill() & tss[\"in_charge\"]) \n",
    "    #     tss[\"in_charge_idx\"] = new_charge_mask.groupby(tss[\"vin\"], observed=True).cumsum()\n",
    "    #     print(tss[\"in_charge_idx\"].count() / len(tss))\n",
    "    #     tss[\"in_charge_idx\"] = tss[\"in_charge_idx\"].fillna(-1).astype(\"uint16\")\n",
    "    #     return tss\n",
    "    \n",
    "    def compute_charge_idx_bis(self, tss):\n",
    "\n",
    "        if self.make == 'tesla-fleet-telemetry':\n",
    "                    tss = tss.pipe(self.compute_enenergy_added)\n",
    "        tss_na = tss.dropna(subset=['soc']).copy()\n",
    "        tss_na['soc_diff'] = tss_na.groupby('vin', observed=True)['soc'].diff()\n",
    "        tss_na['soc_diff_rolling'] = tss_na['soc_diff'].rolling(window=5, min_periods=1).mean()\n",
    "        # Determine trend\n",
    "        tss_na['trend'] = tss_na['soc_diff_rolling'].apply(lambda x: 1 if x > 0 else -1 if x < 0 else np.nan)\n",
    "        tss_na['trend'] = tss_na['trend'].ffill()\n",
    "\n",
    "        def detect_trend_change(group):\n",
    "\n",
    "            group['prev_trend'] = group['trend'].shift(1)\n",
    "            group['prev_prev_trend'] = group['trend'].shift(2)\n",
    "            \n",
    "            group['prev_date'] = group['date'].shift(1)\n",
    "            group['time_diff_min'] = (group['date'] - group['prev_date']).dt.total_seconds() / 60\n",
    "            group['time_gap'] = group['time_diff_min'] > 60  \n",
    "\n",
    "            # Faire une sépration charge_idx et discharge_idx\n",
    "            group['trend_change'] = (\n",
    "                (((group['trend'] != group['prev_trend']) & \n",
    "                  (group['prev_trend'] == group['prev_prev_trend']) ) |\n",
    "                group['time_gap'])\n",
    "            )\n",
    "            group.loc[group.index[0:2], 'trend_change'] = False\n",
    "            return group\n",
    "\n",
    "\n",
    "        tss_na = tss_na.groupby('vin', observed=True).apply(detect_trend_change).reset_index(drop=True)\n",
    "        \n",
    "        # Compute charge id\n",
    "        tss_na['in_charge_idx'] = tss_na.groupby('vin',  observed=True)['trend_change'].cumsum()\n",
    "        tss = tss.merge(tss_na[[\"soc\", \"date\", \"vin\", 'soc_diff', 'in_charge_idx', 'trend', 'prev_trend', 'prev_prev_trend', 'trend_change',]], \n",
    "                        on=[\"soc\", \"date\", \"vin\"], how=\"left\")\n",
    "        tss[[\"odometer\",\"in_charge_idx\"]] = tss[[\"odometer\", \"in_charge_idx\"]].ffill()\n",
    "        return tss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tss = TeslaProcessedTimeSeries(\"tesla-fleet-telemetry\", force_update=True)\n",
    "processed_tss['in_charge_idx'] = processed_tss['in_charge_idx'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results = (processed_tss.groupby([\"vin\", \"in_charge_idx\"], observed=True, as_index=False).agg(\n",
    "            ac_energy_added_min=pd.NamedAgg(\"ac_charge_energy_added\", \"min\"),\n",
    "            dc_energy_added_min=pd.NamedAgg(\"dc_charge_energy_added\", \"min\"),\n",
    "            ac_energy_added_end=pd.NamedAgg(\"ac_charge_energy_added\", \"last\"),\n",
    "            dc_energy_added_end=pd.NamedAgg(\"dc_charge_energy_added\", \"last\"),\n",
    "            soc_diff=pd.NamedAgg(\"soc\", series_start_end_diff),\n",
    "            inside_temp=pd.NamedAgg(\"inside_temp\", \"mean\"),\n",
    "            net_capacity=pd.NamedAgg(\"net_capacity\", \"first\"),\n",
    "            range=pd.NamedAgg(\"range\", \"first\"),\n",
    "            odometer=pd.NamedAgg(\"odometer\", \"first\"),\n",
    "            version=pd.NamedAgg(\"version\", \"first\"),\n",
    "            size=pd.NamedAgg(\"soc\", \"size\"),\n",
    "            model=pd.NamedAgg(\"model\", \"first\"),\n",
    "            date=pd.NamedAgg(\"date\", \"first\"),\n",
    "            ac_charging_power=pd.NamedAgg(\"ac_charging_power\", \"median\"),\n",
    "            dc_charging_power=pd.NamedAgg(\"dc_charging_power\", \"median\"),\n",
    "            tesla_code=pd.NamedAgg(\"tesla_code\", \"first\"),\n",
    "        )\n",
    "        .eval(\"charging_power = ac_charging_power + dc_charging_power\")\n",
    "        .eval(\"ac_energy_added = ac_energy_added_end  - ac_energy_added_min\")\n",
    "        .eval(\"dc_energy_added = dc_energy_added_end  - dc_energy_added_min\")\n",
    "        .assign(energy_added=lambda df: np.maximum(df[\"ac_energy_added\"], df[\"dc_energy_added\"]))\n",
    "        .eval(\"soh = energy_added / (soc_diff / 100.0 * net_capacity)\")\n",
    "        .eval(\"level_1 = soc_diff * (charging_power < 8) / 100\")\n",
    "        .eval(\"level_2 = soc_diff * (charging_power.between(8, 45)) / 100\")\n",
    "        .eval(\"level_3 = soc_diff * (charging_power > 45) / 100\")\n",
    "        .sort_values([\"tesla_code\", \"vin\", \"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results[(raw_results['vin']==\"XP7YGCES2SB594149\") & (raw_results['soc_diff'] > 0)][['soh', 'odometer', 'soc_diff', \"energy_added\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour repartir de ce qui est stocké\n",
    "#raw_results_origin = get_results_origin(force_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Processed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_results.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOH_FILTER_EVAL = {\n",
    "     \"tesla-fleet-telemetry-30\": \"soh = soh.where(soc_diff > 30 & soh.between(0.75, 1.05))\",\n",
    "     \"tesla-fleet-telemetry-25\": \"soh = soh.where(soc_diff > 25 & soh.between(0.75, 1.05))\",\n",
    "     \"tesla-fleet-telemetry-20\": \"soh = soh.where(soc_diff > 20 & soh.between(0.75, 1.05))\",\n",
    "     \"tesla-fleet-telemetry-15\": \"soh = soh.where(soc_diff > 15 & soh.between(0.75, 1.05))\",\n",
    "     \"tesla-fleet-telemetry-8\": \"soh = soh.where(soc_diff > 8 & soh.between(0.75, 1.05))\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_results(brand:str) -> DF:\n",
    "    logger.info(f\"{'Processing ' + brand + ' results.':=^{50}}\")\n",
    "    results =  (\n",
    "        raw_results\n",
    "        # Some raw estimations may have inf values, this will make mask_out_outliers_by_interquartile_range and force_monotonic_decrease fail\n",
    "        # So we replace them by NaNs.\n",
    "        .assign(soh=lambda df: df[\"soh\"].replace([np.inf, -np.inf], np.nan))\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "        .pipe(make_charge_levels_presentable)\n",
    "        .eval(SOH_FILTER_EVAL[brand])\n",
    "        .pipe(agg_results_by_update_frequency)\n",
    "        .groupby('vin', observed=True)\n",
    "        .apply(make_soh_presentable_per_vehicle, include_groups=False)\n",
    "        .reset_index(level=0)\n",
    "        #.pipe(filter_results_by_lines_bounds, VALID_SOH_POINTS_LINE_BOUNDS, logger=logger)\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "    )\n",
    "    results[\"soh\"] = results.groupby(\"vin\", observed=True)[\"soh\"].ffill()\n",
    "    results[\"soh\"] = results.groupby(\"vin\", observed=True)[\"soh\"].bfill()\n",
    "    results[\"odometer\"] = results.groupby(\"vin\", observed=True)[\"odometer\"].ffill()\n",
    "    results[\"odometer\"] = results.groupby(\"vin\", observed=True)[\"odometer\"].bfill()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results_30 = get_processed_results('tesla-fleet-telemetry-30')\n",
    "processed_results_25 = get_processed_results('tesla-fleet-telemetry-25')\n",
    "processed_results_20 = get_processed_results('tesla-fleet-telemetry-20')\n",
    "processed_results_15 = get_processed_results('tesla-fleet-telemetry-15')\n",
    "processed_results_8 = get_processed_results('tesla-fleet-telemetry-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(raw_results[(raw_results['soh'] >.7) &(raw_results['soh'] < 1.05)].dropna(subset='soh'), x='odometer', y='soh', color='vin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(processed_results_30[(processed_results_30['soh'] > .75) &(processed_results_30['soh'] < 1.05)].dropna(subset='soh'), x='odometer', y='soh', color='vin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

