{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Notebook pour tester le pipe de fleet-telemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Raw tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.s3_utils import *\n",
    "from transform.raw_tss.fleet_telemetry_raw_tss import *\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from transform.processed_tss.config import *\n",
    "from core.constants import *\n",
    "from transform.raw_tss.config import *\n",
    "# from transform.processed_tss.ProcessedTimeSeries import ProcessedTimeSeries\n",
    "from transform.raw_results.tesla_fleet_telemetry import get_results as get_results_origin\n",
    "from transform.processed_results.main import get_processed_results\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_RAW_TSS_KEY_FORMAT = \"raw_ts/{brand}/time_series/raw_tss.parquet\"\n",
    "FLEET_TELEMETRY_RAW_TSS_KEY = S3_RAW_TSS_KEY_FORMAT.format(brand=\"tesla-fleet-telemetry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLEET_TELEMETRY_RAW_TSS_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3_Bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = S3_Bucket().get_creds_from_dot_env()['aws_access_key_id']\n",
    "secret_key = S3_Bucket().get_creds_from_dot_env()['aws_secret_access_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from transform.raw_tss.fleet_telemetry_raw_tss import *\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages org.apache.hadoop:hadoop-aws:3.3.4 pyspark-shell\"\n",
    "\n",
    ")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Scaleway S3 Read JSON\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"https://s3.fr-par.scw.cloud\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Raw TSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Processed TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_spark_column = {\n",
    "        \"readable_date\": \"date\",\n",
    "        \"Odometer\" : \"odometer\",\n",
    "        \"ACChargingEnergyIn\": \"ac_charge_energy_added\",\n",
    "        \"Soc\": \"soc\",\n",
    "        \"CarType\": 'model',\n",
    "        \"DCChargingEnergyIn\": \"dc_charge_energy_added\",\n",
    "        \"BatteryLevel\": \"battery_level\",\n",
    "        \"ACChargingPower\": \"ac_charging_power\",\n",
    "        \"DCChargingPower\": \"dc_charging_power\",\n",
    "        \"DetailedChargeState\": \"charging_status\",\n",
    "        \n",
    "}\n",
    "col_to_select = [\n",
    "    'vin', 'date', 'odometer', 'soc', \n",
    "    \"battery_level\",\n",
    "    \"ac_charge_energy_added\",\n",
    "    \"dc_charge_energy_added\",\n",
    "    \"ac_charging_power\",\n",
    "    \"dc_charging_power\",\n",
    "    \"charging_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = TeslaProcessedTimeSeries(make='tesla-fleet-telemetry', force_update=False, spark=spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.data.select('vin').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = res.data.withColumn(\"vin\", col(\"vin\") == \"5YJSA7E52RF541858\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_response = [{\"vin\":\"5YJ3E7EB1KF334219\",\"timestamp\":1748318343277,\"readable_date\":\"2025-05-27 03:59:03\",\n",
    "                  \"data\":[{\"key\":\"InsideTemp\",\"value\":{\"stringValue\":\"19.100000880658627\"}},\n",
    "                          {\"key\":\"FastChargerType\",\"value\":{\"invalid\":True}},\n",
    "                          {\"key\":\"PackCurrent\",\"value\":{\"stringValue\":\"0\"}},\n",
    "                          {\"key\":\"ModuleTempMax\",\"value\":{\"stringValue\":\"26\"}},\n",
    "                          {\"key\":\"ChargeCurrentRequest\",\"value\":{\"stringValue\":\"16\"}},\n",
    "                          {\"key\":\"ChargePortColdWeatherMode\",\"value\":{\"stringValue\":\"false\"}},\n",
    "                          {\"key\":\"DCChargingEnergyIn\",\"value\":{\"stringValue\":\"17.419999610632658\"}},\n",
    "                          {\"key\":\"DCDCEnable\",\"value\":{\"stringValue\":\"false\"}},\n",
    "                          {\"key\":\"ChargerPhases\",\"value\":{\"invalid\":True}},\n",
    "                          {\"key\":\"PreconditioningEnabled\",\"value\":{\"stringValue\":\"false\"}},\n",
    "                          {\"key\":\"ChargeCurrentRequestMax\",\"value\":{\"stringValue\":\"16\"}},\n",
    "                          {\"key\":\"BatteryLevel\",\"value\":{\"stringValue\":\"49.2429022082019\"}},\n",
    "                          {\"key\":\"ACChargingPower\",\"value\":{\"stringValue\":\"0\"}},\n",
    "                          {\"key\":\"EstBatteryRange\",\"value\":{\"stringValue\":\"113.16217657792016\"}},\n",
    "                          {\"key\":\"BmsFullchargecomplete\",\"value\":{\"stringValue\":\"false\"}},\n",
    "                          {\"key\":\"ChargeAmps\",\"value\":{\"stringValue\":\"0\"}},\n",
    "                          {\"key\":\"LifetimeEnergyUsed\",\"value\":{\"stringValue\":\"26604.12326362799\"}},\n",
    "                          {\"key\":\"HvacACEnabled\",\"value\":{\"booleanValue\":False}},\n",
    "                          {\"key\":\"BatteryHeaterOn\",\"value\":{\"stringValue\":\"false\"}},\n",
    "                          {\"key\":\"IsolationResistance\",\"value\":{\"stringValue\":\"4280\"}},\n",
    "                          {\"key\":\"DetailedChargeState\",\"value\":{\"detailedChargeStateValue\":\"DetailedChargeStateDisconnected\"}},\n",
    "                          {\"key\":\"BrickVoltageMin\",\"value\":{\"stringValue\":\"3.836000182200223\"}},\n",
    "                          {\"key\":\"BrickVoltageMax\",\"value\":{\"stringValue\":\"3.838000182295218\"}},\n",
    "                          {\"key\":\"EstimatedHoursToChargeTermination\",\"value\":{\"invalid\":True}},\n",
    "                          {\"key\":\"ChargePort\",\"value\":{\"stringValue\":\"CCS\"}},\n",
    "                          {\"key\":\"ChargeState\",\"value\":{\"stringValue\":\"Idle\"}},\n",
    "                          {\"key\":\"HvacPower\",\"value\":{\"hvacPowerValue\":\"HvacPowerStateOff\"}},\n",
    "                          {\"key\":\"EfficiencyPackage\",\"value\":{\"stringValue\":\"Default\"}},\n",
    "                          {\"key\":\"HvacAutoMode\",\"value\":{\"hvacAutoModeValue\":\"HvacAutoModeStateOn\"}},\n",
    "                          {\"key\":\"SentryMode\",\"value\":{\"stringValue\":\"Off\"}},\n",
    "                          {\"key\":\"HvacFanSpeed\",\"value\":{\"intValue\":2}},\n",
    "                          {\"key\":\"BMSState\",\"value\":{\"stringValue\":\"Standby\"}},\n",
    "                          {\"key\":\"FastChargerPresent\",\"value\":{\"stringValue\":\"false\"}},\n",
    "                          {\"key\":\"ModuleTempMin\",\"value\":{\"stringValue\":\"24.5\"}},\n",
    "                          {\"key\":\"Odometer\",\"value\":{\"stringValue\":\"64016.35690902214\"}},\n",
    "                          {\"key\":\"Soc\",\"value\":{\"stringValue\":\"48.958990536277604\"}},\n",
    "                          {\"key\":\"DefrostMode\",\"value\":{\"defrostModeValue\":\"DefrostModeStateOff\"}},\n",
    "                          {\"key\":\"ChargeEnableRequest\",\"value\":{\"stringValue\":\"true\"}},\n",
    "                          {\"key\":\"ACChargingEnergyIn\",\"value\":{\"stringValue\":\"17.83427804352963\"}},\n",
    "                          {\"key\":\"ChargeRateMilePerHour\",\"value\":{\"doubleValue\":0}},\n",
    "                          {\"key\":\"ChargingCableType\",\"value\":{\"invalid\":True}},\n",
    "                          {\"key\":\"VehicleSpeed\",\"value\":{\"invalid\":True}},\n",
    "                          {\"key\":\"OutsideTemp\",\"value\":{\"stringValue\":\"12\"}},\n",
    "                          {\"key\":\"RatedRange\",\"value\":{\"stringValue\":\"126.69387471919158\"}},\n",
    "                          {\"key\":\"EuropeVehicle\",\"value\":{\"booleanValue\":True}},\n",
    "                          {\"key\":\"PackVoltage\",\"value\":{\"stringValue\":\"368.1199917718768\"}},\n",
    "                          {\"key\":\"IdealBatteryRange\",\"value\":{\"stringValue\":\"126.69387471919158\"}},\n",
    "                          {\"key\":\"ClimateKeeperMode\",\"value\":{\"climateKeeperModeValue\":\"ClimateKeeperModeStateOff\"}},\n",
    "                          {\"key\":\"RearDefrostEnabled\",\"value\":{\"booleanValue\":False}},\n",
    "                          {\"key\":\"CarType\",\"value\":{\"stringValue\":\"Model3\"}},\n",
    "                          {\"key\":\"DefrostForPreconditioning\",\"value\":{\"booleanValue\":False}},\n",
    "                          {\"key\":\"EnergyRemaining\",\"value\":{\"stringValue\":\"32.65999926999211\"}},\n",
    "                          {\"key\":\"ChargeLimitSoc\",\"value\":{\"stringValue\":\"62\"}},\n",
    "                          {\"key\":\"DCChargingPower\",\"value\":{\"stringValue\":\"0\"}}],\"meta\":{},\"createdAt\":\"2025-05-27T03:59:03.277232687Z\"},\n",
    "                 {\"vin\":\"5YJ3E7EB1KF334219\",\"timestamp\":1748318344277,\"readable_date\":\"2025-05-27 03:59:04\",\n",
    "                  \"data\":[{\"key\":\"ChargerVoltage\",\"value\":{\"doubleValue\":1.716}}],\"meta\":{},\"createdAt\":\"2025-05-27T03:59:04.277224934Z\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Process TTS Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_spark_column = {\n",
    "        \"readable_date\": \"date\",\n",
    "        \"Odometer\" : \"odometer\",\n",
    "        \"ACChargingEnergyIn\": \"ac_charge_energy_added\",\n",
    "        \"Soc\": \"soc\",\n",
    "        \"CarType\": 'model',\n",
    "        \"DCChargingEnergyIn\": \"dc_charge_energy_added\",\n",
    "        \"BatteryLevel\": \"battery_level\",\n",
    "        \"ACChargingPower\": \"ac_charging_power\",\n",
    "        \"DCChargingPower\": \"dc_charging_power\",\n",
    "        \"DetailedChargeState\": \"charging_status\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_select = [\n",
    "    'vin', 'date', 'odometer', 'soc', \n",
    "    \"battery_level\",\n",
    "    \"ac_charge_energy_added\",\n",
    "    \"dc_charge_energy_added\",\n",
    "    \"ac_charging_power\",\n",
    "    \"dc_charging_power\",\n",
    "    \"charging_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import FloatType, TimestampType\n",
    "def rename_and_select(tss, rename_col, col_to_select):\n",
    "    return tss.withColumnsRenamed(rename_col).select(col_to_select)\n",
    "\n",
    "def safe_astype(tss):\n",
    "    return tss.withColumn(\"odometer\", col(\"odometer\").cast(FloatType())) \\\n",
    "    .withColumn(\"soc\", col(\"soc\").cast(FloatType())) \\\n",
    "    .withColumn(\"battery_level\", col(\"battery_level\").cast(FloatType())) \\\n",
    "    .withColumn(\"ac_charge_energy_added\", col(\"ac_charge_energy_added\").cast(FloatType())) \\\n",
    "    .withColumn(\"dc_charge_energy_added\", col(\"dc_charge_energy_added\").cast(FloatType())) \\\n",
    "    .withColumn(\"ac_charging_power\", col(\"ac_charging_power\").cast(FloatType())) \\\n",
    "    .withColumn(\"dc_charging_power\", col(\"dc_charging_power\").cast(FloatType())) \\\n",
    "    .withColumn(\"date\", col(\"date\").cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss_filter_type = raw_tss_filter.withColumn(\"odometer\", col(\"odometer\").cast(FloatType())) \\\n",
    "    .withColumn(\"soc\", col(\"soc\").cast(FloatType())) \\\n",
    "    .withColumn(\"battery_level\", col(\"battery_level\").cast(FloatType())) \\\n",
    "    .withColumn(\"ac_charge_energy_added\", col(\"ac_charge_energy_added\").cast(FloatType())) \\\n",
    "    .withColumn(\"dc_charge_energy_added\", col(\"dc_charge_energy_added\").cast(FloatType())) \\\n",
    "    .withColumn(\"ac_charging_power\", col(\"ac_charging_power\").cast(FloatType())) \\\n",
    "    .withColumn(\"dc_charging_power\", col(\"dc_charging_power\").cast(FloatType())) \\\n",
    "    .withColumn(\"date\", col(\"date\").cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_units_to_metric(tss):\n",
    "    tss = tss.withColumn(\"odometer\", col(\"odometer\") * 1.609)\n",
    "    return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_units_to_metric(raw_tss_filter_type)\n",
    "raw_tss_filter_type_sorted = raw_tss_filter_type.sort(['vin', \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, lag, unix_timestamp\n",
    "def compute_date_vars(tss: DF) -> DF:\n",
    "    # Créer une fenêtre par vin, ordonnée par date\n",
    "    window_spec = Window.partitionBy(\"vin\").orderBy(\"date\")\n",
    "    \n",
    "    # Calculer le lag de date (valeur précédente)\n",
    "    tss = tss.withColumn(\"prev_date\", lag(col(\"date\")).over(window_spec))\n",
    "    \n",
    "    # Différence en secondes entre les deux timestamps\n",
    "    tss = tss.withColumn(\n",
    "        \"sec_time_diff\",\n",
    "        (unix_timestamp(col(\"date\")) - unix_timestamp(col(\"prev_date\"))).cast(\"double\")\n",
    "    )\n",
    "    \n",
    "    return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss_filter_type_sorted_date_vars = compute_date_vars(raw_tss_filter_type_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame as DF, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, lag, unix_timestamp, when, lit,\n",
    "    expr, coalesce, sum as _sum\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CHARGE_CHARGING_STATUS_VALS = [\n",
    "    'charging', # Tesla\n",
    "    # 'nopower', # Tesla\n",
    "    'chargingactive',\n",
    "    'slow_charging',\n",
    "    'fast_charging',\n",
    "    'initialization',\n",
    "    \"in-progress\",\n",
    "    # fleet-telemetry\n",
    "    'detailedchargestatecharging', \n",
    "    'detailedchargestatestarting'\n",
    "]\n",
    "\n",
    "IN_DISCHARGE_CHARGING_STATUS_VALS = [\n",
    "    'charging_error',\n",
    "    'nocharging',\n",
    "    'chargingerror',\n",
    "    'cable_unplugged',\n",
    "    'disconnected', # Tesla\n",
    "     # fleet-telemetry\n",
    "    \"detailedchargestatedisconnected\",\n",
    "    \"detailedchargestatenopower\",\n",
    "    \"detailedchargestatestopped\",\n",
    "    \"detailedchargestatecomplete\",\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_n_discharging_masks_from_charging_status(tss: DF, in_charge_vals: list, in_discharge_vals: list) -> DF:\n",
    "    assert \"charging_status\" in tss.columns, NO_CHARGING_STATUS_COL_ERROR\n",
    "    \n",
    "    # Masques booléens Spark\n",
    "    tss = tss.withColumn(\n",
    "        \"in_charge\",\n",
    "        when(col(\"charging_status\").isin(in_charge_vals), lit(True)).otherwise(lit(False))\n",
    "    )\n",
    "\n",
    "    tss = tss.withColumn(\n",
    "        \"in_discharge\",\n",
    "        when(col(\"charging_status\").isin(in_discharge_vals), lit(True)).otherwise(lit(False))\n",
    "    )\n",
    "    \n",
    "    return tss\n",
    "\n",
    "def compute_charge_n_discharge_masks(tss:DF, in_charge_vals:list, in_discharge_vals:list) -> DF:\n",
    "    \"\"\"Computes the `in_charge` and `in_discharge` masks either from the charging_status column or from the evolution of the soc over time.\"\"\"\n",
    "    if \"tesla-fleet-telemetry\" in CHARGE_MASK_WITH_CHARGING_STATUS_MAKES:\n",
    "        return charge_n_discharging_masks_from_charging_status(tss, in_charge_vals, in_discharge_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy_added(tss: DF) -> DF:\n",
    "    tss = tss.withColumn(\n",
    "        \"charge_energy_added\",\n",
    "        when(\n",
    "            col(\"dc_charge_energy_added\").isNotNull() & (col(\"dc_charge_energy_added\") > 0),\n",
    "            col(\"dc_charge_energy_added\")\n",
    "        ).otherwise(col(\"ac_charge_energy_added\"))\n",
    "    )\n",
    "    return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_charge_idx_bis(tss: DF) -> DF:\n",
    "    \n",
    "    tss = compute_energy_added(tss)\n",
    "    \n",
    "    # 1. Filtrer les lignes où soc n'est pas null\n",
    "    tss_na = tss.filter(col(\"soc\").isNotNull())\n",
    "\n",
    "    # 2. Créer une fenêtre ordonnée par date par VIN\n",
    "    vin_window = Window.partitionBy(\"vin\").orderBy(\"date\")\n",
    "\n",
    "    # 3. Calcul des différences\n",
    "    tss_na = tss_na \\\n",
    "        .withColumn(\"soc_diff\", col(\"soc\") - lag(\"soc\", 1).over(vin_window)) \\\n",
    "        .withColumn(\"trend\", when(col(\"soc_diff\") > 0, lit(1))\n",
    "                              .when(col(\"soc_diff\") < 0, lit(-1))\n",
    "                              .otherwise(lit(0))) \\\n",
    "        .withColumn(\"prev_trend\", lag(\"trend\", 1).over(vin_window)) \\\n",
    "        .withColumn(\"prev_prev_trend\", lag(\"trend\", 2).over(vin_window)) \\\n",
    "        .withColumn(\"prev_date\", lag(\"date\", 1).over(vin_window)) \\\n",
    "        .withColumn(\"time_diff_min\", \n",
    "                    (unix_timestamp(col(\"date\")) - unix_timestamp(col(\"prev_date\"))) / 60) \\\n",
    "        .withColumn(\"time_gap\", col(\"time_diff_min\") > 60) \\\n",
    "        .withColumn(\"trend_change\",\n",
    "                    when(\n",
    "                        ((col(\"trend\") != col(\"prev_trend\")) & \n",
    "                         (col(\"prev_trend\") == col(\"prev_prev_trend\"))) | \n",
    "                        col(\"time_gap\"), \n",
    "                        lit(1)\n",
    "                    ).otherwise(lit(0)))\n",
    "\n",
    "    # 4. Initialiser les premières lignes à 0\n",
    "    tss_na = tss_na.withColumn(\n",
    "        \"trend_change\",\n",
    "        when(col(\"date\") == lag(\"date\", 1).over(vin_window), lit(0)).otherwise(col(\"trend_change\"))\n",
    "    )\n",
    "\n",
    "    # 5. Cumulative sum (session index)\n",
    "    tss_na = tss_na.withColumn(\"in_charge_idx\", _sum(\"trend_change\").over(vin_window.rowsBetween(Window.unboundedPreceding, 0)))\n",
    "\n",
    "    # 6. Join avec le DataFrame original\n",
    "    tss = tss.join(\n",
    "        tss_na.select(\"vin\", \"date\", \"soc\", \"soc_diff\", \"in_charge_idx\"),\n",
    "        on=[\"vin\", \"date\", \"soc\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 7. Forward-fill `odometer` et `in_charge_idx` (non-natif en Spark, mais on peut approximer)\n",
    "    fill_window = Window.partitionBy(\"vin\").orderBy(\"date\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "    tss = tss \\\n",
    "        .withColumn(\"odometer\", coalesce(col(\"odometer\"), expr(\"last(odometer, true)\").over(fill_window))) \\\n",
    "        .withColumn(\"in_charge_idx\", coalesce(col(\"in_charge_idx\"), expr(\"last(in_charge_idx, true)\").over(fill_window)))\n",
    "\n",
    "    return tss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_charge_n_discharge_vars(tss:DF) -> DF:\n",
    "    tss = compute_charge_n_discharge_masks(tss, IN_CHARGE_CHARGING_STATUS_VALS,  IN_DISCHARGE_CHARGING_STATUS_VALS)\n",
    "    tss = compute_charge_idx_bis(tss)\n",
    "    return tss\n",
    "        # .pipe(self.compute_idx_from_masks, [\"in_charge\"])\n",
    "        # .pipe(self.trim_leading_n_trailing_soc_off_masks, [\"in_charge\", \"in_discharge\"])\n",
    "        # # .pipe(self.compute_idx_from_masks, [\"trimmed_in_charge\", \"trimmed_in_discharge\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tss = compute_charge_n_discharge_vars(raw_tss_filter_type_sorted_date_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.fleet_info.main import fleet_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(tss) -> DF:\n",
    "        tss = rename_and_select(tss, rename_spark_column, col_to_select)\n",
    "        tss = safe_astype(tss)\n",
    "        tss = normalize_units_to_metric(tss)\n",
    "        tss = tss.orderBy([\"vin\", \"date\"])\n",
    "        #tss = str_lower_columns(tss, COLS_TO_STR_LOWER)\n",
    "        tss = compute_date_vars(tss)\n",
    "        tss = compute_charge_n_discharge_vars(tss)\n",
    "        #tss = tss.merge(fleet_info, on=\"vin\", how=\"left\")\n",
    "        \n",
    "        tss = tss.join(spark.createDataFrame(fleet_info), 'vin', 'left')\n",
    "        #tss = tss.eval(\"age = date.dt.tz_localize(None) - start_date.dt.tz_localize(None)\")\n",
    "        #tss = tss.withColumn(\"age\")\n",
    "        # It seems that the reset_index calls doesn't reset the id_col into a category if the groupby's by argument was categorical.\n",
    "        # So we recall astype on the id_col  in case it is supposed to be categorical.\n",
    "        return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#response.write.mode(\"overwrite\").parquet(\"s3a://bib-platform-prod-data/raw_ts/tesla-fleet-telemetry/time_series/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(raw_tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Processed tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_tss.ProcessedTimeSeries import ProcessedTimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_charge_n_discharge_masks(tss:DF) -> DF:\n",
    "        # We use a nullable boolean Series to represnet the rows where:\n",
    "        tss[\"nan_charging\"] = (\n",
    "            Series(pd.NA, index=tss.index, dtype=\"boolean\")# We are not sure of anything.\n",
    "            .mask(tss[\"charging_status\"].isin(IN_CHARGE_CHARGING_STATUS_VALS), True)# We are sure that the vehicle is in charge.\n",
    "            .mask(tss[\"charging_status\"].isin(IN_DISCHARGE_CHARGING_STATUS_VALS), False)# We are sure that the vehicle is not in charge.\n",
    "        )\n",
    "        # If a period of uncertainty (NaN) is surrounded by equal periods of certainties (True-NaN-True or False-NaN-False),\n",
    "        # We will fill them to the value of these certainties.\n",
    "        # However there are edge cases that have multiple days of uncertainties periods (I can't find the VIN but I'm sure you can ;-) )\n",
    "        # Interestingly enough the charge_energy_added variable does not get forwared that far and gets reset to zero. \n",
    "        # This would create outliers in our charge SoH estimation as we estimate the energy_gained as the diff between the last(0) and first value of charge_energy_added.\n",
    "        # So we set a maximal uncertainty period duration over which we don't fill it.\n",
    "        tss[\"nan_date\"] = tss[\"date\"].mask(tss[\"nan_charging\"].isna())\n",
    "        tss[[\"ffill_charging\", \"ffill_date\"]] = tss.groupby(\"vin\", observed=True)[[\"nan_charging\", \"nan_date\"]].ffill()\n",
    "        tss[[\"bfill_charging\", \"bfill_date\"]] = tss.groupby(\"vin\", observed=True)[[\"nan_charging\", \"nan_date\"]].bfill()\n",
    "        nan_period_duration:Series = tss.eval(\"bfill_date - ffill_date\")\n",
    "        fill_unknown_period = tss.eval(\"ffill_charging.eq(bfill_charging) & @nan_period_duration.le(@MAX_CHARGE_TD)\")\n",
    "        tss[\"nan_charging\"] = tss[\"nan_charging\"].mask(fill_unknown_period, tss[\"ffill_charging\"])\n",
    "        # As mentioned before, the SoC oscillates at [charge_limit_soc - ~3%, charge_limit_soc] so we set these periods to NaN as well.\n",
    "        tss[\"nan_charging\"] = tss[\"nan_charging\"].mask(tss[\"soc\"] >= (tss[\"charge_limit_soc\"] - 3))\n",
    "        # Then we seperate the Series into two, more explicit, columns.\n",
    "        tss[\"in_charge\"] = tss.eval(\"nan_charging.notna() & nan_charging\")\n",
    "        tss[\"in_discharge\"] = tss.eval(\"nan_charging.notna() & ~nan_charging\")\n",
    "        return tss.drop(columns=[\"nan_charging\", \"ffill_charging\", \"bfill_charging\", \"ffill_date\", \"bfill_date\"])\n",
    "    \n",
    "def compute_energy_added(tss:DF) -> DF:\n",
    "        tss['charge_energy_added'] = tss['dc_charge_energy_added'].where(\n",
    "            tss['dc_charge_energy_added'].notnull() & \n",
    "            (tss['dc_charge_energy_added'] > 0), \n",
    "            tss['ac_charge_energy_added'])\n",
    "        return tss\n",
    "    \n",
    "def compute_charge_idx_bis(tss):\n",
    "\n",
    "        tss = tss.pipe(compute_energy_added)\n",
    "        tss_na = tss.dropna(subset=['soc']).copy()\n",
    "        tss_na['soc_diff'] = tss_na.groupby('vin', observed=True)['soc'].diff()\n",
    "        tss_na['soc_diff_rolling'] = tss_na['soc_diff'].rolling(window=5, min_periods=1).mean()\n",
    "        # Determine trend\n",
    "        tss_na['trend'] = tss_na['soc_diff_rolling'].apply(lambda x: 1 if x > 0 else -1 if x < 0 else np.nan)\n",
    "        tss_na['trend'] = tss_na['trend'].ffill()\n",
    "\n",
    "        def detect_trend_change(group):\n",
    "\n",
    "            group['prev_trend'] = group['trend'].shift(1)\n",
    "            group['prev_prev_trend'] = group['trend'].shift(2)\n",
    "            \n",
    "            group['prev_date'] = group['date'].shift(1)\n",
    "            group['time_diff_min'] = (group['date'] - group['prev_date']).dt.total_seconds() / 60\n",
    "            group['time_gap'] = group['time_diff_min'] > 60  \n",
    "\n",
    "            # Faire une sépration charge_idx et discharge_idx\n",
    "            group['trend_change'] = (\n",
    "                (((group['trend'] != group['prev_trend']) & \n",
    "                  (group['prev_trend'] == group['prev_prev_trend']) ) |\n",
    "                group['time_gap'])\n",
    "            )\n",
    "            group.loc[group.index[0:2], 'trend_change'] = False\n",
    "            return group\n",
    "\n",
    "\n",
    "        tss_na = tss_na.groupby('vin', observed=True).apply(detect_trend_change).reset_index(drop=True)\n",
    "        \n",
    "        # Compute charge id\n",
    "        tss_na['in_charge_idx'] = tss_na.groupby('vin',  observed=True)['trend_change'].cumsum()\n",
    "        tss = tss.merge(tss_na[[\"soc\", \"date\", \"vin\", 'soc_diff', 'in_charge_idx', 'trend', 'prev_trend', 'prev_prev_trend', 'trend_change',]], \n",
    "                        on=[\"soc\", \"date\", \"vin\"], how=\"left\")\n",
    "        tss[[\"odometer\",\"in_charge_idx\"]] = tss[[\"odometer\", \"in_charge_idx\"]].ffill()\n",
    "        return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.pandas_utils import safe_locate, safe_astype, str_lower_columns\n",
    "from transform.fleet_info.main import fleet_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "make = \"tesla-fleet-telemetry\"\n",
    "def run(tss):\n",
    "    tss = tss.rename(columns=RENAME_COLS_DICT, errors=\"ignore\")\n",
    "    tss = tss.pipe(safe_locate, col_loc=list(COL_DTYPES.keys()), logger=logger)\n",
    "    tss = tss.pipe(safe_astype, COL_DTYPES, logger=logger)\n",
    "    tss = tss.pipe(normalize_units_to_metric)\n",
    "    tss = tss.sort_values(by=[\"vin\", \"date\"])\n",
    "    tss = tss.pipe(str_lower_columns, COLS_TO_STR_LOWER)\n",
    "    tss = tss.pipe(compute_date_vars)\n",
    "    tss = tss.pipe(compute_charge_n_discharge_vars)\n",
    "    tss = tss.merge(fleet_info, on=\"vin\", how=\"left\")\n",
    "    tss = tss.eval(\"age = date.dt.tz_localize(None) - start_date.dt.tz_localize(None)\")\n",
    "    # It seems that the reset_index calls doesn't reset the \"vin\" into a category if the groupby's by argument was categorical.\n",
    "    # So we recall astype on the \"vin\"  in case it is supposed to be categorical.\n",
    "    tss = tss.astype({\"vin\": COL_DTYPES[\"vin\"]})\n",
    "    return tss\n",
    "\n",
    "def compute_charge_n_discharge_vars(tss:DF) -> DF:\n",
    "    return (\n",
    "        tss\n",
    "        # Compute the in_charge and in_discharge masks \n",
    "        .pipe(compute_charge_n_discharge_masks, IN_CHARGE_CHARGING_STATUS_VALS, IN_DISCHARGE_CHARGING_STATUS_VALS)\n",
    "        # Compute the correspding indices to perfrom split-apply-combine ops\n",
    "        .pipe(compute_idx_from_masks, [\"in_charge\", \"in_discharge\"])\n",
    "        # We recompute the masks by trimming off the points that have the first and last soc values\n",
    "        # This is done to reduce the noise in the output due to measurments noise.\n",
    "        .pipe(trim_leading_n_trailing_soc_off_masks, [\"in_charge\", \"in_discharge\"]) \n",
    "        .pipe(compute_idx_from_masks, [\"trimmed_in_charge\", \"trimmed_in_discharge\"])\n",
    "        .pipe(compute_cum_var, \"power\", \"cum_energy\")\n",
    "        .pipe(compute_cum_var, \"charger_power\", \"cum_charge_energy_added\")\n",
    "        .pipe(compute_status_col)\n",
    "    )\n",
    "\n",
    "def normalize_units_to_metric( tss:DF) -> DF:\n",
    "    tss[\"odometer\"] = tss[\"odometer\"] * ODOMETER_MILES_TO_KM.get(make, 1)\n",
    "    return tss\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "def compute_cum_var( tss: DF, var_col:str, cum_var_col:str) -> DF:\n",
    "    if not var_col in tss.columns:\n",
    "        logger.debug(f\"{var_col} not found, not computing {cum_var_col}.\")\n",
    "        return tss\n",
    "    logger.debug(f\"Computing {cum_var_col} from {var_col}.\")\n",
    "    tss[cum_var_col] = (\n",
    "        cumulative_trapezoid(\n",
    "            # Leave the keywords as default order is y x not x y (-_-)\n",
    "            # Make sure that date time units are in seconds before converting to int\n",
    "            x=tss[\"date\"].dt.as_unit(\"s\").astype(int),\n",
    "            y=tss[var_col].fillna(0).values,\n",
    "            initial=0,\n",
    "        )            \n",
    "        .astype(\"float32\")\n",
    "    )\n",
    "    tss[cum_var_col] *= KJ_TO_KWH # Convert from kj to kwh\n",
    "    # Reset value to zero at the start of each vehicle time series\n",
    "    # This is better than performing a groupby.apply with cumulative_trapezoid\n",
    "    tss[cum_var_col] -= tss.groupby(\"vin\", observed=True)[cum_var_col].transform(\"first\")\n",
    "    return tss\n",
    "\n",
    "def compute_date_vars( tss:DF) -> DF:\n",
    "    tss[\"time_diff\"] = tss.groupby(\"vin\", observed=False)[\"date\"].diff()\n",
    "    tss[\"sec_time_diff\"] = tss[\"time_diff\"].dt.total_seconds()\n",
    "    return tss\n",
    "\n",
    "def compute_charge_n_discharge_masks(tss:DF, in_charge_vals:list, in_discharge_vals:list) -> DF:\n",
    "    \"\"\"Computes the `in_charge` and `in_discharge` masks either from the charging_status column or from the evolution of the soc over time.\"\"\"\n",
    "    if make in CHARGE_MASK_WITH_CHARGING_STATUS_MAKES:\n",
    "        return charge_n_discharging_masks_from_charging_status(tss, in_charge_vals, in_discharge_vals)\n",
    "    if make in CHARGE_MASK_WITH_SOC_DIFFS_MAKES:\n",
    "        return charge_n_discharging_masks_from_soc_diff(tss)\n",
    "    raise ValueError(MAKE_NOT_SUPPORTED_ERROR.format(make=make))\n",
    "\n",
    "def charge_n_discharging_masks_from_soc_diff( tss:DF) -> DF:\n",
    "    tss_grp = tss.groupby(\"vin\", observed=True)\n",
    "    tss[\"soc_ffilled\"] = tss_grp[\"soc\"].ffill()\n",
    "    tss[\"soc_diff\"] = tss_grp[\"soc_ffilled\"].diff()\n",
    "    tss[\"soc_diff\"] /= tss[\"soc_diff\"].abs()\n",
    "    soc_diff_ffilled = tss_grp[\"soc_diff\"].ffill()\n",
    "    soc_diff_bfilled = tss_grp[\"soc_diff\"].bfill()\n",
    "    tss[\"in_charge\"] = soc_diff_ffilled.gt(0, fill_value=False) & soc_diff_bfilled.gt(0, fill_value=False)\n",
    "    tss[\"in_discharge\"] = soc_diff_ffilled.lt(0, fill_value=False) & soc_diff_bfilled.lt(0, fill_value=False)\n",
    "    return tss\n",
    "\n",
    "def charge_n_discharging_masks_from_charging_status( tss:DF, in_charge_vals:list, in_discharge_vals:list) -> DF:\n",
    "    assert \"charging_status\" in tss.columns, NO_CHARGING_STATUS_COL_ERROR\n",
    "    return (\n",
    "        tss\n",
    "        .eval(f\"in_charge = charging_status in {in_charge_vals}\")\n",
    "        .eval(f\"in_discharge = charging_status in {in_discharge_vals}\")\n",
    "    )\n",
    "\n",
    "def trim_leading_n_trailing_soc_off_masks( tss:DF, masks:list[str]) -> DF:\n",
    "    for mask in masks:\n",
    "        tss[\"naned_soc\"] = tss[\"soc\"].where(tss[mask])\n",
    "        soc_grp = tss.groupby([\"vin\", mask + \"_idx\"], observed=True)[\"naned_soc\"]\n",
    "        trailing_soc = soc_grp.transform(\"first\")\n",
    "        leading_soc = soc_grp.transform(\"last\")\n",
    "        tss[\"trailing_soc\"] = trailing_soc\n",
    "        tss[\"leading_soc\"] = leading_soc\n",
    "        tss[f\"trimmed_{mask}\"] = tss[mask] & (tss[\"soc\"] != trailing_soc) & (tss[\"soc\"] != leading_soc)\n",
    "    tss = tss.drop(columns=\"naned_soc\")\n",
    "    return tss\n",
    "max_td = TD(hours=1, minutes=30)\n",
    "def compute_idx_from_masks( tss: DF, masks:list[str]) -> DF:\n",
    "    for mask in masks:\n",
    "        idx_col_name = f\"{mask}_idx\"\n",
    "        shifted_mask = tss.groupby(\"vin\", observed=True)[mask].shift(fill_value=False)\n",
    "        tss[\"new_period_start_mask\"] = shifted_mask.ne(tss[mask]) \n",
    "        if max_td is not None:\n",
    "            tss[\"new_period_start_mask\"] |= (tss[\"time_diff\"] > max_td)\n",
    "        tss[idx_col_name] = tss.groupby(\"vin\", observed=True)[\"new_period_start_mask\"].cumsum().astype(\"uint16\")\n",
    "        tss.drop(columns=[\"new_period_start_mask\"], inplace=True)\n",
    "    return tss\n",
    "\n",
    "def compute_status_col( tss:DF) -> DF:\n",
    "    tss_grp = tss.groupby(\"vin\", observed=True)\n",
    "    status = tss[\"in_charge\"].map({True: \"charging\", False:\"discharging\", pd.NA:\"unknown\"})\n",
    "    tss[\"status\"] = status.mask(\n",
    "        tss[\"in_charge\"].eq(False, fill_value=True),\n",
    "        np.where(tss_grp[\"odometer\"].diff() > 0, \"moving\", \"idle_discharging\"),\n",
    "    )\n",
    "    return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tss = run(raw_tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TeslaProcessedTimeSeries(ProcessedTimeSeries):\n",
    "\n",
    "    def __init__(self, make:str=\"tesla\", id_col:str=\"vin\", log_level:str=\"INFO\", max_td:TD=MAX_TD, force_update:bool=False, **kwargs):\n",
    "        self.logger = getLogger(make)\n",
    "        set_level_of_loggers_with_prefix(log_level, make)\n",
    "        super().__init__(make, id_col, log_level, max_td, force_update, **kwargs)\n",
    "\n",
    "    def compute_charge_n_discharge_vars(self, tss:DF) -> DF:\n",
    "        return (\n",
    "            tss\n",
    "            .pipe(self.compute_charge_n_discharge_masks)\n",
    "            .pipe(self.compute_charge_idx_bis)\n",
    "            # .pipe(self.compute_idx_from_masks, [\"in_charge\"])\n",
    "            # .pipe(self.trim_leading_n_trailing_soc_off_masks, [\"in_charge\", \"in_discharge\"])\n",
    "            # # .pipe(self.compute_idx_from_masks, [\"trimmed_in_charge\", \"trimmed_in_discharge\"])\n",
    "        )\n",
    "\n",
    "    def compute_charge_n_discharge_masks(self, tss:DF) -> DF:\n",
    "        self.logger.debug(\"Computing tesla specific charge and discharge masks\")\n",
    "        # We use a nullable boolean Series to represnet the rows where:\n",
    "        tss[\"nan_charging\"] = (\n",
    "            Series(pd.NA, index=tss.index, dtype=\"boolean\")# We are not sure of anything.\n",
    "            .mask(tss[\"charging_status\"].isin(IN_CHARGE_CHARGING_STATUS_VALS), True)# We are sure that the vehicle is in charge.\n",
    "            .mask(tss[\"charging_status\"].isin(IN_DISCHARGE_CHARGING_STATUS_VALS), False)# We are sure that the vehicle is not in charge.\n",
    "        )\n",
    "        # If a period of uncertainty (NaN) is surrounded by equal periods of certainties (True-NaN-True or False-NaN-False),\n",
    "        # We will fill them to the value of these certainties.\n",
    "        # However there are edge cases that have multiple days of uncertainties periods (I can't find the VIN but I'm sure you can ;-) )\n",
    "        # Interestingly enough the charge_energy_added variable does not get forwared that far and gets reset to zero. \n",
    "        # This would create outliers in our charge SoH estimation as we estimate the energy_gained as the diff between the last(0) and first value of charge_energy_added.\n",
    "        # So we set a maximal uncertainty period duration over which we don't fill it.\n",
    "        tss[\"nan_date\"] = tss[\"date\"].mask(tss[\"nan_charging\"].isna())\n",
    "        tss[[\"ffill_charging\", \"ffill_date\"]] = tss.groupby(\"vin\", observed=True)[[\"nan_charging\", \"nan_date\"]].ffill()\n",
    "        tss[[\"bfill_charging\", \"bfill_date\"]] = tss.groupby(\"vin\", observed=True)[[\"nan_charging\", \"nan_date\"]].bfill()\n",
    "        nan_period_duration:Series = tss.eval(\"bfill_date - ffill_date\")\n",
    "        fill_unknown_period = tss.eval(\"ffill_charging.eq(bfill_charging) & @nan_period_duration.le(@MAX_CHARGE_TD)\")\n",
    "        tss[\"nan_charging\"] = tss[\"nan_charging\"].mask(fill_unknown_period, tss[\"ffill_charging\"])\n",
    "        # As mentioned before, the SoC oscillates at [charge_limit_soc - ~3%, charge_limit_soc] so we set these periods to NaN as well.\n",
    "        tss[\"nan_charging\"] = tss[\"nan_charging\"].mask(tss[\"soc\"] >= (tss[\"charge_limit_soc\"] - 3))\n",
    "        # Then we seperate the Series into two, more explicit, columns.\n",
    "        tss[\"in_charge\"] = tss.eval(\"nan_charging.notna() & nan_charging\")\n",
    "        tss[\"in_discharge\"] = tss.eval(\"nan_charging.notna() & ~nan_charging\")\n",
    "        return tss.drop(columns=[\"nan_charging\", \"ffill_charging\", \"bfill_charging\", \"ffill_date\", \"bfill_date\"])\n",
    "    \n",
    "    def compute_charge_n_discharge_masks_bis(self, tss:DF) -> DF:\n",
    "        self.logger.debug(\"Computing tesla specific charge and discharge masks\")\n",
    "\n",
    "        tss_na = tss.dropna(subset=['soc']).copy()\n",
    "\n",
    "        tss_na['soc_diff'] = tss_na.groupby('vin', observed=True)['soc'].diff()\n",
    "\n",
    "        tss_na['trend'] = tss_na['soc_diff'].apply(lambda x: 1 if x > 0 else -1 if x < 0 else 0)\n",
    "\n",
    "        #tss_na['trend_change'] = tss_na.groupby('vin', observed=True)['trend'].transform(lambda x: x != x.shift())\n",
    "        tss = tss.merge(tss_na[[\"soc\", \"date\", \"vin\", 'soc_diff', 'trend']], \n",
    "                        on=[\"soc\", \"date\", \"vin\"], how=\"left\")\n",
    "        tss[[\"trend\", \"soc\", \"odometer\",]].bfill(inplace=True)\n",
    "        tss[\"in_charge\"] = tss.eval('trend==1')\n",
    "        tss[\"in_discharge\"] = tss.eval('trend==-1')\n",
    "        return tss\n",
    "    \n",
    "    \n",
    "    def compute_energy_added(self, tss:DF) -> DF:\n",
    "        tss['charge_energy_added'] = tss['dc_charge_energy_added'].where(\n",
    "            tss['dc_charge_energy_added'].notnull() & \n",
    "            (tss['dc_charge_energy_added'] > 0), \n",
    "            tss['ac_charge_energy_added'])\n",
    "        return tss\n",
    "    \n",
    "    # def compute_charge_idx(self, tss:DF) -> DF:\n",
    "    #     self.logger.debug(\"Computing tesla specific charge index.\")\n",
    "    #     if self.make == 'tesla-fleet-telemetry':\n",
    "    #         tss = tss.pipe(self.compute_energy_added)\n",
    "    #     tss_grp = tss.groupby(\"vin\", observed=False)\n",
    "    #     tss[\"charge_energy_added\"] = tss_grp[\"charge_energy_added\"].ffill()\n",
    "    #     energy_added_over_time = tss_grp['charge_energy_added'].diff().div(tss[\"sec_time_diff\"].values)\n",
    "    #     # charge_energy_added is cummulative and forward filled, \n",
    "    #     # We check that the charge_energy_added decreases too fast to make sure that  correctly indentify two charging periods before and after a gap as two separate charging periods.\n",
    "    #     new_charge_mask = energy_added_over_time.lt(MIN_POWER_LOSS, fill_value=0) \n",
    "    #     # For the same reason, we ensure that there are no gaps bigger than MAX_CHARGE_TD in between to rows of the same charging period.\n",
    "    #     new_charge_mask |= tss[\"time_diff\"].gt(MAX_CHARGE_TD) \n",
    "    #     # And of course we also check that there is no change of status. \n",
    "    #     new_charge_mask |= (~tss_grp[\"in_charge\"].shift().bfill() & tss[\"in_charge\"]) \n",
    "    #     tss[\"in_charge_idx\"] = new_charge_mask.groupby(tss[\"vin\"], observed=True).cumsum()\n",
    "    #     print(tss[\"in_charge_idx\"].count() / len(tss))\n",
    "    #     tss[\"in_charge_idx\"] = tss[\"in_charge_idx\"].fillna(-1).astype(\"uint16\")\n",
    "    #     return tss\n",
    "    \n",
    "    def compute_charge_idx_bis(self, tss):\n",
    "\n",
    "        if self.make == 'tesla-fleet-telemetry':\n",
    "                    tss = tss.pipe(self.compute_energy_added)\n",
    "        tss_na = tss.dropna(subset=['soc']).copy()\n",
    "        tss_na['soc_diff'] = tss_na.groupby('vin', observed=True)['soc'].diff()\n",
    "        tss_na['soc_diff_rolling'] = tss_na['soc_diff'].rolling(window=5, min_periods=1).mean()\n",
    "        # Determine trend\n",
    "        tss_na['trend'] = tss_na['soc_diff_rolling'].apply(lambda x: 1 if x > 0 else -1 if x < 0 else np.nan)\n",
    "        tss_na['trend'] = tss_na['trend'].ffill()\n",
    "\n",
    "        def detect_trend_change(group):\n",
    "\n",
    "            group['prev_trend'] = group['trend'].shift(1)\n",
    "            group['prev_prev_trend'] = group['trend'].shift(2)\n",
    "            \n",
    "            group['prev_date'] = group['date'].shift(1)\n",
    "            group['time_diff_min'] = (group['date'] - group['prev_date']).dt.total_seconds() / 60\n",
    "            group['time_gap'] = group['time_diff_min'] > 60  \n",
    "\n",
    "            # Faire une sépration charge_idx et discharge_idx\n",
    "            group['trend_change'] = (\n",
    "                (((group['trend'] != group['prev_trend']) & \n",
    "                  (group['prev_trend'] == group['prev_prev_trend']) ) |\n",
    "                group['time_gap'])\n",
    "            )\n",
    "            group.loc[group.index[0:2], 'trend_change'] = False\n",
    "            return group\n",
    "\n",
    "\n",
    "        tss_na = tss_na.groupby('vin', observed=True).apply(detect_trend_change).reset_index(drop=True)\n",
    "        \n",
    "        # Compute charge id\n",
    "        tss_na['in_charge_idx'] = tss_na.groupby('vin',  observed=True)['trend_change'].cumsum()\n",
    "        tss = tss.merge(tss_na[[\"soc\", \"date\", \"vin\", 'soc_diff', 'in_charge_idx', 'trend', 'prev_trend', 'prev_prev_trend', 'trend_change',]], \n",
    "                        on=[\"soc\", \"date\", \"vin\"], how=\"left\")\n",
    "        tss[[\"odometer\",\"in_charge_idx\"]] = tss[[\"odometer\", \"in_charge_idx\"]].ffill()\n",
    "        return tss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tss = TeslaProcessedTimeSeries(\"tesla-fleet-telemetry\", force_update=True)\n",
    "processed_tss['in_charge_idx'] = processed_tss['in_charge_idx'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.stats_utils import series_start_end_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results = (processed_tss.groupby([\"vin\", \"in_charge_idx\"], observed=True, as_index=False).agg(\n",
    "            ac_energy_added_min=pd.NamedAgg(\"ac_charge_energy_added\", \"min\"),\n",
    "            dc_energy_added_min=pd.NamedAgg(\"dc_charge_energy_added\", \"min\"),\n",
    "            ac_energy_added_end=pd.NamedAgg(\"ac_charge_energy_added\", \"last\"),\n",
    "            dc_energy_added_end=pd.NamedAgg(\"dc_charge_energy_added\", \"last\"),\n",
    "            soc_diff=pd.NamedAgg(\"soc\", series_start_end_diff),\n",
    "            inside_temp=pd.NamedAgg(\"inside_temp\", \"mean\"),\n",
    "            net_capacity=pd.NamedAgg(\"net_capacity\", \"first\"),\n",
    "            range=pd.NamedAgg(\"range\", \"first\"),\n",
    "            odometer=pd.NamedAgg(\"odometer\", \"first\"),\n",
    "            version=pd.NamedAgg(\"version\", \"first\"),\n",
    "            size=pd.NamedAgg(\"soc\", \"size\"),\n",
    "            model=pd.NamedAgg(\"model\", \"first\"),\n",
    "            date=pd.NamedAgg(\"date\", \"first\"),\n",
    "            ac_charging_power=pd.NamedAgg(\"ac_charging_power\", \"median\"),\n",
    "            dc_charging_power=pd.NamedAgg(\"dc_charging_power\", \"median\"),\n",
    "            tesla_code=pd.NamedAgg(\"tesla_code\", \"first\"),\n",
    "        )\n",
    "        .eval(\"charging_power = ac_charging_power + dc_charging_power\")\n",
    "        .eval(\"ac_energy_added = ac_energy_added_end  - ac_energy_added_min\")\n",
    "        .eval(\"dc_energy_added = dc_energy_added_end  - dc_energy_added_min\")\n",
    "        .assign(energy_added=lambda df: np.maximum(df[\"ac_energy_added\"], df[\"dc_energy_added\"]))\n",
    "        .eval(\"soh = energy_added / (soc_diff / 100.0 * net_capacity)\")\n",
    "        .eval(\"level_1 = soc_diff * (charging_power < 8) / 100\")\n",
    "        .eval(\"level_2 = soc_diff * (charging_power.between(8, 45)) / 100\")\n",
    "        .eval(\"level_3 = soc_diff * (charging_power > 45) / 100\")\n",
    "        .sort_values([\"tesla_code\", \"vin\", \"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "25.788389 / (40.029564 / 100 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results[(raw_results['vin']==\"LRWYGCFS6PC992837\")][['soh', 'odometer', 'soc_diff', \"energy_added\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour repartir de ce qui est stocké\n",
    "#raw_results_origin = get_results_origin(force_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### Processed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_results.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOH_FILTER_EVAL = {\n",
    "     \"tesla-fleet-telemetry-30\": \"soh = soh.where(soc_diff > 30 & soh.between(0.75, 1.05))\",\n",
    "     \"tesla-fleet-telemetry-25\": \"soh = soh.where(soc_diff > 25 & soh.between(0.75, 1.05))\",\n",
    "     \"tesla-fleet-telemetry-20\": \"soh = soh.where(soc_diff > 20 & soh.between(0.75, 1.05))\",\n",
    "     \"tesla-fleet-telemetry-15\": \"soh = soh.where(soc_diff > 15 & soh.between(0.75, 1.05))\",\n",
    "     \"tesla-fleet-telemetry-8\": \"soh = soh.where(soc_diff > 8 & soh.between(0.75, 1.05))\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_results(brand:str) -> DF:\n",
    "    logger.info(f\"{'Processing ' + brand + ' results.':=^{50}}\")\n",
    "    results =  (\n",
    "        raw_results\n",
    "        # Some raw estimations may have inf values, this will make mask_out_outliers_by_interquartile_range and force_monotonic_decrease fail\n",
    "        # So we replace them by NaNs.\n",
    "        .assign(soh=lambda df: df[\"soh\"].replace([np.inf, -np.inf], np.nan))\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "        .pipe(make_charge_levels_presentable)\n",
    "        .eval(SOH_FILTER_EVAL[brand])\n",
    "        .pipe(agg_results_by_update_frequency)\n",
    "        .groupby('vin', observed=True)\n",
    "        .apply(make_soh_presentable_per_vehicle, include_groups=False)\n",
    "        .reset_index(level=0)\n",
    "        #.pipe(filter_results_by_lines_bounds, VALID_SOH_POINTS_LINE_BOUNDS, logger=logger)\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "    )\n",
    "    results[\"soh\"] = results.groupby(\"vin\", observed=True)[\"soh\"].ffill()\n",
    "    results[\"soh\"] = results.groupby(\"vin\", observed=True)[\"soh\"].bfill()\n",
    "    results[\"odometer\"] = results.groupby(\"vin\", observed=True)[\"odometer\"].ffill()\n",
    "    results[\"odometer\"] = results.groupby(\"vin\", observed=True)[\"odometer\"].bfill()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results_30 = get_processed_results('tesla-fleet-telemetry-30')\n",
    "processed_results_25 = get_processed_results('tesla-fleet-telemetry-25')\n",
    "processed_results_20 = get_processed_results('tesla-fleet-telemetry-20')\n",
    "processed_results_15 = get_processed_results('tesla-fleet-telemetry-15')\n",
    "processed_results_8 = get_processed_results('tesla-fleet-telemetry-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(raw_results[(raw_results['soh'] >.7) &(raw_results['soh'] < 1.05)].dropna(subset='soh'), x='odometer', y='soh', color='vin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(processed_results_30[(processed_results_30['soh'] > .75) &(processed_results_30['soh'] < 1.05)].dropna(subset='soh'), x='odometer', y='soh', color='vin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

