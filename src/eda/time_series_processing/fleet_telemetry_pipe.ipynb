{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Notebook pour tester le pipe de fleet-telemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Raw tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.s3_utils import *\n",
    "from transform.raw_tss.tesla_raw_tss import *\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from transform.processed_tss.config import *\n",
    "from core.constants import *\n",
    "from transform.raw_tss.config import *\n",
    "from transform.processed_tss.ProcessedTimeSeries import ProcessedTimeSeries\n",
    "from transform.raw_results.tesla_fleet_telemetry import get_results as get_results_origin\n",
    "from transform.processed_results.main import get_processed_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "S3_RAW_TSS_KEY_FORMAT = \"raw_ts/{brand}/time_series/raw_tss.parquet\"\n",
    "TESLA_RAW_TSS_KEY = S3_RAW_TSS_KEY_FORMAT.format(brand=\"tesla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3_Bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_tss(bucket: S3_Bucket = S3_Bucket()) -> DF:\n",
    "    logger.debug(\"Getting raw tss from responses provided by tesla fleet telemetry.\")\n",
    "    keys = get_response_keys_to_parse(bucket)\n",
    "    new_raw_tss = get_raw_tss_from_keys(keys, bucket)\n",
    "    if bucket.check_file_exists(FLEET_TELEMETRY_RAW_TSS_KEY):\n",
    "        return concat([bucket.read_parquet_df(FLEET_TELEMETRY_RAW_TSS_KEY), new_raw_tss])\n",
    "    else:\n",
    "        return new_raw_tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(raw_tss[raw_tss[\"vin\"] == \"LRWYGCFS6PC992837\"], x=\"readable_date\", y=\"ACChargingEnergyIn_stringValue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss = get_raw_tss(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Processed tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_tss.ProcessedTimeSeries import ProcessedTimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TeslaProcessedTimeSeries(ProcessedTimeSeries):\n",
    "\n",
    "    def __init__(self, make:str=\"tesla\", id_col:str=\"vin\", log_level:str=\"INFO\", max_td:TD=MAX_TD, force_update:bool=False, **kwargs):\n",
    "        self.logger = getLogger(make)\n",
    "        set_level_of_loggers_with_prefix(log_level, make)\n",
    "        super().__init__(make, id_col, log_level, max_td, force_update, **kwargs)\n",
    "\n",
    "    def compute_charge_n_discharge_vars(self, tss:DF) -> DF:\n",
    "        return (\n",
    "            tss\n",
    "            .pipe(self.compute_charge_n_discharge_masks)\n",
    "            .pipe(self.compute_charge_idx)\n",
    "            .pipe(self.compute_idx_from_masks, [\"in_discharge\"])\n",
    "            .pipe(self.trim_leading_n_trailing_soc_off_masks, [\"in_charge\", \"in_discharge\"])\n",
    "            .pipe(self.compute_idx_from_masks, [\"trimmed_in_charge\", \"trimmed_in_discharge\"])\n",
    "        )\n",
    "\n",
    "    def compute_charge_n_discharge_masks(self, tss:DF) -> DF:\n",
    "        self.logger.debug(\"Computing tesla specific charge and discharge masks\")\n",
    "        # We use a nullable boolean Series to represnet the rows where:\n",
    "        tss[\"nan_charging\"] = (\n",
    "            Series(pd.NA, index=tss.index, dtype=\"boolean\")# We are not sure of anything.\n",
    "            .mask(tss[\"charging_status\"].isin(IN_CHARGE_CHARGING_STATUS_VALS), True)# We are sure that the vehicle is in charge.\n",
    "            .mask(tss[\"charging_status\"].isin(IN_DISCHARGE_CHARGING_STATUS_VALS), False)# We are sure that the vehicle is not in charge.\n",
    "        )\n",
    "        # If a period of uncertainty (NaN) is surrounded by equal periods of certainties (True-NaN-True or False-NaN-False),\n",
    "        # We will fill them to the value of these certainties.\n",
    "        # However there are edge cases that have multiple days of uncertainties periods (I can't find the VIN but I'm sure you can ;-) )\n",
    "        # Interestingly enough the charge_energy_added variable does not get forwared that far and gets reset to zero. \n",
    "        # This would create outliers in our charge SoH estimation as we estimate the energy_gained as the diff between the last(0) and first value of charge_energy_added.\n",
    "        # So we set a maximal uncertainty period duration over which we don't fill it.\n",
    "        tss[\"nan_date\"] = tss[\"date\"].mask(tss[\"nan_charging\"].isna())\n",
    "        tss[[\"ffill_charging\", \"ffill_date\"]] = tss.groupby(\"vin\", observed=True)[[\"nan_charging\", \"nan_date\"]].ffill()\n",
    "        tss[[\"bfill_charging\", \"bfill_date\"]] = tss.groupby(\"vin\", observed=True)[[\"nan_charging\", \"nan_date\"]].bfill()\n",
    "        nan_period_duration:Series = tss.eval(\"bfill_date - ffill_date\")\n",
    "        fill_unknown_period = tss.eval(\"ffill_charging.eq(bfill_charging) & @nan_period_duration.le(@MAX_CHARGE_TD)\")\n",
    "        tss[\"nan_charging\"] = tss[\"nan_charging\"].mask(fill_unknown_period, tss[\"ffill_charging\"])\n",
    "        # As mentioned before, the SoC oscillates at [charge_limit_soc - ~3%, charge_limit_soc] so we set these periods to NaN as well.\n",
    "        tss[\"nan_charging\"] = tss[\"nan_charging\"].mask(tss[\"soc\"] >= (tss[\"charge_limit_soc\"] - 3))\n",
    "        # Then we seperate the Series into two, more explicit, columns.\n",
    "        tss[\"in_charge\"] = tss.eval(\"nan_charging.notna() & nan_charging\")\n",
    "        tss[\"in_discharge\"] = tss.eval(\"nan_charging.notna() & ~nan_charging\")\n",
    "        return tss.drop(columns=[\"nan_charging\", \"ffill_charging\", \"bfill_charging\", \"ffill_date\", \"bfill_date\"])\n",
    "    \n",
    "    def compute_enenergy_added(self, tss:DF) -> DF:\n",
    "        tss['charge_energy_added'] = tss['dc_charge_energy_added'].where(\n",
    "            tss['dc_charge_energy_added'].notnull() & \n",
    "            (tss['dc_charge_energy_added'] > 0), \n",
    "            tss['ac_charge_energy_added'])\n",
    "        return tss\n",
    "    \n",
    "    def compute_charge_idx(self, tss:DF) -> DF:\n",
    "        self.logger.debug(\"Computing tesla specific charge index.\")\n",
    "        if self.make == 'tesla-fleet-telemetry':\n",
    "            tss = tss.pipe(self.compute_enenergy_added)\n",
    "        tss_grp = tss.groupby(\"vin\", observed=False)\n",
    "        tss[\"charge_energy_added\"] = tss_grp[\"charge_energy_added\"].ffill()\n",
    "        energy_added_over_time = tss_grp['charge_energy_added'].diff().div(tss[\"sec_time_diff\"].values)\n",
    "        # charge_energy_added is cummulative and forward filled, \n",
    "        # We check that the charge_energy_added decreases too fast to make sure that  correctly indentify two charging periods before and after a gap as two separate charging periods.\n",
    "        new_charge_mask = energy_added_over_time.lt(MIN_POWER_LOSS, fill_value=0) \n",
    "        # For the same reason, we ensure that there are no gaps bigger than MAX_CHARGE_TD in between to rows of the same charging period.\n",
    "        new_charge_mask |= tss[\"time_diff\"].gt(MAX_CHARGE_TD) \n",
    "        # And of course we also check that there is no change of status. \n",
    "        new_charge_mask |= (~tss_grp[\"in_charge\"].shift() & tss[\"in_charge\"]) \n",
    "        tss[\"in_charge_idx\"] = new_charge_mask.groupby(tss[\"vin\"], observed=True).cumsum()\n",
    "        print(tss[\"in_charge_idx\"].count() / len(tss))\n",
    "        tss[\"in_charge_idx\"] = tss[\"in_charge_idx\"].fillna(-1).astype(\"uint16\")\n",
    "        return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tss = TeslaProcessedTimeSeries(\"tesla-fleet-telemetry\", force_update=True, filters=[(\"trimmed_in_charge\", \"==\", True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tss[processed_tss['vin'] == \"LRWYGCFS6PC992837\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results = (processed_tss.groupby([\"vin\", \"trimmed_in_charge_idx\"], observed=True, as_index=False).agg(\n",
    "            ac_energy_added_min=pd.NamedAgg(\"ac_charge_energy_added\", \"min\"),\n",
    "            dc_energy_added_min=pd.NamedAgg(\"dc_charge_energy_added\", \"min\"),\n",
    "            ac_energy_added_end=pd.NamedAgg(\"ac_charge_energy_added\", \"last\"),\n",
    "            dc_energy_added_end=pd.NamedAgg(\"dc_charge_energy_added\", \"last\"),\n",
    "            soc_diff=pd.NamedAgg(\"soc\", series_start_end_diff),\n",
    "            inside_temp=pd.NamedAgg(\"inside_temp\", \"mean\"),\n",
    "            net_capacity=pd.NamedAgg(\"net_capacity\", \"first\"),\n",
    "            range=pd.NamedAgg(\"range\", \"first\"),\n",
    "            odometer=pd.NamedAgg(\"odometer\", \"first\"),\n",
    "            version=pd.NamedAgg(\"version\", \"first\"),\n",
    "            size=pd.NamedAgg(\"soc\", \"size\"),\n",
    "            model=pd.NamedAgg(\"model\", \"first\"),\n",
    "            date=pd.NamedAgg(\"date\", \"first\"),\n",
    "            ac_charging_power=pd.NamedAgg(\"ac_charging_power\", \"median\"),\n",
    "            dc_charging_power=pd.NamedAgg(\"dc_charging_power\", \"median\"),\n",
    "            tesla_code=pd.NamedAgg(\"tesla_code\", \"first\"),\n",
    "        )\n",
    "        .eval(\"charging_power = ac_charging_power + dc_charging_power\")\n",
    "        .eval(\"ac_energy_added = ac_energy_added_end  - ac_energy_added_min\")\n",
    "        .eval(\"dc_energy_added = dc_energy_added_end  - dc_energy_added_min\")\n",
    "        .assign(energy_added=lambda df: np.minimum(df[\"ac_energy_added\"], df[\"dc_energy_added\"]))\n",
    "        .eval(\"soh = energy_added / (soc_diff / 100.0 * net_capacity)\")\n",
    "        .eval(\"level_1 = soc_diff * (charging_power < 8) / 100\")\n",
    "        .eval(\"level_2 = soc_diff * (charging_power.between(8, 45)) / 100\")\n",
    "        .eval(\"level_3 = soc_diff * (charging_power > 45) / 100\")\n",
    "        .sort_values([\"tesla_code\", \"vin\", \"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results_origin = get_results_origin(force_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results[raw_results['vin'] == \"LRWYGCFS6PC992837\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Processed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_results.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_results(brand:str) -> DF:\n",
    "    logger.info(f\"{'Processing ' + brand + ' results.':=^{50}}\")\n",
    "    results =  (\n",
    "        raw_results\n",
    "        # Some raw estimations may have inf values, this will make mask_out_outliers_by_interquartile_range and force_monotonic_decrease fail\n",
    "        # So we replace them by NaNs.\n",
    "        .assign(soh=lambda df: df[\"soh\"].replace([np.inf, -np.inf], np.nan))\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "        .pipe(make_charge_levels_presentable)\n",
    "        .eval(SOH_FILTER_EVAL_STRINGS[brand])\n",
    "        .pipe(agg_results_by_update_frequency)\n",
    "        .groupby('vin', observed=True)\n",
    "        .apply(make_soh_presentable_per_vehicle, include_groups=False)\n",
    "        .reset_index(level=0)\n",
    "        .pipe(filter_results_by_lines_bounds, VALID_SOH_POINTS_LINE_BOUNDS, logger=logger)\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "    )\n",
    "    results[\"soh\"] = results.groupby(\"vin\", observed=True)[\"soh\"].ffill()\n",
    "    results[\"soh\"] = results.groupby(\"vin\", observed=True)[\"soh\"].bfill()\n",
    "    results[\"odometer\"] = results.groupby(\"vin\", observed=True)[\"odometer\"].ffill()\n",
    "    results[\"odometer\"] = results.groupby(\"vin\", observed=True)[\"odometer\"].bfill()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results = get_processed_results('tesla-fleet-telemetry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "(22.9) / (38.950089 / 100.0 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results[raw_results['vin']==\"LRWYGCFS6PC992837\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tss[(processed_tss['vin']==\"LRWYGCFS6PC992837\") & \n",
    "              (processed_tss['trimmed_in_charge_idx']) > 0][['date', 'soc', 'odometer','dc_charge_energy_added',\"ac_charge_energy_added\", 'trimmed_in_charge_idx']].dropna(subset='soc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tss['trimmed_in_charge_idx'] = processed_tss['trimmed_in_charge_idx'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tss[(processed_tss['vin']==\"LRWYGCFS6PC992837\")]['trimmed_in_charge_idx'].max() > 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

