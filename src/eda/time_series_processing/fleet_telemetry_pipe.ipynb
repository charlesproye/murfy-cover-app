{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Notebook pour tester le pipe de fleet-telemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Raw tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.s3_utils import *\n",
    "from transform.raw_tss.fleet_telemetry_raw_tss import *\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from transform.processed_tss.config import *\n",
    "from core.constants import *\n",
    "from transform.raw_tss.config import *\n",
    "# from transform.processed_tss.ProcessedTimeSeries import ProcessedTimeSeries\n",
    "from transform.raw_results.tesla_fleet_telemetry import get_results as get_results_origin\n",
    "from transform.processed_results.main import get_processed_results\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_RAW_TSS_KEY_FORMAT = \"raw_ts/{brand}/time_series/raw_tss.parquet\"\n",
    "FLEET_TELEMETRY_RAW_TSS_KEY = S3_RAW_TSS_KEY_FORMAT.format(brand=\"tesla-fleet-telemetry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLEET_TELEMETRY_RAW_TSS_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3_Bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = S3_Bucket().get_creds_from_dot_env()['aws_access_key_id']\n",
    "secret_key = S3_Bucket().get_creds_from_dot_env()['aws_secret_access_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from transform.raw_tss.fleet_telemetry_raw_tss import *\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages org.apache.hadoop:hadoop-aws:3.3.4 pyspark-shell\"\n",
    "\n",
    ")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Scaleway S3 Read JSON\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"https://s3.fr-par.scw.cloud\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Raw TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = RawTss(\"ford\", spark=spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Ford.get_raw_tss(Ford.spark, force_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Process TTS Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_tss.ProcessedTimeSeriesSpark import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ProcessedTimeSeries(\"tesla-fleet-telemetry\", spark=spark, force_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Raw res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.raw_results.RawResults import RawResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RawResult('tesla-fleet-telemetry', spark=spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.raw_tss.RawTss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet(\"s3a://bib-platform-prod-data/raw_ts/tesla-fleet-telemetry/time_series/spark_raw_tss.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

