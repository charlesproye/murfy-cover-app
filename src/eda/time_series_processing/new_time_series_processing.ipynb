{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve time series processing\n",
    "Most of the current code for processing time series is legacy code from watea POC.  \n",
    "It works but is not optimized and is not scalable.  \n",
    "This is because it was concieved to be used on a single time series at a time.  \n",
    "We need to change this to be able to process multiple time series in a single DataFrame.  \n",
    "This will hopefully improve the performance and scalability of the code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Timedelta as TD\n",
    "from rich.progress import Progress\n",
    "import plotly.express as px\n",
    "\n",
    "from core.logging_utils import set_level_of_loggers_with_prefix\n",
    "from core.pandas_utils import *\n",
    "from core.time_series_processing import *\n",
    "from transform.raw_tss.main import get_raw_tss\n",
    "from transform.processed_tss.config import *\n",
    "from transform.fleet_info.main import fleet_info\n",
    "\n",
    "logger = getLogger(\"transform.processed_tss.tesla\")\n",
    "set_level_of_loggers_with_prefix(\"DEBUG\", \"transform.processed_tss.tesla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss = get_raw_tss(\"tesla\")\n",
    "raw_tss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I copied pasted the legacy code here for future references once the new implementation will have replaced it.  \n",
    "I also added comments to the code to explain what it does(wrong).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legacy_tesla_processed_tss(raw_tss:DF) -> DF:\n",
    "    with Progress(transient=True) as progress:\n",
    "        task = progress.add_task(\"Processing VINs...\", visible=False, total=raw_tss[\"vin\"].nunique())\n",
    "        return (\n",
    "            raw_tss\n",
    "            .rename(columns=RENAME_COLS_DICT, errors=\"ignore\")\n",
    "            .pipe(safe_locate, col_loc=list(COL_DTYPES.keys()), logger=logger)\n",
    "            .pipe(safe_astype, COL_DTYPES, logger=logger)\n",
    "            # We should probably not drop duplicates as there might be multiple measurements for the same date\n",
    "            # We should probobably check the responses parsing an switch from concatenating to joining/merging on date instead.\n",
    "            .drop_duplicates(subset=[\"vin\", \"date\"]) \n",
    "            .sort_values(by=[\"vin\", \"date\"])\n",
    "            .pipe(legacy_charge_n_discharging, \"vin\", CHARGING_STATUS_VAL_TO_MASK, logger) \n",
    "            .groupby(\"vin\")\n",
    "            .apply(legacy_tesla_process_ts, progress, task, include_groups=False)\n",
    "            .reset_index(drop=False)\n",
    "            .pipe(set_all_str_cols_to_lower, but=[\"vin\"])\n",
    "            .pipe(left_merge, fleet_info.dropna(subset=[\"vin\"]), \"vin\", \"vin\", COLS_TO_CPY_FROM_FLEET_INFO, logger)\n",
    "            .pipe(compute_discharge_diffs, DISCHARGE_VARS_TO_MEASURE, logger)\n",
    "        )\n",
    "\n",
    "def legacy_tesla_process_ts(raw_ts: DF, progress: Progress, task) -> DF:\n",
    "    vin = raw_ts.name\n",
    "    progress.update(task, visible=True, advance=1, description=f\"Processing vin {vin}...\")\n",
    "    if progress.finished:\n",
    "        progress.update(task, visible=False)\n",
    "    return (\n",
    "        raw_ts\n",
    "        .assign(\n",
    "            # We don't use any of these variables later in the pipeline so we can drop them\n",
    "            ffiled_outside_temp=raw_ts[\"outside_temp\"].ffill(),\n",
    "            ffiled_inside_temp=raw_ts[\"inside_temp\"].ffill(),\n",
    "            floored_soc=floor_to(raw_ts[\"soc\"].ffill(), 1),\n",
    "            date_diff=raw_ts[\"date\"].diff(),\n",
    "            soc_diff=raw_ts[\"soc\"].diff(),\n",
    "        )\n",
    "        .pipe(compute_cum_energy, power_col=\"power\", cum_energy_col=\"cum_energy\")\n",
    "        # The only column we actually use from this function is cum_charge_energy_added from charger_power\n",
    "        # Instead of doing a groupby/apply we can perform a single compute_cum_energy call\n",
    "        # And then compute some sort of energy_added_offset that resets the results to zero at the start of each vin time series.\n",
    "        .pipe(compute_cum_energy, power_col=\"charger_power\", cum_energy_col=\"cum_charge_energy_added\")\n",
    "        .assign(energy_added=lambda tss: tss[\"cum_charge_energy_added\"].diff())\n",
    "        .assign(energy_diff=lambda df: df[\"cum_energy\"].diff())\n",
    "        .pipe(fillna_vars, COLS_TO_FILL, MAX_TIME_DIFF_TO_FILL)\n",
    "    )\n",
    "\n",
    "def legacy_charge_n_discharging(tss:DF, id_col:str=None, charging_status_val_to_mask:dict=None, logger:Logger=logger) -> DF:\n",
    "    \"\"\"\n",
    "    ### Description:\n",
    "    Computes the charging and discharging masks for a time series.\n",
    "    Uses the string charging_status column if it exists, otherwise uses the soc difference.\n",
    "    ### Parameters:\n",
    "    id_col: optional parameter to provide if the dataframe represents multiple time series.\n",
    "    charging_status_val_to_mask: dict mapping charging status values to boolean values to create masks.\n",
    "    \"\"\"\n",
    "    logger.info(f\"compute_charging_n_discharging_masks called.\")\n",
    "    if \"charging_status\" in tss.columns and charging_status_val_to_mask is not None:\n",
    "        logger.debug(f\"Computing charging and discharging masks using charging status dictionary.\")\n",
    "        charge_mask = tss[\"charging_status\"].map(charging_status_val_to_mask)\n",
    "        tss[\"in_charge\"] = charge_mask\n",
    "        tss[\"in_discharge\"] = charge_mask == False\n",
    "        if id_col is not None and id_col in tss.columns:\n",
    "            tss = (\n",
    "                tss\n",
    "                .groupby(id_col)\n",
    "                .apply(compute_charge_n_discharge_perf_mask_and_idx_from_masks)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "        else:\n",
    "            tss = compute_charge_n_discharge_perf_mask_and_idx_from_masks(tss)\n",
    "        return tss\n",
    "    elif \"soc\" in tss.columns:\n",
    "        logger.debug(f\"Computing charging and discharging masks using soc difference.\")\n",
    "        if id_col in tss.columns:\n",
    "            return (\n",
    "                tss\n",
    "                .groupby(id_col)\n",
    "                .apply(low_freq_compute_charge_n_discharge_vars)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "        else:\n",
    "            return low_freq_compute_charge_n_discharge_vars(tss)\n",
    "    else:\n",
    "        logger.warning(\"No charging status or soc column found to compute charging and discharging masks, returning original tss.\")\n",
    "        return tss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TD = TD(hours=1, minutes=30)\n",
    "\n",
    "def new_process_raw_tss(raw_tss:DF, logger=logger) -> DF:\n",
    "    return (\n",
    "        raw_tss\n",
    "        .rename(columns=RENAME_COLS_DICT, errors=\"ignore\")\n",
    "        .pipe(safe_locate, col_loc=list(COL_DTYPES.keys()), logger=logger)\n",
    "        .pipe(safe_astype, COL_DTYPES, logger=logger)\n",
    "        .sort_values(by=[\"vin\", \"date\"])\n",
    "        .pipe(compute_date_vars, \"vin\", logger)\n",
    "        .pipe(new_charge_n_discharging_from_charging_status, IN_CHARGE_CHARGING_STATUS_VALS, IN_DISCHARGE_CHARGING_STATUS_VALS, MAX_TD, \"vin\", logger)\n",
    "    )\n",
    "\n",
    "def compute_date_vars(tss:DF, id_col:str=\"vin\", logger:Logger=logger) -> DF:\n",
    "    logger.debug(f\"Computing sec_date and sec_date_diff.\")\n",
    "    tss[\"time_diff\"] = tss.groupby(id_col)[\"date\"].diff()\n",
    "    tss[\"sec_time_diff\"] = tss[\"time_diff\"].dt.total_seconds()\n",
    "    return tss\n",
    "\n",
    "def new_charge_n_discharging_from_charging_status(tss:DF, in_charge_vals:list, in_discharge_vals:list, max_td:TD=None, id_col:str=\"vin\", logger:Logger=logger) -> DF:\n",
    "    logger.debug(f\"Computing charging and discharging vars using charging status dictionary.\")\n",
    "    return (\n",
    "        tss\n",
    "        .eval(\"charging_status = charging_status.str.lower()\")\n",
    "        .eval(f\"in_charge = charging_status in {in_charge_vals}\")\n",
    "        .eval(f\"in_discharge = charging_status in {in_discharge_vals}\")\n",
    "        .pipe(compute_idx_from_mask, \"in_charge\", max_td, id_col, logger)\n",
    "        .pipe(compute_idx_from_mask, \"in_discharge\", max_td, id_col, logger)\n",
    "    )\n",
    "\n",
    "def compute_idx_from_mask(tss: DF, src_mask:str, max_time_diff:TD=None, id_col:str=\"vin\", logger:Logger=logger) -> DF:\n",
    "    logger.debug(f\"Computing {src_mask}_idx from {src_mask} mask.\")\n",
    "    idx_col_name = f\"{src_mask}_idx\"\n",
    "    shifted_mask = tss.groupby(id_col)[src_mask].shift(fill_value=False)\n",
    "    tss[\"new_period_start_mask\"] = shifted_mask.ne(tss[src_mask]) \n",
    "    if max_time_diff is not None:\n",
    "        logger.debug(f\"Adding max_time_diff condition to new_period_start_mask.\")\n",
    "        tss[\"new_period_start_mask\"] |= (tss[\"time_diff\"] > max_time_diff)\n",
    "    else:\n",
    "        logger.debug(f\"No max_time_diff condition added to new_period_start_mask.\")\n",
    "    tss[idx_col_name] = tss.groupby(id_col)[\"new_period_start_mask\"].cumsum().astype(\"uint16\")\n",
    "    tss.drop(columns=[\"new_period_start_mask\"], inplace=True)\n",
    "    return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = new_process_raw_tss(raw_tss, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VINS = [\n",
    "    \"LRW3E7EK5PC797921\",\n",
    "    \"5YJ3E7EA9LF751886\",\n",
    "    \"XP7YGCEL2RB413022\",\n",
    "    \"LRW3E7FR7NC480876\",\n",
    "    \"XP7YGCES9RB442881\",\n",
    "]\n",
    "#vin = tss[\"vin\"].sample(3)\n",
    "ts = tss.query(\"vin in @VINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    ts.eval(\"charging_status = charging_status.fillna('Unknown')\"),\n",
    "    x=\"date\",\n",
    "    y=\"soc\",\n",
    "    color=\"in_charge_idx\",\n",
    "    color_continuous_scale=\"Rainbow\",\n",
    "    symbol=\"in_charge\",\n",
    "    hover_data=\"charging_status\",\n",
    "    facet_row=\"vin\",\n",
    ")\n",
    "fig.update_layout(height=1000, showlegend=False)\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

