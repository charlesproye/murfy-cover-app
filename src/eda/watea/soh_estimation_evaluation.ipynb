{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of our soh estimation\n",
    "The goal of this notebook is to establish a way of evaluatig our own estimation.  \n",
    "Given the fact that we don't have a ground trhuth to compare our estimation with, we will have to get creative.  \n",
    "We want to:  \n",
    "1.  Visualize the estimation of the soh\n",
    "1.  Quantify the evaluation of the estimation\n",
    "1.  Visualize the change in soh estimation   \n",
    "\n",
    "This evaluation could then be used to improve our soh estimation pipeline either manually or, ideally, programmatically using hyper tunning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import linregress\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "from core.pandas_utils import floor_to\n",
    "from core.plt_utils import plt_3d_df\n",
    "from transform.watea.soh_estimation import get_processed_cluster, get_soh_per_charges\n",
    "from transform.watea.watea_config import SOH_ESTIMATION_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_cluster = get_processed_cluster()\n",
    "charges = get_soh_per_charges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation Visualization\n",
    "We will visualize the results per charging point, per charge over odometer.  \n",
    "We will also visualize it over features to interpret their respective influence over the final etimation both in 2d and in 3d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soh over odometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    processed_cluster,\n",
    "    \"odometer\",\n",
    "    \"soh\",\n",
    "    color=\"id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    charges,\n",
    "    \"odometer\",\n",
    "    \"soh\",\n",
    "    color=\"id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOH over features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in SOH_ESTIMATION_FEATURES:\n",
    "    (\n",
    "        px.scatter(\n",
    "            processed_cluster,\n",
    "            feature,\n",
    "            \"soh\",\n",
    "            trendline=\"rolling\",\n",
    "            opacity=0.25,\n",
    "            trendline_options={\"window\": 100},\n",
    "            trendline_scope=\"overall\",\n",
    "            color=\"id\"\n",
    "        )\n",
    "        .update_traces(line={\"color\": \"red\"})\n",
    "        .show()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### energy_added estimation over features\n",
    "I will re implement this properly when I have time :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import DataFrame as DF\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# FEATURES = [\"voltage\", \"temperature\", \"current\"]\n",
    "\n",
    "# def estimate_soh(cluster:DF) -> tuple[DF, Pipeline]:\n",
    "#     x = cluster[FEATURES].values\n",
    "#     y = cluster[\"energy_added\"].values\n",
    "#     soh_estimator = (\n",
    "#         Pipeline([\n",
    "#             ('poly_features', PolynomialFeatures(degree=10)),\n",
    "#             ('regressor', LinearRegression())\n",
    "#         ])\n",
    "#         .fit(X=x, y=y)\n",
    "#     )\n",
    "#     cluster[\"general_energy_added\"] = (\n",
    "#         soh_estimator\n",
    "#         .predict(X=x)\n",
    "#         .squeeze()\n",
    "#     )\n",
    "#     default_100_soh_cluster = cluster.query(\"is_default_100_soh\")\n",
    "#     y2_pred = soh_estimator.predict(default_100_soh_cluster[FEATURES])\n",
    "#     residuals = default_100_soh_cluster['energy_added'] - y2_pred\n",
    "#     initial_intercept = soh_estimator.named_steps['regressor'].intercept_\n",
    "#     adjusted_intercept = initial_intercept + residuals.mean()\n",
    "#     soh_estimator.named_steps['regressor'].intercept_ = adjusted_intercept\n",
    "\n",
    "#     cluster:DF = (\n",
    "#         cluster\n",
    "#         .assign(default_100_energy_added=soh_estimator.predict(cluster[FEATURES]))\n",
    "#         .eval(\"soh = 100 * energy_added / default_100_energy_added\")\n",
    "#         .eval(\"residual = default_100_energy_added - energy_added\")\n",
    "#     )\n",
    "#     cluster[\"residual\"] = cluster[\"residual\"].abs()\n",
    "\n",
    "    \n",
    "#     return cluster, soh_estimator\n",
    "\n",
    "# reprocessed_cluster, soh_estimator = estimate_soh(processed_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# mins = processed_cluster[FEATURES].min().values\n",
    "# maxs = processed_cluster[FEATURES].max().values\n",
    "\n",
    "# # Create a 1D array for each feature using np.arange with a step of 1\n",
    "# voltage_range = np.arange(mins[0], maxs[0] + 1, 1)  # Add 1 to include the max\n",
    "# temperature_range = np.arange(mins[1], maxs[1] + 1, 1)\n",
    "\n",
    "# # Create a 2D grid of all combinations of voltage and temperature\n",
    "# voltage_grid, temperature_grid = np.meshgrid(voltage_range, temperature_range)\n",
    "\n",
    "# # Flatten the grids to make a 2D array of shape (n_points, 2)\n",
    "# decision_boundry_input = np.c_[voltage_grid.ravel(), temperature_grid.ravel()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = soh_estimator.predict(decision_boundry_input)\n",
    "# z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.graph_objects as go\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from plotly.graph_objects import Figure\n",
    "\n",
    "# # Assume you already have the FEATURES, processed_cluster, and soh_estimator defined.\n",
    "\n",
    "# FEATURES_TO_SHOW = [\"voltage\", \"temperature\"]\n",
    "\n",
    "# # Step 1: Generate the grid of input points\n",
    "# mins = processed_cluster[FEATURES].min().values\n",
    "# # maxs = processed_cluster[FEATURES].max().values\n",
    "\n",
    "# # Create a 1D array for each feature using np.arange with a step of 1\n",
    "# voltage_range = np.arange(mins[0], maxs[0] + 1, 1)  # Voltage range\n",
    "# temperature_range = np.arange(mins[1], maxs[1] + 1, 1)  # Temperature range\n",
    "\n",
    "# # Create a 2D grid of all combinations of voltage and temperature\n",
    "# voltage_grid, temperature_grid = np.meshgrid(voltage_range, temperature_range)\n",
    "\n",
    "# # Flatten the grids to create a 2D array with (n_points, 2) shape\n",
    "# decision_boundry_input = np.c_[voltage_grid.ravel(), temperature_grid.ravel()]\n",
    "\n",
    "# # Step 2: Predict the z-values using the 'soh_estimator' pipeline\n",
    "# z_pred = soh_estimator.predict(decision_boundry_input)\n",
    "\n",
    "# # Step 3: Reshape the predicted values back into the grid shape\n",
    "# z_grid = z_pred.reshape(voltage_grid.shape)\n",
    "\n",
    "\n",
    "# def plt_3d_df(\n",
    "#         df: DF,\n",
    "#         x:str,\n",
    "#         y:str,\n",
    "#         z:str,\n",
    "#         color:str=None,\n",
    "#         opacity=0.5,\n",
    "#         colorscale='Rainbow',\n",
    "#         size=3,\n",
    "#         width=1500,\n",
    "#         height=1000,\n",
    "#         hover_name=None,\n",
    "#     ) -> Figure:\n",
    "#     return (\n",
    "#         px.scatter_3d(\n",
    "#             df,\n",
    "#             x,\n",
    "#             y,\n",
    "#             z,\n",
    "#             color,\n",
    "#             opacity=opacity,\n",
    "#             width=width,\n",
    "#             height=height,\n",
    "#             hover_name=hover_name,\n",
    "#             size=[size] * len(df),\n",
    "#             color_continuous_scale=colorscale,\n",
    "#         ) \n",
    "#         .update_traces(marker=dict(line=dict(width=0)))\n",
    "#         .update_layout(\n",
    "#             scene=dict(\n",
    "#                 camera=dict(\n",
    "#                     projection=dict(\n",
    "#                         type='orthographic'  # Keeps projection consistent\n",
    "#                     )\n",
    "#                 ),\n",
    "#                 zaxis=dict(\n",
    "#                     backgroundcolor=\"white\",  # Make the background lighter\n",
    "#                     showgrid=True,  # Gridlines help with depth perception\n",
    "#                     showspikes=False,\n",
    "#                 ),\n",
    "#                 xaxis=dict(\n",
    "#                     showgrid=True,\n",
    "#                 ),\n",
    "#                 yaxis=dict(\n",
    "#                     showgrid=True,\n",
    "#                 ),\n",
    "#             ),\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# # Use the same figure as before and add the surface trace\n",
    "# fig = plt_3d_df(processed_cluster.query(\"odometer <= 3000\"), \"voltage\", \"temperature\", \"energy_added\", \"id\", opacity=1)\n",
    "\n",
    "# # Add the surface trace to the same figure\n",
    "# fig.add_trace(\n",
    "#     go.Surface(\n",
    "#         x=voltage_grid,  # X-axis: voltage\n",
    "#         y=temperature_grid,  # Y-axis: temperature\n",
    "#         z=z_grid,  # Z-axis: predicted SOH (or another target value)\n",
    "#         colorscale=\"Rainbow\",\n",
    "#         # opacity=0.6,  # Set opacity to make the surface semi-transparent\n",
    "#         showscale=False,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Show the figure\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model change visualization\n",
    "To visualize the changes in estimation we will implement a function in plt_utils to plot a scatter with the two estimations and arrwos to visualize the direction and magnitude of change.  \n",
    "We will emulate a diffrent soh estimation by adding niose to our original estimation.  \n",
    "There are two reasons for adding noise to the original estimation:\n",
    "1.  It's easy to do.\n",
    "1.  If our programmatic soh estimation evaluation method works it should give us a worse score.  \n",
    "    Hopefully it will reliably give us a better for better soh estimations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_charges = processed_cluster.groupby(\"charge_id\").agg({\"odometer\": \"median\", \"soh\":\"median\", \"id\":\"first\", \"charge_id\":\"first\"})\n",
    "new_charges = reprocessed_cluster.groupby(\"charge_id\").agg({\"odometer\": \"median\", \"soh\":\"median\", \"id\":\"first\", \"charge_id\":\"first\"})\n",
    "\n",
    "old_and_new_charges = pd.concat((old_charges, new_charges))\n",
    "arrow_df = (\n",
    "    old_charges\n",
    "    .assign(new_soh=new_charges['soh'])\n",
    "    .assign(empty_col=pd.NA)\n",
    "    .loc[:, [\"odometer\", \"id\", \"soh\", \"new_soh\", \"empty_col\"]]\n",
    "    .set_index([\"odometer\", \"id\"], append=True)\n",
    "    .T\n",
    "    .unstack()\n",
    "    .to_frame()\n",
    "    .rename(columns={0: \"soh\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "MARKER_SIZE = 8\n",
    "\n",
    "fig = (\n",
    "    px.scatter(\n",
    "        old_and_new_charges,\n",
    "        \"odometer\",\n",
    "        \"soh\",\n",
    "        color=\"id\",\n",
    "    )\n",
    "    .add_trace(\n",
    "        go.Scatter(\n",
    "            x=arrow_df[\"odometer\"],\n",
    "            y=arrow_df[\"soh\"],\n",
    "            mode=\"markers+lines\",\n",
    "            marker=dict(\n",
    "                symbol=\"arrow\",\n",
    "                color=\"royalblue\",\n",
    "                size=MARKER_SIZE,\n",
    "                angleref=\"previous\",\n",
    "                standoff=MARKER_SIZE / 2,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have a (more) convinient way to visualize the impact of the changes on our soh estimation.  \n",
    "Unfortunatly, tweaking manually the soh estimation pipeline is to unefficient.  \n",
    "Let's try to programatically search for a better soh estimation through hyperparameter tunning.  \n",
    "To do so we will need a reward/loss function.  \n",
    "Since this is an unsupervised regression task, we will need to get creative...  \n",
    "We will try to use the values mean of the outputs of scipy.stats.linregress per vehicle (as we are (almost) sure that the soh should be monotonically decreasing per vehicle).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = [\n",
    "    \"slope\",\n",
    "    \"intercept\",\n",
    "    \"rvalue\",\n",
    "    \"pvalue\",\n",
    "    \"stderr\",\n",
    "    # \"intercept_stderr\",\n",
    "]\n",
    "\n",
    "def reward_function(processed_cluster:DF) -> float:\n",
    "    return (\n",
    "        processed_cluster\n",
    "        .groupby(\"id\")\n",
    "        .apply(lambda df: Series(linregress(df[\"odometer\"], df[\"soh\"]), INDEX), include_groups=False)\n",
    "        .eval(\"r2 = rvalue ** 2\")\n",
    "        .groupby(level=0)\n",
    "        .mean()\n",
    "        .mean()\n",
    "        .loc[:, \"r2\"]\n",
    "    )\n",
    "\n",
    "lr_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason there is no intercept_stderr when constructing the df using Series but that's alright for now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

