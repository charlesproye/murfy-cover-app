{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "\n",
    "\n",
    "# URL to scrapp\n",
    "base_url = \"https://www.autosphere.fr\"\n",
    "# All electric\n",
    "search_url_template = \"https://www.autosphere.fr/recherche?fuel_type=Electrique&from={}\"\n",
    "# Pour un modèle en particulier\n",
    "search_url_model = \"https://www.autosphere.fr/recherche?fuel_type=Electrique&brand=Peugeot&model=2008\"\n",
    "\n",
    "# la pagination d'autosphère se fait via un from et avance de 23 en 23 pour le moment\n",
    "all_links = set()\n",
    "offset = 2576 # -> start\n",
    "step = 23\n",
    "infos = {} # Pour le df de fin a exporter dans l'excel \n",
    "\n",
    "\n",
    "### On récupère tous les liens en parcourant toutes les pages\n",
    "\n",
    "while True:\n",
    "    url = search_url_template.format(offset)\n",
    "    print(f\"Scraping page avec from={offset} ...\")\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # S'arrête lorsque que la page n'a pas de lien\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Page avec from={offset} inaccessible. Fin du scraping.\")\n",
    "        break\n",
    "\n",
    "    # Structure des lien des véhicules -> fiche ou fiche4 ou fiche-mixte puis / auto-occasion\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    new_links = set()\n",
    "    for a_tag in soup.select('a[href*=\"/fiche\"]'):\n",
    "        href = a_tag.get('href')\n",
    "        if href and \"/auto-occasion\" in href:\n",
    "            full_url = base_url + href\n",
    "            new_links.add(full_url)\n",
    "\n",
    "    if not new_links:\n",
    "        print(f\"Aucun nouveau lien trouvé avec from={offset}. Fin du scraping.\")\n",
    "        break\n",
    "\n",
    "    initial_count = len(all_links)\n",
    "    all_links.update(new_links)\n",
    "    added_count = len(all_links) - initial_count\n",
    "\n",
    "    print(f\"{added_count} nouveaux liens trouvés avec from={offset}.\")\n",
    "    offset += step\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\nNombre total de fiches uniques récupérées : {len(all_links)}\")\n",
    "\n",
    "### Récupération des infos pour chaque véhicule\n",
    "car_nbr = 1\n",
    "for link in all_links:\n",
    "    infos[car_nbr] = {}\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # options.add_argument(\"--headless\")  # Active cette ligne si tu veux en mode sans fenêtre\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    driver.get(link)\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "\n",
    "        all_li = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//li\")))\n",
    "\n",
    "        score_sante = None\n",
    "        kilometrage = None\n",
    "        annee = None\n",
    "\n",
    "        for li in all_li:\n",
    "            text = li.text.strip()\n",
    "\n",
    "            if \"Santé\" in text and not score_sante:\n",
    "                match = re.search(r\"(\\d+\\s?%)\", text)\n",
    "                if match:\n",
    "                    score_sante = match.group(1)\n",
    "\n",
    "            if \"km\" in text and not kilometrage:\n",
    "                match = re.search(r\"([\\d\\s]+km)\", text)\n",
    "                if match:\n",
    "                    kilometrage = match.group(1).strip().replace(\"\\u202f\", \"\").replace(\" \", \"\").replace(\"km\", \"\").strip()\n",
    "\n",
    "            if re.search(r\"\\b20\\d{2}\\b\", text) and not annee:\n",
    "                annee = re.search(r\"\\b(20\\d{2})\\b\", text).group(1)\n",
    "\n",
    "        # Titre principal de la fiche (h1)\n",
    "        titre_element = wait.until(EC.presence_of_element_located((By.XPATH, \"//h1\")))\n",
    "        titre_text = titre_element.text.strip()\n",
    "\n",
    "        # Version courte si détectée dans le titre\n",
    "        version = None\n",
    "        match = re.search(r\"\\d+ch\\s+\\w+\", titre_text)\n",
    "        if match:\n",
    "            version = match.group(0)\n",
    "\n",
    "        # === Récupération de la marque, modèle, version complète via fil d’Ariane ===\n",
    "        marque = None\n",
    "        modele = None\n",
    "        version_complete = None\n",
    "\n",
    "        try:\n",
    "            links_breadcrumb = wait.until(EC.presence_of_all_elements_located(\n",
    "                (By.CSS_SELECTOR, \"li.inline-flex.items-center a.text-blue-700\")\n",
    "            ))\n",
    "            if len(links_breadcrumb) >= 2:\n",
    "                marque = links_breadcrumb[2].text.strip()\n",
    "                modele = links_breadcrumb[3].text.strip()\n",
    "            version_span = driver.find_element(By.CSS_SELECTOR, \"span.text-black-600\")\n",
    "            version_complete = version_span.text.strip()\n",
    "            if version_complete.find(' - ') > 0:\n",
    "                version_complete = version_complete[:version_complete.find('-')]\n",
    "            if modele !=\"2008\":\n",
    "                version_complete = re.sub(r\"\\b20\\d{2}\\b\", \"\",  version_complete)\n",
    "            version_complete = version_complete.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Erreur lors de la récupération marque/modèle/version:\", e)\n",
    "\n",
    "        # Enregistrement pour l'excel \n",
    "        \n",
    "        infos[car_nbr][\"lien\"] = link\n",
    "        infos[car_nbr]['SoH'] = score_sante\n",
    "        infos[car_nbr]['Année'] = annee\n",
    "        infos[car_nbr]['Odomètre (km)'] = kilometrage\n",
    "        infos[car_nbr]['Type'] = version_complete\n",
    "        infos[car_nbr]['Modèle'] = modele\n",
    "        infos[car_nbr]['OEM'] = marque\n",
    "\n",
    "        car_nbr +=1\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(infos).T.dropna(subset='SoH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(infos).T[[\"OEM\",\"Modèle\",\"Type\",\"Année\",\"Odomètre (km)\",\"SoH\"]].dropna(subset='SoH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapping.scrapping_autospherre import export_to_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.insights_results.trendlines_excel import get_gspread_client\n",
    "def export_to_excel(df_to_write, gsheet):\n",
    "    client = get_gspread_client()\n",
    "    sheet_out = client.open(\"202505 - Courbes SoH\")\n",
    "    worksheet = sheet_out.worksheet(gsheet)\n",
    "    worksheet.append_rows(df_to_write.values.tolist())\n",
    "    print(f\"Données écritent dans {gsheet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({1: {'lien': 'https://www.autosphere.fr/fiche/auto-occasion-dacia-spring-45ch-business-2020-achat-integral-62000-arras-450331',\n",
    "  'SoH': None,\n",
    "  'Année': '2020',\n",
    "  'Odomètre (km)': '31764',\n",
    "  'Type': '45ch Business',\n",
    "  'Modèle': 'Spring',\n",
    "  'Marque': 'Dacia',\n",
    "  'Version complète': '45ch Business'},}).T[[\"OEM\",\"Modèle\",\"Type\",\"Année\",\"Odomètre (km)\",\"SoH\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_excel(df, 'Courbes OS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

