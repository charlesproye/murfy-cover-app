{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Delay to get the first SoH\n",
    "We want to know how much time we have to wait before getting a SoH for a vin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.s3.s3_utils import S3Service\n",
    "from core.s3.settings import S3Settings\n",
    "from core.spark_utils import create_spark_session\n",
    "import plotly.express as px\n",
    "from core.stats_utils import *\n",
    "from core.sql_utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "settings = S3Settings()\n",
    "\n",
    "spark = create_spark_session(\n",
    "    settings.S3_KEY,\n",
    "    settings.S3_SECRET\n",
    ")\n",
    "\n",
    "s3 = S3Service()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_renault = s3.read_parquet_df_spark(spark, \"result_phases/result_phases_renault.parquet\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_renault.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from core.sql_utils import *\n",
    "with get_connection() as con:\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(\"\"\"SELECT v.vin as VIN, m.make_name as MAKE, vm.model_name as MODEL, vd.soh as SOH_prod, vd.timestamp  FROM vehicle_data vd \n",
    "                   left JOIN vehicle v on v.id = vd.vehicle_id\n",
    "                    left JOIN vehicle_model vm\n",
    "                    ON v.vehicle_model_id = vm.id\n",
    "                    left JOIN make m on m.id = vm.make_id\n",
    "                    Where vd.soh < 1.2\"\"\")\n",
    "    dbeaver_df = cursor.fetchall()\n",
    "dbeaver_df = pd.DataFrame(dbeaver_df, columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## delay evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Renault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vin = phase_renault[phase_renault['VIN'] == 'VF1AG000964802627']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vin = pd.merge_asof(vin.sort_values('DATETIME_BEGIN'),\n",
    "                    dbeaver_df[['timestamp', 'soh_prod', 'vin']].sort_values('timestamp'), \n",
    "                    right_on='timestamp',\n",
    "                    left_on='DATETIME_BEGIN',\n",
    "                    left_by='VIN',\n",
    "                    right_by='vin',\n",
    "                    direction='forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Filtres temporels\n",
    "\n",
    "Création de différents filtres pour analyser l'évolution dans le temps depuis la première date de suivi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Identifier la première date de suivi\n",
    "first_date = vin['DATETIME_BEGIN'].min()\n",
    "\n",
    "# Créer les différents filtres temporels\n",
    "filters = {\n",
    "    '1_jour': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(days=1)],\n",
    "    '1_semaine': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(weeks=1)],\n",
    "    '2_semaines': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(weeks=2)],\n",
    "    '3_semaines': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(weeks=3)],\n",
    "    '4_semaines': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(weeks=4)],\n",
    "    '5_semaines': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(weeks=5)],\n",
    "    '6_semaines': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(weeks=6)],\n",
    "    '7_semaines': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(weeks=7)],\n",
    "    '8_semaines': vin[vin['DATETIME_BEGIN'] <= first_date + pd.Timedelta(weeks=8)],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Option alternative : Filtres par période spécifique (non cumulatifs)\n",
    "\n",
    "Si vous voulez uniquement les données d'une période spécifique (par exemple seulement la 2ème semaine), utilisez ce code :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.stats_utils import (\n",
    "    mask_out_outliers_by_interquartile_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soh_presentable_per_vehicle( df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df[\"SOH\"].count() > 3:\n",
    "        outliser_mask = mask_out_outliers_by_interquartile_range(df[\"SOH\"])\n",
    "        assert outliser_mask.any(), (\n",
    "            f\"There seems to be only outliers???:\\n{df['SOH']}.\"\n",
    "        )\n",
    "        df = df[outliser_mask].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtres non cumulatifs : uniquement les données de chaque période spécifique\n",
    "filters_specific = {\n",
    "    '1_jour': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(days=1))\n",
    "    ],\n",
    "    'semaine_1': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(weeks=1))\n",
    "    ],\n",
    "    'semaine_2': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date + pd.Timedelta(weeks=1)) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(weeks=2))\n",
    "    ],\n",
    "    'semaine_3': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date + pd.Timedelta(weeks=2)) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(weeks=3))\n",
    "    ],\n",
    "    'semaine_4': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date + pd.Timedelta(weeks=3)) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(weeks=4))\n",
    "    ],\n",
    "    'semaine_5': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date + pd.Timedelta(weeks=4)) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(weeks=5))\n",
    "    ],\n",
    "    'semaine_6': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date + pd.Timedelta(weeks=5)) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(weeks=6))\n",
    "    ],\n",
    "    'semaine_7': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date + pd.Timedelta(weeks=6)) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(weeks=7))\n",
    "    ],\n",
    "    'semaine_8': vin[\n",
    "        (vin['DATETIME_BEGIN'] >= first_date + pd.Timedelta(weeks=7)) & \n",
    "        (vin['DATETIME_BEGIN'] < first_date + pd.Timedelta(weeks=8))\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Afficher le nombre de lignes par période spécifique\n",
    "print(f\"\\nNombre de lignes par période spécifique (non cumulatif) :\")\n",
    "for period, df in filters_specific.items():\n",
    "    print(f\"  {period:15s}: {len(df):5d} lignes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Visualisation de l'évolution du nombre de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordre des périodes\n",
    "periods_order = [\n",
    "    '1_jour', '1_semaine', '2_semaines', '3_semaines', '4_semaines',\n",
    "    '5_semaines', '6_semaines', '7_semaines', '8_semaines'\n",
    "]\n",
    "\n",
    "# Création du DataFrame d'évolution\n",
    "evolution_data = pd.DataFrame({\n",
    "    'Période': periods_order,\n",
    "    'SoH median': [make_soh_presentable_per_vehicle(filters[p])['SOH'].median() for p in periods_order],\n",
    "    'SoH prod': [filters[p].soh_prod.min() for p in periods_order],\n",
    "    'Jours': [1, 7, 14, 21, 28, 35, 42, 49, 56]\n",
    "})\n",
    "\n",
    "# Graphique principal\n",
    "fig = px.scatter(\n",
    "    evolution_data,\n",
    "    x='Jours',\n",
    "    y='SoH median',\n",
    "    title='Évolution du SoH médian depuis le début du suivi',\n",
    "    labels={'Jours': 'Jours depuis le début du suivi', 'SoH median': 'SoH médian'}\n",
    ")\n",
    "\n",
    "# Ajout d'une deuxième trace (SoH production médian)\n",
    "fig.add_scatter(\n",
    "    x=evolution_data['Jours'],\n",
    "    y=evolution_data['SoH prod'],\n",
    "    mode='lines+markers',\n",
    "    name='SoH prod'\n",
    ")\n",
    "\n",
    "# Mise en forme\n",
    "fig.update_traces(marker=dict(size=10), line=dict(width=3))\n",
    "fig.update_layout(template='plotly_white', hovermode='x unified')\n",
    "\n",
    "# Affichage\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des statistiques pour chaque tranche temporelle\n",
    "stats_per_period = []\n",
    "\n",
    "for period, df in filters_specific.items():\n",
    "    if len(df) > 0 and 'SOH' in df.columns:\n",
    "        # Filtrage des outliers\n",
    "        df_clean = make_soh_presentable_per_vehicle(df) if df[\"SOH\"].count() > 3 else df\n",
    "        df_val = df_clean.copy()\n",
    "        df_val['SOH'] = df_val['SOH'] * 100\n",
    "        df_val['soh_prod'] = df_val['soh_prod'] * 100\n",
    "        stats = {\n",
    "            'Période': period,\n",
    "            'Nombre de données': len(df),\n",
    "            'Moyenne': df_val['SOH'].mean(),\n",
    "            'Médiane': df_val['SOH'].median(),\n",
    "            'Variance': df_val['SOH'].var(),\n",
    "            'Écart-type': df_val['SOH'].std(),\n",
    "            'Min': df_val['SOH'].min(),\n",
    "            'Max': df_val['SOH'].max(),\n",
    "            'soh_prod': df_val['soh_prod'].min() if 'soh_prod' in df_val.columns else None\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            'Période': period,\n",
    "            'Nombre de données': 0,\n",
    "            'Moyenne': None,\n",
    "            'Médiane': None,\n",
    "            'Variance': None,\n",
    "            'Écart-type': None,\n",
    "            'Min': None,\n",
    "            'Max': None,\n",
    "        }\n",
    "    stats_per_period.append(stats)\n",
    "\n",
    "# Création du DataFrame des statistiques\n",
    "df_stats = pd.DataFrame(stats_per_period)\n",
    "\n",
    "# Tri selon l'ordre des périodes\n",
    "period_order = ['1_jour', 'semaine_1', 'semaine_2', 'semaine_3', 'semaine_4', \n",
    "                'semaine_5', 'semaine_6', 'semaine_7', 'semaine_8']\n",
    "df_stats['Période'] = pd.Categorical(df_stats['Période'], categories=period_order, ordered=True)\n",
    "df_stats = df_stats.sort_values('Période')\n",
    "\n",
    "display(df_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'évolution des statistiques par tranche temporelle\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Préparation des données pour le graphique\n",
    "df_stats_clean = df_stats.dropna()  # Retirer les périodes sans données\n",
    "\n",
    "# Création d'un mapping de période vers jours\n",
    "period_to_days = {\n",
    "    '1_jour': 1,\n",
    "    'semaine_1': 7,\n",
    "    'semaine_2': 14,\n",
    "    'semaine_3': 21,\n",
    "    'semaine_4': 28,\n",
    "    'semaine_5': 35,\n",
    "    'semaine_6': 42,\n",
    "    'semaine_7': 49,\n",
    "    'semaine_8': 56\n",
    "}\n",
    "\n",
    "df_stats_clean['Jours'] = df_stats_clean['Période'].map(period_to_days)\n",
    "\n",
    "# Création du graphique\n",
    "fig = go.Figure()\n",
    "\n",
    "# Zone d'incertitude (min-max)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_stats_clean['Jours'],\n",
    "    y=df_stats_clean['Max'],\n",
    "    mode='lines',\n",
    "    line=dict(width=0),\n",
    "    showlegend=False,\n",
    "    hovertemplate='Max: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_stats_clean['Jours'],\n",
    "    y=df_stats_clean['Min'],\n",
    "    mode='lines',\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(68, 68, 68, 0.2)',\n",
    "    fill='tonexty',\n",
    "    name='Intervalle Min-Max',\n",
    "    hovertemplate='Min: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Moyenne\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_stats_clean['Jours'],\n",
    "    y=df_stats_clean['Moyenne'],\n",
    "    mode='lines+markers',\n",
    "    name='Moyenne',\n",
    "    line=dict(color='blue', width=3),\n",
    "    marker=dict(size=10),\n",
    "    hovertemplate='Moyenne: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Médiane\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_stats_clean['Jours'],\n",
    "    y=df_stats_clean['Médiane'],\n",
    "    mode='lines+markers',\n",
    "    name='Médiane',\n",
    "    line=dict(color='red', width=3, dash='dash'),\n",
    "    marker=dict(size=10),\n",
    "    hovertemplate='Médiane: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_stats_clean['Jours'],\n",
    "    y=df_stats_clean['soh_prod'],\n",
    "    mode='lines+markers',\n",
    "    name='SoH Prod',\n",
    "    line=dict(color='green', width=3, dash='dash'),\n",
    "    marker=dict(size=10),\n",
    "    hovertemplate='SoH prod: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Mise en forme\n",
    "fig.update_layout(\n",
    "    title='Évolution des statistiques du SoH par tranche temporelle',\n",
    "    xaxis_title='Jours depuis le début du suivi',\n",
    "    yaxis_title='SoH (%)',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified',\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Analyse de la variance par tranche pour tous les VIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vehicles = pd.merge_asof(\n",
    "    phase_renault.sort_values('DATETIME_BEGIN'),\n",
    "    dbeaver_df[['timestamp', 'soh_prod', 'vin']].sort_values('timestamp'), \n",
    "    right_on='timestamp',\n",
    "    left_on='DATETIME_BEGIN',\n",
    "    left_by='VIN',\n",
    "    right_by='vin',\n",
    "    direction='forward'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_soh_stats_for_vehicle(vin_df):\n",
    "    \"\"\"\n",
    "    Calcule les statistiques du SoH pour un véhicule donné sur différentes périodes\n",
    "    depuis la première date de suivi.\n",
    "    \n",
    "    Args:\n",
    "        vin_df: DataFrame contenant les données d'un seul véhicule\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame avec les statistiques par période\n",
    "    \"\"\"\n",
    "    if len(vin_df) == 0 or 'SOH' not in vin_df.columns:\n",
    "        return None\n",
    "    \n",
    "    # Identifier la première date de suivi\n",
    "    first_date = vin_df['DATETIME_BEGIN'].min()\n",
    "    \n",
    "    # Définir les périodes à analyser (en jours)\n",
    "    periods = {\n",
    "        '1_jour': 1,\n",
    "        '1_semaine': 7,\n",
    "        '2_semaines': 14,\n",
    "        '3_semaines': 21,\n",
    "        '4_semaines': 28,\n",
    "        '5_semaines': 35,\n",
    "        '6_semaines': 42,\n",
    "        '7_semaines': 49,\n",
    "        '8_semaines': 56\n",
    "    }\n",
    "    \n",
    "    # Créer les filtres non cumulatifs\n",
    "    filters_specific = {}\n",
    "    prev_days = 0\n",
    "    for period_name, days in periods.items():\n",
    "        filters_specific[period_name] = vin_df[\n",
    "            (vin_df['DATETIME_BEGIN'] >= first_date + pd.Timedelta(days=prev_days)) & \n",
    "            (vin_df['DATETIME_BEGIN'] < first_date + pd.Timedelta(days=days))\n",
    "        ]\n",
    "        prev_days = days\n",
    "    \n",
    "    # Calculer les statistiques pour chaque période\n",
    "    stats_per_period = []\n",
    "    \n",
    "    for period, df in filters_specific.items():\n",
    "        if len(df) > 0:\n",
    "            # Filtrage des outliers si assez de données\n",
    "            df_clean = make_soh_presentable_per_vehicle(df) if df[\"SOH\"].count() > 3 else df\n",
    "            df_clean['SOH'] = df_clean['SOH'] * 100\n",
    "            if len(df_clean) > 0:\n",
    "                stats = {\n",
    "                    'Période': period,\n",
    "                    'Nombre de données': len(df),\n",
    "                    'Moyenne': df_clean['SOH'].mean(),\n",
    "                    'Médiane': df_clean['SOH'].median(),\n",
    "                    'Variance': df_clean['SOH'].var(),\n",
    "                    'Écart-type': df_clean['SOH'].std(),\n",
    "                    'Min': df_clean['SOH'].min(),\n",
    "                    'Max': df_clean['SOH'].max(),\n",
    "                    'SoH prod median': df['soh_prod'].median() if 'soh_prod' in df.columns else None\n",
    "                }\n",
    "            else:\n",
    "                stats = {\n",
    "                    'Période': period,\n",
    "                    'Nombre de données': len(df),\n",
    "                    'Moyenne': None,\n",
    "                    'Médiane': None,\n",
    "                    'Variance': None,\n",
    "                    'Écart-type': None,\n",
    "                    'Min': None,\n",
    "                    'Max': None,\n",
    "                    'SoH prod median': None\n",
    "                }\n",
    "        else:\n",
    "            stats = {\n",
    "                'Période': period,\n",
    "                'Nombre de données': 0,\n",
    "                'Moyenne': None,\n",
    "                'Médiane': None,\n",
    "                'Variance': None,\n",
    "                'Écart-type': None,\n",
    "                'Min': None,\n",
    "                'Max': None,\n",
    "                'SoH prod median': None\n",
    "            }\n",
    "        stats_per_period.append(stats)\n",
    "    \n",
    "    return pd.DataFrame(stats_per_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = []\n",
    "\n",
    "vins = all_vehicles['VIN'].unique()\n",
    "print(f\"Traitement de {len(vins)} véhicules...\")\n",
    "\n",
    "for i, vin in enumerate(vins):\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"Progression : {i+1}/{len(vins)} véhicules traités\")\n",
    "    \n",
    "    vin_df = all_vehicles[all_vehicles['VIN'] == vin]\n",
    "    stats_df = compute_soh_stats_for_vehicle(vin_df)\n",
    "    \n",
    "    if stats_df is not None:\n",
    "        stats_df['VIN'] = vin\n",
    "        all_stats.append(stats_df)\n",
    "\n",
    "# Concaténer tous les résultats\n",
    "all_stats_df = pd.concat(all_stats, ignore_index=True)\n",
    "all_stats_df_no_na = all_stats_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_df_no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "period_to_days = {\n",
    "    '1_jour': 1,\n",
    "    '1_semaine': 7,\n",
    "    '2_semaines': 14,\n",
    "    '3_semaines': 21,\n",
    "    '4_semaines': 28,\n",
    "    '5_semaines': 35,\n",
    "    '6_semaines': 42,\n",
    "    '7_semaines': 49,\n",
    "    '8_semaines': 56\n",
    "}\n",
    "\n",
    "\n",
    "all_stats_df_no_na['Jours'] = all_stats_df_no_na['Période'].map(period_to_days)\n",
    "\n",
    "\n",
    "period_order = ['1_jour', '1_semaine', '2_semaines', '3_semaines', '4_semaines', \n",
    "                '5_semaines', '6_semaines', '7_semaines', '8_semaines']\n",
    "all_stats_df_no_na['Période'] = pd.Categorical(all_stats_df_no_na['Période'], \n",
    "                                                 categories=period_order, ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques agrégées de la variance par période\n",
    "variance_stats = all_stats_df_no_na.groupby('Période').agg({\n",
    "    'Variance': ['mean', 'median', 'std', 'min', 'max', \n",
    "                 lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)],\n",
    "    'Écart-type': ['mean', 'median'],\n",
    "    'Nombre de données': 'sum',\n",
    "    'VIN': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Aplatir les colonnes\n",
    "variance_stats.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                          for col in variance_stats.columns.values]\n",
    "variance_stats = variance_stats.rename(columns={\n",
    "    'Variance_<lambda_0>': 'Variance_q25',\n",
    "    'Variance_<lambda_1>': 'Variance_q75'\n",
    "})\n",
    "\n",
    "variance_stats['Jours'] = variance_stats['Période'].map(period_to_days)\n",
    "\n",
    "\n",
    "variance_stats['Période'] = pd.Categorical(variance_stats['Période'], \n",
    "                                            categories=period_order, ordered=True)\n",
    "variance_stats = variance_stats.sort_values('Période')\n",
    "\n",
    "\n",
    "variance_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'évolution de la variance avec intervalles de confiance\n",
    "fig = go.Figure()\n",
    "\n",
    "# Zone d'incertitude (Q25 - Q75)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_q75'],\n",
    "    mode='lines',\n",
    "    line=dict(width=0),\n",
    "    showlegend=False,\n",
    "    hovertemplate='Q75: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_q25'],\n",
    "    mode='lines',\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255, 0, 0, 0.2)',\n",
    "    fill='tonexty',\n",
    "    name='Intervalle interquartile',\n",
    "    hovertemplate='Q25: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Zone d'incertitude (Moyenne ± 1 écart-type)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_mean'] + variance_stats['Variance_std'],\n",
    "    mode='lines',\n",
    "    line=dict(width=0),\n",
    "    showlegend=False,\n",
    "    hovertemplate='Moyenne + 1σ: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_mean'] - variance_stats['Variance_std'],\n",
    "    mode='lines',\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(0, 0, 255, 0.15)',\n",
    "    fill='tonexty',\n",
    "    name='Moyenne ± 1 écart-type',\n",
    "    hovertemplate='Moyenne - 1σ: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Moyenne de la variance\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_mean'],\n",
    "    mode='lines+markers',\n",
    "    name='Moyenne de la variance',\n",
    "    line=dict(color='blue', width=4),\n",
    "    marker=dict(size=12),\n",
    "    hovertemplate='Moyenne<br>Jours: %{x}<br>Variance: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Médiane de la variance\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_median'],\n",
    "    mode='lines+markers',\n",
    "    name='Médiane de la variance',\n",
    "    line=dict(color='red', width=4, dash='dash'),\n",
    "    marker=dict(size=12),\n",
    "    hovertemplate='Médiane<br>Jours: %{x}<br>Variance: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Min et Max\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_max'],\n",
    "    mode='markers',\n",
    "    name='Maximum',\n",
    "    marker=dict(symbol='triangle-up', size=8, color='orange'),\n",
    "    hovertemplate='Max: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_min'],\n",
    "    mode='markers',\n",
    "    name='Minimum',\n",
    "    marker=dict(symbol='triangle-down', size=8, color='green'),\n",
    "    hovertemplate='Min: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Évolution de la variance du SoH par période (tous les VINs)',\n",
    "    xaxis_title='Jours depuis le début du suivi',\n",
    "    yaxis_title='Variance du SoH',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified',\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    ),\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Identification de la période la plus performante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier la période avec la variance moyenne la plus faible (plus performante)\n",
    "\n",
    "best_period_by_median_variance = variance_stats.loc[variance_stats['Variance_median'].idxmin()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "colors_bar = ['green' if p == best_period_by_median_variance['Période'] else 'lightblue' \n",
    "              for p in variance_stats['Période']]\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=variance_stats['Période'],\n",
    "    y=variance_stats['Variance_median'],\n",
    "    name='Variance moyenne',\n",
    "    marker=dict(color=colors_bar),\n",
    "    hovertemplate='Période: %{x}<br>Variance médiane: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Ligne de référence pour la variance moyenne minimale\n",
    "fig.add_hline(\n",
    "    y=variance_stats['Variance_median'].mean(),\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"green\",\n",
    "    annotation_text=f\"Mean: {variance_stats['Variance_median'].mean():.2f}\",\n",
    "    annotation_position=\"right\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Variance par période ',\n",
    "    xaxis_title='Période',\n",
    "    yaxis_title='Variance',\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de l'écart-type (plus interprétable que la variance)\n",
    "ecart_type_stats = all_stats_df_no_na.groupby('Période').agg({\n",
    "    'Écart-type': ['mean', 'median', 'std', 'min', 'max'],\n",
    "    'Variance': ['mean', 'median'],\n",
    "    'VIN': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "ecart_type_stats.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                            for col in ecart_type_stats.columns.values]\n",
    "ecart_type_stats['Jours'] = ecart_type_stats['Période'].map(period_to_days)\n",
    "ecart_type_stats['Période'] = pd.Categorical(ecart_type_stats['Période'], \n",
    "                                               categories=period_order, ordered=True)\n",
    "ecart_type_stats = ecart_type_stats.sort_values('Période')\n",
    "\n",
    "# Identifier la période avec l'écart-type moyen le plus faible\n",
    "best_period_by_std = ecart_type_stats.loc[ecart_type_stats['Variance_mean'].idxmin()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'évolution de l'écart-type avec mise en évidence de la meilleure période\n",
    "fig = go.Figure()\n",
    "\n",
    "colors_bar = ['green' if p == best_period_by_std['Période'] else 'lightblue' \n",
    "              for p in ecart_type_stats['Période']]\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=ecart_type_stats['Période'],\n",
    "    y=ecart_type_stats['Écart-type_mean'],\n",
    "    name='Écart-type mean',\n",
    "    marker=dict(color=colors_bar),\n",
    "    hovertemplate='Période: %{x}<br>Écart-type mean: %{y:.2f}%<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=ecart_type_stats['Période'],\n",
    "    y=ecart_type_stats['Écart-type_median'],\n",
    "    mode='lines+markers',\n",
    "    name='Écart-type médian',\n",
    "    line=dict(color='orange', width=3),\n",
    "    marker=dict(size=10),\n",
    "    hovertemplate='Période: %{x}<br>Écart-type médian: %{y:.2f}%<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.add_hline(\n",
    "    y=ecart_type_stats['Écart-type_median'].min(),\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"Mean: {ecart_type_stats['Écart-type_median'].mean():.2f}%\",\n",
    "    annotation_position=\"right\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Écart-type par période',\n",
    "    xaxis_title='Période',\n",
    "    yaxis_title='Écart-type (%)',\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé final de la performance par période\n",
    "\n",
    "\n",
    "# Créer un tableau récapitulatif\n",
    "summary_performance = variance_stats[['Période', 'Jours', 'Variance_mean', 'Variance_median', \n",
    "                                     'Écart-type_mean', 'VIN_nunique']].copy()\n",
    "summary_performance['Rang_variance_moyenne'] = summary_performance['Variance_mean'].rank()\n",
    "summary_performance['Rang_ecart_type'] = summary_performance['Écart-type_mean'].rank()\n",
    "summary_performance = summary_performance.sort_values('Rang_variance_moyenne')\n",
    "\n",
    "display(summary_performance.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Analyse des causes de la variance élevée observée sur certains véhicules spécifiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 1. Identification des véhicules avec variance élevée\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier les véhicules avec variance élevée par période\n",
    "# On se concentre sur les périodes de 4 semaines et plus où on devrait avoir une bonne précision\n",
    "periods_to_analyze = ['4_semaines', '5_semaines', '6_semaines', '7_semaines', '8_semaines']\n",
    "\n",
    "# Filtrer les données pour ces périodes\n",
    "high_variance_df = all_stats_df_no_na[\n",
    "    all_stats_df_no_na['Période'].isin(periods_to_analyze)\n",
    "].copy()\n",
    "\n",
    "# Calculer la variance moyenne par véhicule sur ces périodes\n",
    "vin_variance_stats = high_variance_df.groupby('VIN').agg({\n",
    "    'Variance': ['mean', 'max', 'std'],\n",
    "    'Écart-type': ['mean', 'max'],\n",
    "    'Nombre de données': 'sum',\n",
    "    'Moyenne': 'mean',\n",
    "    'Médiane': 'mean',\n",
    "    'Min': 'min',\n",
    "    'Max': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# Aplatir les colonnes\n",
    "vin_variance_stats.columns = ['_'.join(col).strip('_') if col[1] else col[0] \n",
    "                              for col in vin_variance_stats.columns.values]\n",
    "\n",
    "# Définir un seuil pour variance élevée (75e percentile)\n",
    "variance_threshold = vin_variance_stats['Variance_mean'].quantile(0.75)\n",
    "std_threshold = vin_variance_stats['Écart-type_mean'].quantile(0.75)\n",
    "\n",
    "print(f\"Seuil de variance moyenne (75e percentile): {variance_threshold:.2f}\")\n",
    "print(f\"Seuil d'écart-type moyen (75e percentile): {std_threshold:.2f}\")\n",
    "print(f\"\\nNombre de véhicules avec variance élevée: {(vin_variance_stats['Variance_mean'] > variance_threshold).sum()}\")\n",
    "print(f\"Nombre de véhicules avec écart-type élevé: {(vin_variance_stats['Écart-type_mean'] > std_threshold).sum()}\")\n",
    "\n",
    "# Identifier les véhicules avec variance élevée\n",
    "high_variance_vins = vin_variance_stats[\n",
    "    (vin_variance_stats['Variance_mean'] > variance_threshold) |\n",
    "    (vin_variance_stats['Écart-type_mean'] > std_threshold)\n",
    "].sort_values('Variance_mean', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 véhicules avec la variance la plus élevée:\")\n",
    "display(high_variance_vins.head(10)[['VIN', 'Variance_mean', 'Écart-type_mean', 'Nombre de données_sum', 'Moyenne_mean', 'Médiane_mean']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### 2. Analyse des caractéristiques des véhicules avec variance élevée\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les caractéristiques des véhicules avec variance élevée vs normale\n",
    "normal_variance_vins = vin_variance_stats[\n",
    "    (vin_variance_stats['Variance_mean'] <= variance_threshold) &\n",
    "    (vin_variance_stats['Écart-type_mean'] <= std_threshold)\n",
    "]\n",
    "\n",
    "comparison_stats = pd.DataFrame({\n",
    "    'Métrique': [\n",
    "        'Nombre de véhicules',\n",
    "        'Variance moyenne',\n",
    "        'Écart-type moyen',\n",
    "        'Nombre total de données',\n",
    "        'Nombre moyen de données par période',\n",
    "        'Amplitude SoH (Max - Min)',\n",
    "        'Écart Moyenne-Médiane'\n",
    "    ],\n",
    "    'Variance élevée': [\n",
    "        len(high_variance_vins),\n",
    "        high_variance_vins['Variance_mean'].mean(),\n",
    "        high_variance_vins['Écart-type_mean'].mean(),\n",
    "        high_variance_vins['Nombre de données_sum'].mean(),\n",
    "        high_variance_vins['Nombre de données_sum'].mean() / len(periods_to_analyze),\n",
    "        (high_variance_vins['Max_max'] - high_variance_vins['Min_min']).mean(),\n",
    "        (high_variance_vins['Moyenne_mean'] - high_variance_vins['Médiane_mean']).abs().mean()\n",
    "    ],\n",
    "    'Variance normale': [\n",
    "        len(normal_variance_vins),\n",
    "        normal_variance_vins['Variance_mean'].mean(),\n",
    "        normal_variance_vins['Écart-type_mean'].mean(),\n",
    "        normal_variance_vins['Nombre de données_sum'].mean(),\n",
    "        normal_variance_vins['Nombre de données_sum'].mean() / len(periods_to_analyze),\n",
    "        (normal_variance_vins['Max_max'] - normal_variance_vins['Min_min']).mean(),\n",
    "        (normal_variance_vins['Moyenne_mean'] - normal_variance_vins['Médiane_mean']).abs().mean()\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_stats['Ratio'] = comparison_stats['Variance élevée'] / comparison_stats['Variance normale']\n",
    "display(comparison_stats.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative : Variance vs Nombre de données\n",
    "fig = go.Figure()\n",
    "\n",
    "# Véhicules avec variance normale\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=normal_variance_vins['Nombre de données_sum'],\n",
    "    y=normal_variance_vins['Variance_mean'],\n",
    "    mode='markers',\n",
    "    name='Variance normale',\n",
    "    marker=dict(color='blue', size=8, opacity=0.6),\n",
    "    hovertemplate='VIN: %{text}<br>Données: %{x}<br>Variance: %{y:.2f}<extra></extra>',\n",
    "    text=normal_variance_vins['VIN']\n",
    "))\n",
    "\n",
    "# Véhicules avec variance élevée\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=high_variance_vins['Nombre de données_sum'],\n",
    "    y=high_variance_vins['Variance_mean'],\n",
    "    mode='markers',\n",
    "    name='Variance élevée',\n",
    "    marker=dict(color='red', size=10, opacity=0.8),\n",
    "    hovertemplate='VIN: %{text}<br>Données: %{x}<br>Variance: %{y:.2f}<extra></extra>',\n",
    "    text=high_variance_vins['VIN']\n",
    "))\n",
    "\n",
    "# Ligne de seuil\n",
    "fig.add_hline(\n",
    "    y=variance_threshold,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"orange\",\n",
    "    annotation_text=f\"Seuil (75e percentile): {variance_threshold:.2f}\",\n",
    "    annotation_position=\"right\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Relation entre nombre de données et variance du SoH',\n",
    "    xaxis_title='Nombre total de données (4-8 semaines)',\n",
    "    yaxis_title='Variance moyenne du SoH',\n",
    "    template='plotly_white',\n",
    "    hovermode='closest',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### 3. Analyse temporelle détaillée pour les véhicules problématiques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser l'évolution de la variance dans le temps pour les véhicules problématiques\n",
    "top_problematic_vins = high_variance_vins.head(5)['VIN'].tolist()\n",
    "\n",
    "print(f\"Analyse détaillée des {len(top_problematic_vins)} véhicules les plus problématiques:\\n\")\n",
    "\n",
    "for vin in top_problematic_vins:\n",
    "    vin_stats = all_stats_df_no_na[all_stats_df_no_na['VIN'] == vin].copy()\n",
    "    vin_stats = vin_stats.sort_values('Période')\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"VIN: {vin}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Variance moyenne: {vin_stats['Variance'].mean():.2f}\")\n",
    "    print(f\"Écart-type moyen: {vin_stats['Écart-type'].mean():.2f}\")\n",
    "    print(f\"Nombre total de données: {vin_stats['Nombre de données'].sum()}\")\n",
    "    print(f\"\\nÉvolution par période:\")\n",
    "    display(vin_stats[['Période', 'Nombre de données', 'Variance', 'Écart-type', 'Moyenne', 'Médiane', 'Min', 'Max']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'évolution temporelle pour les véhicules problématiques\n",
    "fig = go.Figure()\n",
    "\n",
    "for vin in top_problematic_vins:\n",
    "    vin_stats = all_stats_df_no_na[all_stats_df_no_na['VIN'] == vin].copy()\n",
    "    vin_stats = vin_stats.sort_values('Jours')\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=vin_stats['Jours'],\n",
    "        y=vin_stats['Variance'],\n",
    "        mode='lines+markers',\n",
    "        name=f'VIN: {vin[:8]}...',\n",
    "        hovertemplate=f'VIN: {vin}<br>Jours: %{{x}}<br>Variance: %{{y:.2f}}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "# Ligne de référence (variance moyenne globale)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=variance_stats['Jours'],\n",
    "    y=variance_stats['Variance_mean'],\n",
    "    mode='lines',\n",
    "    name='Variance moyenne (tous véhicules)',\n",
    "    line=dict(color='black', width=3, dash='dash'),\n",
    "    hovertemplate='Moyenne globale<br>Jours: %{x}<br>Variance: %{y:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Évolution de la variance dans le temps - Véhicules problématiques',\n",
    "    xaxis_title='Jours depuis le début du suivi',\n",
    "    yaxis_title='Variance du SoH',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified',\n",
    "    height=600,\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### 4. Analyse des données brutes pour comprendre les causes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les données brutes pour quelques véhicules problématiques\n",
    "def analyze_vehicle_raw_data(vin_code, all_vehicles_df):\n",
    "    \"\"\"Analyse les données brutes d'un véhicule pour identifier les causes de variance élevée\"\"\"\n",
    "    vin_data = all_vehicles_df[all_vehicles_df['VIN'] == vin_code].copy()\n",
    "    vin_data = vin_data.sort_values('DATETIME_BEGIN')\n",
    "    \n",
    "    # Convertir SoH en pourcentage\n",
    "    vin_data['SOH_pct'] = vin_data['SOH'] * 100\n",
    "    \n",
    "    # Calculer les statistiques\n",
    "    analysis = {\n",
    "        'VIN': vin_code,\n",
    "        'Nombre total de phases': len(vin_data),\n",
    "        'Période de suivi (jours)': (vin_data['DATETIME_BEGIN'].max() - vin_data['DATETIME_BEGIN'].min()).days,\n",
    "        'Variance SoH': vin_data['SOH_pct'].var(),\n",
    "        'Écart-type SoH': vin_data['SOH_pct'].std(),\n",
    "        'Moyenne SoH': vin_data['SOH_pct'].mean(),\n",
    "        'Médiane SoH': vin_data['SOH_pct'].median(),\n",
    "        'Min SoH': vin_data['SOH_pct'].min(),\n",
    "        'Max SoH': vin_data['SOH_pct'].max(),\n",
    "        'Amplitude SoH': vin_data['SOH_pct'].max() - vin_data['SOH_pct'].min(),\n",
    "        'Écart Moyenne-Médiane': abs(vin_data['SOH_pct'].mean() - vin_data['SOH_pct'].median()),\n",
    "        'Nombre de valeurs uniques SoH': vin_data['SOH_pct'].nunique(),\n",
    "        'Pourcentage de données manquantes SoH': (vin_data['SOH'].isna().sum() / len(vin_data)) * 100\n",
    "    }\n",
    "    \n",
    "    # Analyser la distribution\n",
    "    q25, q75 = vin_data['SOH_pct'].quantile([0.25, 0.75])\n",
    "    analysis['IQR'] = q75 - q25\n",
    "    \n",
    "    # Identifier les outliers (méthode IQR)\n",
    "    outliers = vin_data[(vin_data['SOH_pct'] < q25 - 1.5 * analysis['IQR']) | \n",
    "                        (vin_data['SOH_pct'] > q75 + 1.5 * analysis['IQR'])]\n",
    "    analysis['Nombre outliers (IQR)'] = len(outliers)\n",
    "    analysis['Pourcentage outliers'] = (len(outliers) / len(vin_data)) * 100\n",
    "    \n",
    "    # Analyser les patterns temporels\n",
    "    vin_data['jours_since_start'] = (vin_data['DATETIME_BEGIN'] - vin_data['DATETIME_BEGIN'].min()).dt.days\n",
    "    \n",
    "    # Variance dans les premières semaines vs dernières semaines\n",
    "    first_4_weeks = vin_data[vin_data['jours_since_start'] < 28]\n",
    "    after_4_weeks = vin_data[vin_data['jours_since_start'] >= 28]\n",
    "    \n",
    "    if len(first_4_weeks) > 0:\n",
    "        analysis['Variance semaines 1-4'] = first_4_weeks['SOH_pct'].var()\n",
    "        analysis['Écart-type semaines 1-4'] = first_4_weeks['SOH_pct'].std()\n",
    "    \n",
    "    if len(after_4_weeks) > 0:\n",
    "        analysis['Variance après 4 semaines'] = after_4_weeks['SOH_pct'].var()\n",
    "        analysis['Écart-type après 4 semaines'] = after_4_weeks['SOH_pct'].std()\n",
    "    \n",
    "    return analysis, vin_data\n",
    "\n",
    "# Analyser les véhicules problématiques\n",
    "problematic_analyses = []\n",
    "for vin in top_problematic_vins:\n",
    "    analysis, _ = analyze_vehicle_raw_data(vin, all_vehicles)\n",
    "    problematic_analyses.append(analysis)\n",
    "\n",
    "analysis_df = pd.DataFrame(problematic_analyses)\n",
    "display(analysis_df.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des données brutes pour un véhicule problématique représentatif\n",
    "vin_to_plot = top_problematic_vins[0]\n",
    "_, vin_raw_data = analyze_vehicle_raw_data(vin_to_plot, all_vehicles)\n",
    "\n",
    "# Créer un graphique avec plusieurs sous-graphiques\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        f'Évolution du SoH dans le temps (VIN: {vin_to_plot[:8]}...)',\n",
    "        'Distribution du SoH',\n",
    "        'Variance mobile (fenêtre 7 jours)',\n",
    "        'Évolution de l\\'écart-type mobile'\n",
    "    ),\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Graphique 1: Évolution temporelle\n",
    "vin_raw_data['jours_since_start'] = (vin_raw_data['DATETIME_BEGIN'] - vin_raw_data['DATETIME_BEGIN'].min()).dt.days\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=vin_raw_data[[\"SOH_pct\", \"jours_since_start\"]].dropna()['jours_since_start'],\n",
    "        y=vin_raw_data[[\"SOH_pct\", \"jours_since_start\"]].dropna()['SOH_pct'],\n",
    "        mode='markers',\n",
    "        name='SoH',\n",
    "        marker=dict(size=4, opacity=0.6),\n",
    "        hovertemplate='Jour: %{x}<br>SoH: %{y:.2f}%<extra></extra>'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Ajouter une ligne de tendance\n",
    "from scipy import stats\n",
    "z = np.polyfit(vin_raw_data[[\"SOH_pct\", \"jours_since_start\"]].dropna()['jours_since_start'].dropna(), vin_raw_data[[\"SOH_pct\", \"jours_since_start\"]].dropna()['SOH_pct'].dropna(), 1)\n",
    "p = np.poly1d(z)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=vin_raw_data['jours_since_start'],\n",
    "        y=p(vin_raw_data['jours_since_start']),\n",
    "        mode='lines',\n",
    "        name='Tendance',\n",
    "        line=dict(color='red', width=2, dash='dash')\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Graphique 2: Distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=vin_raw_data['SOH_pct'],\n",
    "        nbinsx=30,\n",
    "        name='Distribution SoH',\n",
    "        marker_color='lightblue'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Ajouter lignes de moyenne et médiane\n",
    "mean_soh = vin_raw_data['SOH_pct'].mean()\n",
    "median_soh = vin_raw_data['SOH_pct'].median()\n",
    "fig.add_vline(x=mean_soh, line_dash=\"dash\", line_color=\"blue\", \n",
    "              annotation_text=f\"Moyenne: {mean_soh:.2f}\", row=1, col=2)\n",
    "fig.add_vline(x=median_soh, line_dash=\"dash\", line_color=\"red\", \n",
    "              annotation_text=f\"Médiane: {median_soh:.2f}\", row=1, col=2)\n",
    "\n",
    "# Graphique 3: Variance mobile\n",
    "window_size = 7\n",
    "vin_raw_data_sorted = vin_raw_data.sort_values('jours_since_start')\n",
    "rolling_var = vin_raw_data_sorted['SOH_pct'].rolling(window=window_size, min_periods=1).var()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=vin_raw_data_sorted['jours_since_start'],\n",
    "        y=rolling_var,\n",
    "        mode='lines',\n",
    "        name='Variance mobile',\n",
    "        line=dict(color='orange', width=2)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Graphique 4: Écart-type mobile\n",
    "rolling_std = vin_raw_data_sorted['SOH_pct'].rolling(window=window_size, min_periods=1).std()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=vin_raw_data_sorted['jours_since_start'],\n",
    "        y=rolling_std,\n",
    "        mode='lines',\n",
    "        name='Écart-type mobile',\n",
    "        line=dict(color='green', width=2)\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Mise à jour des axes\n",
    "fig.update_xaxes(title_text=\"Jours depuis le début\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"SoH (%)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"SoH (%)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Fréquence\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Jours depuis le début\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Variance\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Jours depuis le début\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Écart-type\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Analyse détaillée - Véhicule avec variance élevée (VIN: {vin_to_plot})',\n",
    "    template='plotly_white',\n",
    "    height=900,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### 6. Synthèse et hypothèses sur les causes de variance élevée\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- Une grande variabilité entre les différents véhicules, avec des patterns individuels significatifs\n",
    "\n",
    "**2. Période la plus performante**\n",
    "\n",
    "L'identification de la période optimale pour les estimations de SoH dépend de la métrique considérée :\n",
    "\n",
    "- **Variance médiane** : La période de **4 semaines** présente la variance médiane la plus faible, suggérant qu'une majorité de véhicules atteignent une bonne précision plus rapidement\n",
    "- **Variance moyenne** : La période de **6 semaines** présente la variance médiane la plus faible, suggérant qu'une majorité de véhicules atteignent une bonne précision plus rapidement\n",
    "\n",
    "L'analyse révèle que :\n",
    "- Avant 3 semaines la variance est très élevée, notamment due à un manque de données et à la phase d'initialisation du suivi\n",
    "- La période optimale semble être aux alentours de 4 semaines, où la variance est minimisée\n",
    "- L'écart-type moyen montre une tendance similaire, confirmant que la précision s'améliore avec le temps\n",
    "\n",
    "#### Recommandations\n",
    "\n",
    "**Pour la production :**\n",
    "\n",
    "1. **Délai minimum recommandé** : Attendre au minimum **3 semaines** de données avant d'utiliser les estimations de SoH afin d'obtenir une précision acceptable pour la majorité des véhicules\n",
    "\n",
    "2. **Suivi individuel** : L'analyse par VIN montre une grande hétérogénéité. Il est recommandé de surveiller individuellement les véhicules présentant une variance anormalement élevée, même après plusieurs semaines de suivim\n",
    "\n",
    "**NS :**\n",
    "\n",
    "- Faire la même hose pour d'autres marques\n",
    "- Investiguer les causes de la variance élevée observée sur certains véhicules spécifiques\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

