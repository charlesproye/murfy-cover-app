{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.s3_utils import *\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from transform.raw_tss.tesla_raw_tss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame as DF\n",
    "\n",
    "S3_RAW_TSS_KEY_FORMAT = \"raw_ts/{brand}/time_series/raw_tss.parquet\"\n",
    "TESLA_RAW_TSS_KEY = S3_RAW_TSS_KEY_FORMAT.format(brand=\"tesla\")\n",
    "DEFAULT_TESLA_RAW_TSS_DF = DF(columns=[\"vin\", \"readable_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3_Bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_response_keys_to_parse(bucket:S3_Bucket) -> DF:\n",
    "    return (\n",
    "        bucket.list_responses_keys_of_brand(\"tesla-fleet-telemetry\")\n",
    "        .assign(date=lambda df: df[\"file\"].str[:-5].astype(\"datetime64[ns]\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_key  = get_response_keys_to_parse(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'aplatissement\n",
    "def flatten_metrics(metrics_list):\n",
    "    if not isinstance(metrics_list, list):\n",
    "        return {}\n",
    "    flat = {}\n",
    "    for item in metrics_list:\n",
    "        key = item.get('key')\n",
    "        value_dict = item.get('value', {})\n",
    "        for subkey, subval in value_dict.items():\n",
    "            flat[f\"{key}_{subkey}\"] = subval\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_data(df):\n",
    "    df_merge = pd.DataFrame(index=df.index)\n",
    "    if \"metrics\" in df.columns:\n",
    "        metrics=pd.json_normalize(df['metrics'])\n",
    "        df_merge = pd.merge(df, metrics, left_index=True, right_index=True)\n",
    "    if \"data\" in df.columns:\n",
    "        data_df = df['data'].apply(flatten_metrics).apply(pd.Series)\n",
    "        df_merge = pd.merge(df_merge, data_df,  left_index=True, right_index=True)\n",
    "    else:\n",
    "        return df\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_key= pd.read_csv('pars_key.csv', index_col=0)\n",
    "parse_key['date'] = pd.to_datetime(parse_key['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.read_json_file(\"response/tesla-fleet-telemetry/LRWYGCFS6PC992837/2025-04-14.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss = get_raw_tss_from_keys(pd.DataFrame({'key':[\"response/tesla-fleet-telemetry/LRWYGCFS6PC992837/2025-04-14.json\"],\n",
    "              'dtype_folder': 'response',\n",
    "              'brand': 'esla-fleet-telemetry',\n",
    "              'vin': 'LRWYGCFS6PC992837',\n",
    "              'file': '2025-04-14.json',\n",
    "              'is_valid_file': True,\n",
    "              'date':pd.to_datetime('2025-04-14')}), s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_tss.config import *\n",
    "from transform.fleet_info.main import fleet_info\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from core.constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_n_discharging_masks_from_soc_diff(tss:DF) -> DF:\n",
    "        tss_grp = tss.groupby('vin', observed=True)\n",
    "        tss[\"soc_ffilled\"] = tss_grp[\"soc\"].ffill()\n",
    "        tss[\"soc_diff\"] = tss_grp[\"soc_ffilled\"].diff()\n",
    "        tss[\"soc_diff\"] /= tss[\"soc_diff\"].abs()\n",
    "        soc_diff_ffilled = tss_grp[\"soc_diff\"].ffill()\n",
    "        soc_diff_bfilled = tss_grp[\"soc_diff\"].bfill()\n",
    "        tss[\"in_charge\"] = soc_diff_ffilled.gt(0, fill_value=False) & soc_diff_bfilled.gt(0, fill_value=False)\n",
    "        tss[\"in_discharge\"] = soc_diff_ffilled.lt(0, fill_value=False) & soc_diff_bfilled.lt(0, fill_value=False)\n",
    "        return tss\n",
    "\n",
    "def charge_n_discharging_masks_from_charging_status(tss:DF, in_charge_vals:list, in_discharge_vals:list) -> DF:\n",
    "        assert \"charging_status\" in tss.columns, NO_CHARGING_STATUS_COL_ERROR\n",
    "        return (\n",
    "            tss\n",
    "            .eval(f\"in_charge = charging_status in {in_charge_vals}\")\n",
    "            .eval(f\"in_discharge = charging_status in {in_discharge_vals}\")\n",
    "        )\n",
    "def compute_charge_n_discharge_masks(tss:DF, make, in_charge_vals:list, in_discharge_vals:list) -> DF:\n",
    "    if make in CHARGE_MASK_WITH_CHARGING_STATUS_MAKES:\n",
    "        print(make)\n",
    "        return charge_n_discharging_masks_from_charging_status(tss, in_charge_vals, in_discharge_vals)\n",
    "    if make in CHARGE_MASK_WITH_SOC_DIFFS_MAKES:\n",
    "        return charge_n_discharging_masks_from_soc_diff(tss)\n",
    "    raise ValueError(MAKE_NOT_SUPPORTED_ERROR.format(make=make))\n",
    "\n",
    "def trim_leading_n_trailing_soc_off_masks(tss:DF, masks:list[str]) -> DF:\n",
    "        for mask in masks:\n",
    "            tss[\"naned_soc\"] = tss[\"soc\"].where(tss[mask])\n",
    "            soc_grp = tss.groupby([\"vin\", mask + \"_idx\"], observed=True)[\"naned_soc\"]\n",
    "            trailing_soc = soc_grp.transform(\"first\")\n",
    "            leading_soc = soc_grp.transform(\"last\")\n",
    "            tss[\"trailing_soc\"] = trailing_soc\n",
    "            tss[\"leading_soc\"] = leading_soc\n",
    "            tss[f\"trimmed_{mask}\"] = tss[mask] & (tss[\"soc\"] != trailing_soc) & (tss[\"soc\"] != leading_soc)\n",
    "        tss = tss.drop(columns=\"naned_soc\")\n",
    "        return tss\n",
    "def compute_idx_from_masks( tss: DF, masks:list[str]) -> DF:\n",
    "\n",
    "    for mask in masks:\n",
    "        idx_col_name = f\"{mask}_idx\"\n",
    "        shifted_mask = tss.groupby(\"vin\", observed=True)[mask].shift(fill_value=False)\n",
    "        tss[\"new_period_start_mask\"] = shifted_mask.ne(tss[mask]) \n",
    "        if MAX_TD is not None:\n",
    "            tss[\"new_period_start_mask\"] |= (tss[\"time_diff\"] > MAX_TD)\n",
    "        tss[idx_col_name] = tss.groupby(\"vin\", observed=True)[\"new_period_start_mask\"].cumsum().astype(\"uint16\")\n",
    "        tss.drop(columns=[\"new_period_start_mask\"], inplace=True)\n",
    "    return tss\n",
    "\n",
    "def compute_status_col( tss:DF) -> DF:\n",
    "    tss_grp = tss.groupby(\"vin\", observed=True)\n",
    "    status = tss[\"in_charge\"].map({True: \"charging\", False:\"discharging\", pd.NA:\"unknown\"})\n",
    "    tss[\"status\"] = status.mask(\n",
    "        tss[\"in_charge\"].eq(False, fill_value=True),\n",
    "        np.where(tss_grp[\"odometer\"].diff() > 0, \"moving\", \"idle_discharging\"),\n",
    "    )\n",
    "    return tss\n",
    "\n",
    "def compute_cum_var(tss: DF, var_col:str, cum_var_col:str) -> DF:\n",
    "        if not var_col in tss.columns:\n",
    "            return tss\n",
    "        tss[cum_var_col] = (\n",
    "            cumulative_trapezoid(\n",
    "                # Leave the keywords as default order is y x not x y (-_-)\n",
    "                # Make sure that date time units are in seconds before converting to int\n",
    "                x=tss[\"date\"].dt.as_unit(\"s\").astype(int),\n",
    "                y=tss[var_col].fillna(0).values,\n",
    "                initial=0,\n",
    "            )            \n",
    "            .astype(\"float32\")\n",
    "        )\n",
    "        tss[cum_var_col] *= KJ_TO_KWH # Convert from kj to kwh\n",
    "        # Reset value to zero at the start of each vehicle time series\n",
    "        # This is better than performing a groupby.apply with cumulative_trapezoid\n",
    "        tss[cum_var_col] -= tss.groupby('vin', observed=True)[cum_var_col].transform(\"first\")\n",
    "        return tss\n",
    "    \n",
    "def compute_date_vars(tss:DF) -> DF:\n",
    "\n",
    "        tss[\"time_diff\"] = tss.groupby('vin', observed=False)[\"date\"].diff()\n",
    "        tss[\"sec_time_diff\"] = tss[\"time_diff\"].dt.total_seconds()\n",
    "        return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_units_to_metric(tss):\n",
    "        tss[\"odometer\"] = tss[\"odometer\"] * ODOMETER_MILES_TO_KM.get(\"tesla\", 1)\n",
    "        return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw_tss.rename(columns=RENAME_COLS_DICT, errors=\"ignore\")\n",
    "raw = raw.pipe(safe_locate, col_loc=list(COL_DTYPES.keys()))\n",
    "raw = raw.pipe(safe_astype, COL_DTYPES)\n",
    "raw = raw.pipe(normalize_units_to_metric)\n",
    "raw = raw.pipe(str_lower_columns, COLS_TO_STR_LOWER)\n",
    "raw = raw.pipe(compute_date_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_charge_n_discharge_vars(tss:DF) -> DF:\n",
    "    return (\n",
    "        tss\n",
    "        # Compute the in_charge and in_discharge masks \n",
    "        .pipe(compute_charge_n_discharge_masks, 'tesla', IN_CHARGE_CHARGING_STATUS_VALS, IN_DISCHARGE_CHARGING_STATUS_VALS)\n",
    "        # Compute the correspding indices to perfrom split-apply-combine ops\n",
    "        .pipe(compute_idx_from_masks, [\"in_charge\", \"in_discharge\"])\n",
    "        # We recompute the masks by trimming off the points that have the first and last soc values\n",
    "        # This is done to reduce the noise in the output due to measurments noise.\n",
    "        .pipe(trim_leading_n_trailing_soc_off_masks, [\"in_charge\", \"in_discharge\"]) \n",
    "        .pipe(compute_idx_from_masks, [\"trimmed_in_charge\", \"trimmed_in_discharge\"])\n",
    "        .pipe(compute_cum_var, \"power\", \"cum_energy\")\n",
    "        .pipe(compute_cum_var, \"charger_power\", \"cum_charge_energy_added\")\n",
    "        .pipe(compute_status_col)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.pipe(compute_charge_n_discharge_vars)\n",
    "\n",
    "raw = raw.merge(fleet_info, on=\"vin\", how=\"left\")\n",
    "raw = raw.eval(\"age = date.dt.tz_localize(None) - start_date.dt.tz_localize(None)\")\n",
    "# It seems that the reset_index calls doesn't reset the id_col into a category if the groupby's by argument was categorical.\n",
    "# So we recall astype on the id_col  in case it is supposed to be categorical.\n",
    "processed_tss = raw.astype({'vin': COL_DTYPES['vin']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tss['ACChargingPower_stringValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_result = (raw.groupby([\"vin\", \"trimmed_in_charge_idx\"], observed=True, as_index=False)\n",
    "        .agg(\n",
    "            energy_added_min=pd.NamedAgg(\"charge_energy_added\", \"min\"),\n",
    "            energy_added_end=pd.NamedAgg(\"charge_energy_added\", \"last\"),\n",
    "            soc_diff=pd.NamedAgg(\"soc\", series_start_end_diff),\n",
    "            inside_temp=pd.NamedAgg(\"inside_temp\", \"mean\"),\n",
    "            net_capacity=pd.NamedAgg(\"net_capacity\", \"first\"),\n",
    "            range=pd.NamedAgg(\"range\", \"first\"),\n",
    "            odometer=pd.NamedAgg(\"odometer\", \"first\"),\n",
    "            version=pd.NamedAgg(\"version\", \"first\"),\n",
    "            size=pd.NamedAgg(\"soc\", \"size\"),\n",
    "            model=pd.NamedAgg(\"model\", \"first\"),\n",
    "            date=pd.NamedAgg(\"date\", \"first\"),\n",
    "            charging_power=pd.NamedAgg(\"charging_power\", \"median\"),\n",
    "            tesla_code=pd.NamedAgg(\"tesla_code\", \"first\"),\n",
    "        )\n",
    "        .eval(\"energy_added = energy_added_end - energy_added_min\")\n",
    "        .eval(\"soh = energy_added / (soc_diff / 100.0 * net_capacity)\")\n",
    "        #.query(\"soc_diff > 40 & soh.between(0.75, 1.05)\")\n",
    "        .eval(\"level_1 = soc_diff * (charging_power < 8) / 100\")\n",
    "        .eval(\"level_2 = soc_diff * (charging_power.between(8, 45)) / 100\")\n",
    "        .eval(\"level_3 = soc_diff * (charging_power > 45) / 100\")\n",
    "\t    # .eval(\"bottom_soh = soh.between(0.75, 0.9)\")\n",
    "        # .eval(\"fixed_soh_min_end = soh.mask(tesla_code == 'MTY13', soh / 0.96)\")\n",
    "        # .eval(\"fixed_soh_min_end = fixed_soh_min_end.mask(bottom_soh & tesla_code == 'MTY13', fixed_soh_min_end + 0.08)\")\n",
    "        # .eval(\"soh = fixed_soh_min_end\")\n",
    "        .sort_values([\"tesla_code\", \"vin\", \"date\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOH_FILTER_EVAL_STRINGS: dict[callable] = {\n",
    "    \"tesla\": \"soh = soh.where(soc_diff > 40 & soh.between(0.75, 1.05))\",\n",
    "    \"volvo\": \"soh = soh.where(soc > 0.7)\",\n",
    "    \"renault\": \"soh = soh.where(soc > 0.5)\",\n",
    "    \"ford\": \"soh = soh\",\n",
    "    \"mercedes-benz\": \"soh = soh\",\n",
    "    \"bmw\": \"soh = soh\",\n",
    "    \"kia\": \"soh = soh\",\n",
    "    \"stellantis\": \"soh = soh\",\n",
    "}\n",
    "\n",
    "def make_charge_levels_presentable(results:DF) -> DF:\n",
    "    # If none of the level columns exist, return the results as is\n",
    "    level_columns = [\"level_1\", \"level_2\", \"level_3\"]\n",
    "    existing_level_columns = [col for col in level_columns if col in results.columns]\n",
    "    if not existing_level_columns:\n",
    "        return results\n",
    "    negative_charge_levels = results[[\"level_1\", \"level_2\", \"level_3\"]].lt(0)\n",
    "    nb_negative_levels = negative_charge_levels.sum().sum()\n",
    "    if nb_negative_levels > 0:\n",
    "        logger.warning(f\"There are {nb_negative_levels}({100*nb_negative_levels/len(results):2f}%) negative charge levels, setting them to 0.\")\n",
    "    results[[\"level_1\", \"level_2\", \"level_3\"]] = results[[\"level_1\", \"level_2\", \"level_3\"]].mask(negative_charge_levels, 0)\n",
    "    return results\n",
    "UPDATE_FREQUENCY = pd.Timedelta(days=7)\n",
    "def agg_results_by_update_frequency(results:DF) -> DF:\n",
    "    results[\"date\"] = (\n",
    "        pd.to_datetime(results[\"date\"], format='mixed')\n",
    "        .dt.floor(UPDATE_FREQUENCY)\n",
    "        .dt.tz_localize(None)\n",
    "        .dt.date\n",
    "        .astype('datetime64[ns]')\n",
    "    )\n",
    "    return (\n",
    "        results\n",
    "        # Setting level columns to 0 if they don't exist.\n",
    "        .assign(\n",
    "            level_1=results.get(\"level_1\", 0),\n",
    "            level_2=results.get(\"level_2\", 0),\n",
    "            level_3=results.get(\"level_3\", 0),\n",
    "        )\n",
    "        .groupby([\"vin\", \"date\"], observed=True, as_index=False)\n",
    "        .agg(\n",
    "            odometer=pd.NamedAgg(\"odometer\", \"last\"),\n",
    "            soh=pd.NamedAgg(\"soh\", \"median\"),\n",
    "            model=pd.NamedAgg(\"model\", \"first\"),\n",
    "            version=pd.NamedAgg(\"version\", \"first\"),\n",
    "            level_1=pd.NamedAgg(\"level_1\", \"sum\"),\n",
    "            level_2=pd.NamedAgg(\"level_2\", \"sum\"),\n",
    "            level_3=pd.NamedAgg(\"level_3\", \"sum\"),            \n",
    "        )\n",
    "    )\n",
    "from core.stats_utils import *\n",
    "def make_soh_presentable_per_vehicle(df:DF) -> DF:\n",
    "    if df[\"soh\"].isna().all():\n",
    "        return df\n",
    "    if df[\"soh\"].count() > 3:\n",
    "        outliser_mask = mask_out_outliers_by_interquartile_range(df[\"soh\"])\n",
    "        assert outliser_mask.any(), f\"There seems to be only outliers???:\\n{df['soh']}.\"\n",
    "        df = df[outliser_mask].copy()\n",
    "    if df[\"soh\"].count() >= 2:\n",
    "        df[\"soh\"] = force_decay(df[[\"soh\", \"odometer\"]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VALID_SOH_POINTS_LINE_BOUNDS = DF({\n",
    "  \"odometer\": [20_000, 200_000, 0, 200_000],\n",
    "  \"soh\": [1.0, 0.95, 0.9, 0.5],\n",
    "  \"point\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "  \"bound\": [\"max\", \"max\", \"min\", \"min\"]\n",
    "}).set_index([\"bound\", \"point\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_result = (raw_result.assign(soh=lambda df: df[\"soh\"].replace([np.inf, -np.inf], np.nan))\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "        .pipe(make_charge_levels_presentable)\n",
    "        .eval(SOH_FILTER_EVAL_STRINGS['tesla'])\n",
    "        .pipe(agg_results_by_update_frequency)\n",
    "        .groupby('vin', observed=True)\n",
    "        .apply(make_soh_presentable_per_vehicle, include_groups=False)\n",
    "        .reset_index(level=0)\n",
    "        .pipe(filter_results_by_lines_bounds, VALID_SOH_POINTS_LINE_BOUNDS, logger=logger)\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_results(brand:str) -> DF:\n",
    "    logger.info(f\"{'Processing ' + brand + ' results.':=^{50}}\")\n",
    "    results =  (\n",
    "        GET_RESULTS_FUNCS[brand]()\n",
    "        # Some raw estimations may have inf values, this will make mask_out_outliers_by_interquartile_range and force_monotonic_decrease fail\n",
    "        # So we replace them by NaNs.\n",
    "        .assign(soh=lambda df: df[\"soh\"].replace([np.inf, -np.inf], np.nan))\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "        .pipe(make_charge_levels_presentable)\n",
    "        .eval(SOH_FILTER_EVAL_STRINGS[brand])\n",
    "        .pipe(agg_results_by_update_frequency)\n",
    "        .groupby('vin', observed=True)\n",
    "        .apply(make_soh_presentable_per_vehicle, include_groups=False)\n",
    "        .reset_index(level=0)\n",
    "        .pipe(filter_results_by_lines_bounds, VALID_SOH_POINTS_LINE_BOUNDS, logger=logger)\n",
    "        .sort_values([\"vin\", \"date\"])\n",
    "    )\n",
    "    results[\"soh\"] = results.groupby(\"vin\", observed=True)[\"soh\"].ffill()\n",
    "    results[\"soh\"] = results.groupby(\"vin\", observed=True)[\"soh\"].bfill()\n",
    "    results[\"odometer\"] = results.groupby(\"vin\", observed=True)[\"odometer\"].ffill()\n",
    "    results[\"odometer\"] = results.groupby(\"vin\", observed=True)[\"odometer\"].bfill()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.raw_tss.fleet_telemetry_raw_tss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_raw_tss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = res.rename(columns=RENAME_COLS_DICT, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = res_test.pipe(safe_locate, col_loc=list(COL_DTYPES.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = tss.pipe(safe_astype, COL_DTYPES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_units_to_metric(tss):\n",
    "        tss[\"odometer\"] = tss[\"odometer\"] * ODOMETER_MILES_TO_KM.get(\"tesla\", 1)\n",
    "        return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = tss.pipe(normalize_units_to_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = tss.pipe(str_lower_columns, COLS_TO_STR_LOWER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_tss.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_charge_n_discharge_vars(self, tss:DF) -> DF:\n",
    "    return (\n",
    "        tss\n",
    "        # Compute the in_charge and in_discharge masks \n",
    "        .pipe(compute_charge_n_discharge_masks, 'tesla', IN_CHARGE_CHARGING_STATUS_VALS, IN_DISCHARGE_CHARGING_STATUS_VALS)\n",
    "        # Compute the correspding indices to perfrom split-apply-combine ops\n",
    "        .pipe(compute_idx_from_masks, [\"in_charge\", \"in_discharge\"])\n",
    "        # We recompute the masks by trimming off the points that have the first and last soc values\n",
    "        # This is done to reduce the noise in the output due to measurments noise.\n",
    "        .pipe(trim_leading_n_trailing_soc_off_masks, [\"in_charge\", \"in_discharge\"]) \n",
    "        .pipe(compute_idx_from_masks, [\"trimmed_in_charge\", \"trimmed_in_discharge\"])\n",
    "        .pipe(compute_cum_var, \"power\", \"cum_energy\")\n",
    "        .pipe(compute_cum_var, \"charger_power\", \"cum_charge_energy_added\")\n",
    "        .pipe(compute_status_col)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss.pipe(compute_charge_n_discharge_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_n_discharging_masks_from_charging_status(tss, IN_CHARGE_CHARGING_STATUS_VALS, IN_DISCHARGE_CHARGING_STATUS_VALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.processed_tss.ProcessedTimeSeries import ProcessedTimeSeries\n",
    "from transform.processed_tss.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ProcessedTimeSeries('fleet-telemetry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[[\"vin\", \"date\", \"vehicle\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

