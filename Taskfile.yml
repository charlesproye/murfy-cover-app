# https://taskfile.dev

version: '3'

vars:
  RDB_INSTANCE_ID: 196b3cc5-8de2-4a4c-bcfa-57f06b2b8364
  RDB_DATABASE_NAMES: rdb data-engineering
  LOCAL_DB_HOST: localhost
  LOCAL_DB_PORT: 55432
  LOCAL_DB_NAME: evalue
  LOCAL_DB_USER: evalue
  LOCAL_DB_PASSWORD: evalue

tasks:
  dagster:redeploy:
    cmds:
      - docker compose build dagster-user-deployment --push
      - kubectl --context $BIB_KAPSULE_PROD rollout restart deployment -n dagster user-code-dagster-user-deployments-bib-code
      - kubectl --context $BIB_KAPSULE_PROD rollout status deployment -n dagster user-code-dagster-user-deployments-bib-code
    silent: true

  evalue:back:build-deploy:
    cmds:
      - docker compose build external_api --push
      - kubectl --context $BIB_KAPSULE_PROD rollout restart deployment -n evalue external-api
      - kubectl --context $BIB_KAPSULE_PROD rollout status deployment -n evalue external-api
    silent: true

  db:production:backup:
    desc: Create a backup of the production Scaleway RDB (both rdb and data-engineering databases)
    cmds:
      - |
        for DB_NAME in {{.RDB_DATABASE_NAMES}}; do
          echo "Creating backup for database: $DB_NAME..."
          BACKUP_ID=$(scw rdb backup create instance-id={{.RDB_INSTANCE_ID}} name="${DB_NAME}-$(whoami)-$(date +%s)" database-name="$DB_NAME" expires-at=$(TZ=UTC-24 date +%Y-%m-%dT%H:%M:%SZ) --output json | jq -r '.id')
          scw rdb backup wait $BACKUP_ID
          scw rdb backup export $BACKUP_ID
          echo "âœ… Backup complete for $DB_NAME"
        done
        echo "To restore these backups, run: task db:local:restore"
        echo "ðŸš¨ This is only usable for now because the DB is small (~10MB). When reaching a few GB, we'll need to think about something else."
    silent: true

  db:local:restore:
    desc: Restore the latest Scaleway RDB backups to local PostgreSQL (both rdb and data-engineering databases)
    cmds:
      - |
        docker compose down postgres -v
        docker compose up -d postgres
        sleep 3
        for DB_NAME in {{.RDB_DATABASE_NAMES}}; do
          echo "Finding latest backup for database: $DB_NAME..."
          BACKUPS_JSON=$(scw rdb backup list instance-id={{.RDB_INSTANCE_ID}} --output json)
          BACKUP_ID=$(echo "$BACKUPS_JSON" | jq -r --arg db "$DB_NAME" '[.[] | select(.database_name == $db)] | sort_by(.created_at) | reverse | .[0].ID // empty')
          if [ -z "$BACKUP_ID" ] || [ "$BACKUP_ID" = "null" ]; then
            echo "Error: No backups found for database $DB_NAME"
            exit 1
          fi
          DOWNLOAD_URL=$(scw rdb backup get $BACKUP_ID --output json | jq -r '.download_url')
          BACKUP_FILE="/tmp/${DB_NAME}_backup.custom"
          curl -L -o "$BACKUP_FILE" "$DOWNLOAD_URL"
          # Map source DB name to local DB name:
          # - rdb -> evalue (existing local DB name)
          # - data-engineering -> data_engineering
          if [ "$DB_NAME" = "rdb" ]; then
            LOCAL_DB="{{.LOCAL_DB_NAME}}"
          else
            LOCAL_DB=$(echo "$DB_NAME" | tr '-' '_')
          fi
          docker compose exec -T postgres psql -U {{.LOCAL_DB_USER}} -d postgres -c "CREATE DATABASE $LOCAL_DB;" 2>/dev/null || true
          docker compose cp "$BACKUP_FILE" "postgres:/tmp/${DB_NAME}_backup.custom"
          docker compose exec -T postgres bash -c "pg_restore --list /tmp/${DB_NAME}_backup.custom | grep -v pgaudit > /tmp/${DB_NAME}_restore.list"
          docker compose exec -T postgres pg_restore -U {{.LOCAL_DB_USER}} -d "$LOCAL_DB" --no-owner --no-acl -L "/tmp/${DB_NAME}_restore.list" "/tmp/${DB_NAME}_backup.custom"
          rm "$BACKUP_FILE"
          echo "âœ… Restored $DB_NAME to local database: $LOCAL_DB"
        done
    silent: true

  db:local:backup-and-restore:
    desc: Create a backup and restore it to local database (all-in-one)
    cmds:
      - task: db:production:backup
      - sleep 5
      - task: db:local:restore
    silent: false

  docker:setup:
    cmds:
      - docker buildx create --name multiarch --driver docker-container --bootstrap --use

  # Alembic
  alembic:data-eng:generate:
    cmds:
      - uv run alembic -c src/db_models/data_eng/alembic.ini revision --autogenerate -m "NEW COMMIT - CHANGE ME"
  alembic:data-eng:upgrade:
    cmds:
      - uv run alembic -c src/db_models/data_eng/alembic.ini upgrade head

  alembic:data-ev:generate:
    cmds:
      - uv run alembic -c src/db_models/alembic.ini revision --autogenerate -m "NEW COMMIT - CHANGE ME"
  alembic:data-ev:upgrade:
    cmds:
      - uv run alembic -c src/db_models/alembic.ini upgrade head

  utils:generate-oem-field-files:
    cmds:
      - uv run -m src.utils.oem_field_filter_generator.generate_fields
